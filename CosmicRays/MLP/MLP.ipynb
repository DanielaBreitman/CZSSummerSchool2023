{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sgagnon/anaconda3/envs/ddpm/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['DejaVu Serif']\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = [ \"snapshot_110.hdf5\", \"snapshot_115.hdf5\" , \"snapshot_100.hdf5\", \"snapshot_105.hdf5\" ]\n",
    "files = [ \"../snapshot_110.hdf5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file:  snapshot_110.hdf5\n",
      "reading file:  snapshot_110.hdf5\n"
     ]
    }
   ],
   "source": [
    "# initialize training dataset arrays\n",
    "pos_arr = []\n",
    "rad_arr = []\n",
    "dens_arr = []\n",
    "mass_arr = []\n",
    "vol_arr = []\n",
    "gpot_arr = []\n",
    "pres_arr = []\n",
    "mag_arr = []\n",
    "Babs_arr = []\n",
    "encr_arr = [] # is this supposed to be a target array?\n",
    "# target array\n",
    "slope_arr = []\n",
    "\n",
    "for filename in files:\n",
    "\n",
    "    # open file\n",
    "    f = h5py.File(filename)\n",
    "    #if filename == files[0]:\n",
    "    #    for k in f[\"PartType0\"].keys():\n",
    "    #        print(k)\n",
    "    \n",
    "    # read units from file\n",
    "    UnitM, UnitL, UnitV, BoxSize = read_units(filename)\n",
    "    U = compute_arepo_units(UnitM, UnitL, UnitV, False)\n",
    "    \n",
    "    # read momenta\n",
    "    pf, pi = read_momentum_bins(filename)\n",
    "    #print(pi)\n",
    "    \n",
    "    BoxCtr = BoxSize*U[\"UnitLength\"]/2.\n",
    "\n",
    "    # get full data and convert it to cgs\n",
    "    \n",
    "    # positions\n",
    "    pos  = np.array(f[u'PartType0/Coordinates']).astype(np.float64)*U[\"UnitLength\"]-BoxCtr\n",
    "    rad  = np.sqrt(np.sum(pos**2,axis=1))\n",
    "\n",
    "    # pos_arr += list(pos)\n",
    "    rad_arr += list(rad)\n",
    "\n",
    "    # density, mass and volume\n",
    "    dens = np.array(f[u'PartType0/Density']).astype(np.float64)*U[\"UnitDensity\"]\n",
    "    mass = np.array(f[u'PartType0/Masses'])*U[\"UnitMass\"]\n",
    "    volu = mass/dens\n",
    "\n",
    "    dens_arr += list(dens)\n",
    "    mass_arr += list(mass)\n",
    "    vol_arr += list(volu)\n",
    "\n",
    "    # gravitational potential\n",
    "    gpot = np.array(f[u'PartType0/Potential']).astype(np.float64)*U[\"UnitPotential\"]\n",
    "\n",
    "    gpot_arr += list(gpot)\n",
    "\n",
    "    # thermal pressure\n",
    "    pres = np.array(f[u'PartType0/Pressure']).astype(np.float64)*U[\"UnitPressure\"]\n",
    "\n",
    "    pres_arr += list(pres)\n",
    "\n",
    "    # magnetic field vector\n",
    "    mag  = np.array(f[u'PartType0/MagneticField']).astype(np.float64)*U[\"UnitBfield\"]\n",
    "    Babs = np.sqrt(np.sum(mag**2,axis=1))\n",
    "\n",
    "    mag_arr += list(mag)\n",
    "    Babs_arr += list(Babs)\n",
    "    \n",
    "    # total CR energy density\n",
    "    cren = np.array(f[u'PartType0/CosmicRaySpecificEnergy']).astype(np.float64)*U[\"UnitEspecific\"]\n",
    "    encr = cren*dens\n",
    "\n",
    "    encr_arr += list(encr)\n",
    "    \n",
    "    # CR spectrum amplitude\n",
    "    crspec = np.array(f[u'PartType0/CRspecEnergy']).astype(np.float64)\n",
    "    \n",
    "    # CR sprectral slope\n",
    "    slope  = np.log(crspec[:,-1]/crspec[:,-2]) / np.log(pi[-1]/pi[-2])\n",
    "\n",
    "    slope_arr += list(slope)\n",
    "\n",
    "# put em in numpy\n",
    "# training dataset arrays\n",
    "pos_arr = np.asarray(pos_arr)\n",
    "rad_arr = np.asarray(rad_arr)\n",
    "dens_arr = np.asarray(dens_arr)\n",
    "mass_arr = np.asarray(mass_arr)\n",
    "vol_arr = np.asarray(vol_arr)\n",
    "gpot_arr = np.asarray(gpot_arr)\n",
    "pres_arr = np.asarray(pres_arr)\n",
    "mag_arr = np.asarray(mag_arr)\n",
    "Babs_arr = np.asarray(Babs_arr)\n",
    "encr_arr = np.asarray(encr_arr)\n",
    "# target array\n",
    "slope_arr = np.asarray(slope_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idcs = np.where(dens_arr > 1e-29)\n",
    "np.random.shuffle(idcs[0]) # remove correlations between neighboring cells\n",
    "train_end_idx = int(len(idcs[0])*0.7)\n",
    "\n",
    "dataset = {\"source\": np.log10(np.stack([rad_arr[idcs], dens_arr[idcs], Babs_arr[idcs], encr_arr[idcs]])),\n",
    "            \"target\": slope_arr[idcs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for src in dataset[\"source\"]:\n",
    "    src -= src.min()\n",
    "    src /= src.max()\n",
    "\n",
    "dataset[\"target\"] -= dataset[\"target\"].min()\n",
    "dataset[\"target\"] /= dataset[\"target\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = {\"source\": dataset[\"source\"][:,:train_end_idx],\\\n",
    "                    \"target\": dataset[\"target\"][:train_end_idx]}\n",
    "\n",
    "testing_dataset = {\"source\": dataset[\"source\"][:,train_end_idx:],\\\n",
    "                    \"target\": dataset[\"target\"][train_end_idx:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lin1 = nn.Linear(4, 100, dtype=torch.float32)\n",
    "        self.tanh1 = nn.Sigmoid()\n",
    "\n",
    "        # self.lin2 = nn.Linear(8, 16, dtype=torch.float32)\n",
    "        # self.tanh2 = nn.Sigmoid()\n",
    "        \n",
    "        self.lin3 = nn.Linear(100, 1, dtype=torch.float32)\n",
    "        self.tanh3 = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.tanh1(x)\n",
    "        # x = self.lin2(x)\n",
    "        # x = self.tanh2(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.tanh3(x)\n",
    "        return x\n",
    "\n",
    "model = MLP().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch 0 | Batch 0 | Training Loss   0.10\n",
      "\tEpoch 0 | Batch 40 | Training Loss   0.09\n",
      "\tEpoch 0 | Batch 80 | Training Loss   0.08\n",
      "\tEpoch 0 | Batch 120 | Training Loss   0.07\n",
      "\tEpoch 0 | Batch 160 | Training Loss   0.06\n",
      "\tEpoch 0 | Batch 200 | Training Loss   0.05\n",
      "\tEpoch 0 | Batch 240 | Training Loss   0.05\n",
      "\tEpoch 0 | Batch 280 | Training Loss   0.05\n",
      "\tEpoch 0 | Batch 0 | Validation Loss   0.05\n",
      "\tEpoch 0 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 0 | Batch 80 | Validation Loss   0.05\n",
      "\tEpoch 0 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 0 | Training Loss   0.06\n",
      "Epoch 0 | Validation Loss   0.05\n",
      "\tEpoch 1 | Batch 0 | Training Loss   0.05\n",
      "\tEpoch 1 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 1 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 1 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 1 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 1 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 1 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 1 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 1 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 1 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 1 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 1 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 1 | Training Loss   0.05\n",
      "Epoch 1 | Validation Loss   0.04\n",
      "\tEpoch 2 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 2 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 2 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 2 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 2 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 2 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 2 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 2 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 2 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 2 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 2 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 2 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 2 | Training Loss   0.05\n",
      "Epoch 2 | Validation Loss   0.04\n",
      "\tEpoch 3 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 3 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 3 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 3 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 3 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 3 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 3 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 3 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 3 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 3 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 3 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 3 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 3 | Training Loss   0.05\n",
      "Epoch 3 | Validation Loss   0.04\n",
      "\tEpoch 4 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 4 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 4 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 4 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 4 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 4 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 4 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 4 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 4 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 4 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 4 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 4 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 4 | Training Loss   0.04\n",
      "Epoch 4 | Validation Loss   0.04\n",
      "\tEpoch 5 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 5 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 5 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 5 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 5 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 5 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 5 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 5 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 5 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 5 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 5 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 5 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 5 | Training Loss   0.04\n",
      "Epoch 5 | Validation Loss   0.04\n",
      "\tEpoch 6 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 6 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 6 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 6 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 6 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 6 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 6 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 6 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 6 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 6 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 6 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 6 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 6 | Training Loss   0.04\n",
      "Epoch 6 | Validation Loss   0.04\n",
      "\tEpoch 7 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 7 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 7 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 7 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 7 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 7 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 7 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 7 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 7 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 7 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 7 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 7 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 7 | Training Loss   0.04\n",
      "Epoch 7 | Validation Loss   0.04\n",
      "\tEpoch 8 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 8 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 8 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 8 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 8 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 8 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 8 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 8 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 8 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 8 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 8 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 8 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 8 | Training Loss   0.04\n",
      "Epoch 8 | Validation Loss   0.04\n",
      "\tEpoch 9 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 9 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 9 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 9 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 9 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 9 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 9 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 9 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 9 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 9 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 9 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 9 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 9 | Training Loss   0.04\n",
      "Epoch 9 | Validation Loss   0.04\n",
      "\tEpoch 10 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 10 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 10 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 10 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 10 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 10 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 10 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 10 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 10 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 10 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 10 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 10 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 10 | Training Loss   0.04\n",
      "Epoch 10 | Validation Loss   0.04\n",
      "\tEpoch 11 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 11 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 11 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 11 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 11 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 11 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 11 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 11 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 11 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 11 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 11 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 11 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 11 | Training Loss   0.04\n",
      "Epoch 11 | Validation Loss   0.04\n",
      "\tEpoch 12 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 12 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 12 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 12 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 12 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 12 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 12 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 12 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 12 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 12 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 12 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 12 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 12 | Training Loss   0.04\n",
      "Epoch 12 | Validation Loss   0.04\n",
      "\tEpoch 13 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 13 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 13 | Batch 80 | Training Loss   0.04\n",
      "\tEpoch 13 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 13 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 13 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 13 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 13 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 13 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 13 | Batch 40 | Validation Loss   0.04\n",
      "\tEpoch 13 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 13 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 13 | Training Loss   0.04\n",
      "Epoch 13 | Validation Loss   0.04\n",
      "\tEpoch 14 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 14 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 14 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 14 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 14 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 14 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 14 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 14 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 14 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 14 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 14 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 14 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 14 | Training Loss   0.04\n",
      "Epoch 14 | Validation Loss   0.04\n",
      "\tEpoch 15 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 15 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 15 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 15 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 15 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 15 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 15 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 15 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 15 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 15 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 15 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 15 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 15 | Training Loss   0.04\n",
      "Epoch 15 | Validation Loss   0.04\n",
      "\tEpoch 16 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 16 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 16 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 16 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 16 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 16 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 16 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 16 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 16 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 16 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 16 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 16 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 16 | Training Loss   0.04\n",
      "Epoch 16 | Validation Loss   0.04\n",
      "\tEpoch 17 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 17 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 17 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 17 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 17 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 17 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 17 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 17 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 17 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 17 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 17 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 17 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 17 | Training Loss   0.04\n",
      "Epoch 17 | Validation Loss   0.04\n",
      "\tEpoch 18 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 18 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 18 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 18 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 18 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 18 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 18 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 18 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 18 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 18 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 18 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 18 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 18 | Training Loss   0.04\n",
      "Epoch 18 | Validation Loss   0.04\n",
      "\tEpoch 19 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 19 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 19 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 19 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 19 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 19 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 19 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 19 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 19 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 19 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 19 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 19 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 19 | Training Loss   0.04\n",
      "Epoch 19 | Validation Loss   0.04\n",
      "\tEpoch 20 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 20 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 20 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 20 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 20 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 20 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 20 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 20 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 20 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 20 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 20 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 20 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 20 | Training Loss   0.04\n",
      "Epoch 20 | Validation Loss   0.04\n",
      "\tEpoch 21 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 21 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 21 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 21 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 21 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 21 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 21 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 21 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 21 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 21 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 21 | Batch 80 | Validation Loss   0.04\n",
      "\tEpoch 21 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 21 | Training Loss   0.04\n",
      "Epoch 21 | Validation Loss   0.04\n",
      "\tEpoch 22 | Batch 0 | Training Loss   0.04\n",
      "\tEpoch 22 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 22 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 22 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 22 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 22 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 22 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 22 | Batch 280 | Training Loss   0.04\n",
      "\tEpoch 22 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 22 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 22 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 22 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 22 | Training Loss   0.04\n",
      "Epoch 22 | Validation Loss   0.04\n",
      "\tEpoch 23 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 23 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 23 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 23 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 23 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 23 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 23 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 23 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 23 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 23 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 23 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 23 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 23 | Training Loss   0.04\n",
      "Epoch 23 | Validation Loss   0.04\n",
      "\tEpoch 24 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 24 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 24 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 24 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 24 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 24 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 24 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 24 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 24 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 24 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 24 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 24 | Batch 120 | Validation Loss   0.04\n",
      "Epoch 24 | Training Loss   0.04\n",
      "Epoch 24 | Validation Loss   0.04\n",
      "\tEpoch 25 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 25 | Batch 40 | Training Loss   0.04\n",
      "\tEpoch 25 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 25 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 25 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 25 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 25 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 25 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 25 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 25 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 25 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 25 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 25 | Training Loss   0.04\n",
      "Epoch 25 | Validation Loss   0.04\n",
      "\tEpoch 26 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 26 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 26 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 26 | Batch 120 | Training Loss   0.04\n",
      "\tEpoch 26 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 26 | Batch 200 | Training Loss   0.04\n",
      "\tEpoch 26 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 26 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 26 | Batch 0 | Validation Loss   0.04\n",
      "\tEpoch 26 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 26 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 26 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 26 | Training Loss   0.04\n",
      "Epoch 26 | Validation Loss   0.04\n",
      "\tEpoch 27 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 27 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 27 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 27 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 27 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 27 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 27 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 27 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 27 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 27 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 27 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 27 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 27 | Training Loss   0.04\n",
      "Epoch 27 | Validation Loss   0.04\n",
      "\tEpoch 28 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 28 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 28 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 28 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 28 | Batch 160 | Training Loss   0.04\n",
      "\tEpoch 28 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 28 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 28 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 28 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 28 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 28 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 28 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 28 | Training Loss   0.04\n",
      "Epoch 28 | Validation Loss   0.04\n",
      "\tEpoch 29 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 29 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 29 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 29 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 29 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 29 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 29 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 29 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 29 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 29 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 29 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 29 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 29 | Training Loss   0.04\n",
      "Epoch 29 | Validation Loss   0.04\n",
      "\tEpoch 30 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 30 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 30 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 30 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 30 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 30 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 30 | Batch 240 | Training Loss   0.04\n",
      "\tEpoch 30 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 30 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 30 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 30 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 30 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 30 | Training Loss   0.04\n",
      "Epoch 30 | Validation Loss   0.04\n",
      "\tEpoch 31 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 31 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 31 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 31 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 31 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 31 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 31 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 31 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 31 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 31 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 31 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 31 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 31 | Training Loss   0.04\n",
      "Epoch 31 | Validation Loss   0.04\n",
      "\tEpoch 32 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 32 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 32 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 32 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 32 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 32 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 32 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 32 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 32 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 32 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 32 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 32 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 32 | Training Loss   0.04\n",
      "Epoch 32 | Validation Loss   0.04\n",
      "\tEpoch 33 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 33 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 33 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 33 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 33 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 33 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 33 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 33 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 33 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 33 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 33 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 33 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 33 | Training Loss   0.04\n",
      "Epoch 33 | Validation Loss   0.04\n",
      "\tEpoch 34 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 34 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 34 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 34 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 34 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 34 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 34 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 34 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 34 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 34 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 34 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 34 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 34 | Training Loss   0.04\n",
      "Epoch 34 | Validation Loss   0.04\n",
      "\tEpoch 35 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 35 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 35 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 35 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 35 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 35 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 35 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 35 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 35 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 35 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 35 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 35 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 35 | Training Loss   0.04\n",
      "Epoch 35 | Validation Loss   0.04\n",
      "\tEpoch 36 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 36 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 36 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 36 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 36 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 36 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 36 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 36 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 36 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 36 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 36 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 36 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 36 | Training Loss   0.04\n",
      "Epoch 36 | Validation Loss   0.04\n",
      "\tEpoch 37 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 37 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 37 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 37 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 37 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 37 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 37 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 37 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 37 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 37 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 37 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 37 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 37 | Training Loss   0.04\n",
      "Epoch 37 | Validation Loss   0.04\n",
      "\tEpoch 38 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 38 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 38 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 38 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 38 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 38 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 38 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 38 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 38 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 38 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 38 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 38 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 38 | Training Loss   0.04\n",
      "Epoch 38 | Validation Loss   0.04\n",
      "\tEpoch 39 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 39 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 39 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 39 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 39 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 39 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 39 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 39 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 39 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 39 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 39 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 39 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 39 | Training Loss   0.04\n",
      "Epoch 39 | Validation Loss   0.04\n",
      "\tEpoch 40 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 40 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 40 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 40 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 40 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 40 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 40 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 40 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 40 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 40 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 40 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 40 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 40 | Training Loss   0.04\n",
      "Epoch 40 | Validation Loss   0.04\n",
      "\tEpoch 41 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 41 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 41 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 41 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 41 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 41 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 41 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 41 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 41 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 41 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 41 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 41 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 41 | Training Loss   0.04\n",
      "Epoch 41 | Validation Loss   0.03\n",
      "\tEpoch 42 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 42 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 42 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 42 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 42 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 42 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 42 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 42 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 42 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 42 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 42 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 42 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 42 | Training Loss   0.04\n",
      "Epoch 42 | Validation Loss   0.03\n",
      "\tEpoch 43 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 43 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 43 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 43 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 43 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 43 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 43 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 43 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 43 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 43 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 43 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 43 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 43 | Training Loss   0.04\n",
      "Epoch 43 | Validation Loss   0.03\n",
      "\tEpoch 44 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 44 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 44 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 44 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 44 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 44 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 44 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 44 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 44 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 44 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 44 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 44 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 44 | Training Loss   0.03\n",
      "Epoch 44 | Validation Loss   0.03\n",
      "\tEpoch 45 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 45 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 45 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 45 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 45 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 45 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 45 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 45 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 45 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 45 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 45 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 45 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 45 | Training Loss   0.03\n",
      "Epoch 45 | Validation Loss   0.03\n",
      "\tEpoch 46 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 46 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 46 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 46 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 46 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 46 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 46 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 46 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 46 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 46 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 46 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 46 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 46 | Training Loss   0.03\n",
      "Epoch 46 | Validation Loss   0.03\n",
      "\tEpoch 47 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 47 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 47 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 47 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 47 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 47 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 47 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 47 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 47 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 47 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 47 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 47 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 47 | Training Loss   0.03\n",
      "Epoch 47 | Validation Loss   0.03\n",
      "\tEpoch 48 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 48 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 48 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 48 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 48 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 48 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 48 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 48 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 48 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 48 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 48 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 48 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 48 | Training Loss   0.03\n",
      "Epoch 48 | Validation Loss   0.03\n",
      "\tEpoch 49 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 49 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 49 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 49 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 49 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 49 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 49 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 49 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 49 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 49 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 49 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 49 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 49 | Training Loss   0.03\n",
      "Epoch 49 | Validation Loss   0.03\n",
      "\tEpoch 50 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 50 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 50 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 50 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 50 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 50 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 50 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 50 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 50 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 50 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 50 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 50 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 50 | Training Loss   0.03\n",
      "Epoch 50 | Validation Loss   0.03\n",
      "\tEpoch 51 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 51 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 51 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 51 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 51 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 51 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 51 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 51 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 51 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 51 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 51 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 51 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 51 | Training Loss   0.03\n",
      "Epoch 51 | Validation Loss   0.03\n",
      "\tEpoch 52 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 52 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 52 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 52 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 52 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 52 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 52 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 52 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 52 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 52 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 52 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 52 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 52 | Training Loss   0.03\n",
      "Epoch 52 | Validation Loss   0.03\n",
      "\tEpoch 53 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 53 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 53 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 53 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 53 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 53 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 53 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 53 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 53 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 53 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 53 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 53 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 53 | Training Loss   0.03\n",
      "Epoch 53 | Validation Loss   0.03\n",
      "\tEpoch 54 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 54 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 54 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 54 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 54 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 54 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 54 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 54 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 54 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 54 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 54 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 54 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 54 | Training Loss   0.03\n",
      "Epoch 54 | Validation Loss   0.03\n",
      "\tEpoch 55 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 55 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 55 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 55 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 55 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 55 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 55 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 55 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 55 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 55 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 55 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 55 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 55 | Training Loss   0.03\n",
      "Epoch 55 | Validation Loss   0.03\n",
      "\tEpoch 56 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 56 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 56 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 56 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 56 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 56 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 56 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 56 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 56 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 56 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 56 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 56 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 56 | Training Loss   0.03\n",
      "Epoch 56 | Validation Loss   0.03\n",
      "\tEpoch 57 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 57 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 57 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 57 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 57 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 57 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 57 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 57 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 57 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 57 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 57 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 57 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 57 | Training Loss   0.03\n",
      "Epoch 57 | Validation Loss   0.03\n",
      "\tEpoch 58 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 58 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 58 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 58 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 58 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 58 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 58 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 58 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 58 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 58 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 58 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 58 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 58 | Training Loss   0.03\n",
      "Epoch 58 | Validation Loss   0.03\n",
      "\tEpoch 59 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 59 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 59 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 59 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 59 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 59 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 59 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 59 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 59 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 59 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 59 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 59 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 59 | Training Loss   0.03\n",
      "Epoch 59 | Validation Loss   0.03\n",
      "\tEpoch 60 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 60 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 60 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 60 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 60 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 60 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 60 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 60 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 60 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 60 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 60 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 60 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 60 | Training Loss   0.03\n",
      "Epoch 60 | Validation Loss   0.03\n",
      "\tEpoch 61 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 61 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 61 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 61 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 61 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 61 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 61 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 61 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 61 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 61 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 61 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 61 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 61 | Training Loss   0.03\n",
      "Epoch 61 | Validation Loss   0.03\n",
      "\tEpoch 62 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 62 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 62 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 62 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 62 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 62 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 62 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 62 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 62 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 62 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 62 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 62 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 62 | Training Loss   0.03\n",
      "Epoch 62 | Validation Loss   0.03\n",
      "\tEpoch 63 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 63 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 63 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 63 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 63 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 63 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 63 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 63 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 63 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 63 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 63 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 63 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 63 | Training Loss   0.03\n",
      "Epoch 63 | Validation Loss   0.03\n",
      "\tEpoch 64 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 64 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 64 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 64 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 64 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 64 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 64 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 64 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 64 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 64 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 64 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 64 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 64 | Training Loss   0.03\n",
      "Epoch 64 | Validation Loss   0.03\n",
      "\tEpoch 65 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 65 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 65 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 65 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 65 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 65 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 65 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 65 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 65 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 65 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 65 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 65 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 65 | Training Loss   0.03\n",
      "Epoch 65 | Validation Loss   0.03\n",
      "\tEpoch 66 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 66 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 66 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 66 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 66 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 66 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 66 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 66 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 66 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 66 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 66 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 66 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 66 | Training Loss   0.03\n",
      "Epoch 66 | Validation Loss   0.03\n",
      "\tEpoch 67 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 67 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 67 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 67 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 67 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 67 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 67 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 67 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 67 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 67 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 67 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 67 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 67 | Training Loss   0.03\n",
      "Epoch 67 | Validation Loss   0.03\n",
      "\tEpoch 68 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 68 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 68 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 68 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 68 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 68 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 68 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 68 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 68 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 68 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 68 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 68 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 68 | Training Loss   0.03\n",
      "Epoch 68 | Validation Loss   0.03\n",
      "\tEpoch 69 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 69 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 69 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 69 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 69 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 69 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 69 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 69 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 69 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 69 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 69 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 69 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 69 | Training Loss   0.03\n",
      "Epoch 69 | Validation Loss   0.03\n",
      "\tEpoch 70 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 70 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 70 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 70 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 70 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 70 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 70 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 70 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 70 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 70 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 70 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 70 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 70 | Training Loss   0.03\n",
      "Epoch 70 | Validation Loss   0.03\n",
      "\tEpoch 71 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 71 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 71 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 71 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 71 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 71 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 71 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 71 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 71 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 71 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 71 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 71 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 71 | Training Loss   0.03\n",
      "Epoch 71 | Validation Loss   0.03\n",
      "\tEpoch 72 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 72 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 72 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 72 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 72 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 72 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 72 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 72 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 72 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 72 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 72 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 72 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 72 | Training Loss   0.03\n",
      "Epoch 72 | Validation Loss   0.03\n",
      "\tEpoch 73 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 73 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 73 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 73 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 73 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 73 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 73 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 73 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 73 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 73 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 73 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 73 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 73 | Training Loss   0.03\n",
      "Epoch 73 | Validation Loss   0.03\n",
      "\tEpoch 74 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 74 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 74 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 74 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 74 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 74 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 74 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 74 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 74 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 74 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 74 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 74 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 74 | Training Loss   0.03\n",
      "Epoch 74 | Validation Loss   0.03\n",
      "\tEpoch 75 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 75 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 75 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 75 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 75 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 75 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 75 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 75 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 75 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 75 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 75 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 75 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 75 | Training Loss   0.03\n",
      "Epoch 75 | Validation Loss   0.03\n",
      "\tEpoch 76 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 76 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 76 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 76 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 76 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 76 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 76 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 76 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 76 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 76 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 76 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 76 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 76 | Training Loss   0.03\n",
      "Epoch 76 | Validation Loss   0.03\n",
      "\tEpoch 77 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 77 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 77 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 77 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 77 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 77 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 77 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 77 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 77 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 77 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 77 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 77 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 77 | Training Loss   0.03\n",
      "Epoch 77 | Validation Loss   0.03\n",
      "\tEpoch 78 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 78 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 78 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 78 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 78 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 78 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 78 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 78 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 78 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 78 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 78 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 78 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 78 | Training Loss   0.03\n",
      "Epoch 78 | Validation Loss   0.03\n",
      "\tEpoch 79 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 79 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 79 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 79 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 79 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 79 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 79 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 79 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 79 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 79 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 79 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 79 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 79 | Training Loss   0.03\n",
      "Epoch 79 | Validation Loss   0.03\n",
      "\tEpoch 80 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 80 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 80 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 80 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 80 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 80 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 80 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 80 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 80 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 80 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 80 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 80 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 80 | Training Loss   0.03\n",
      "Epoch 80 | Validation Loss   0.03\n",
      "\tEpoch 81 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 81 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 81 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 81 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 81 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 81 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 81 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 81 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 81 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 81 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 81 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 81 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 81 | Training Loss   0.03\n",
      "Epoch 81 | Validation Loss   0.03\n",
      "\tEpoch 82 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 82 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 82 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 82 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 82 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 82 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 82 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 82 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 82 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 82 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 82 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 82 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 82 | Training Loss   0.03\n",
      "Epoch 82 | Validation Loss   0.03\n",
      "\tEpoch 83 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 83 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 83 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 83 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 83 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 83 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 83 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 83 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 83 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 83 | Batch 40 | Validation Loss   0.03\n",
      "\tEpoch 83 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 83 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 83 | Training Loss   0.03\n",
      "Epoch 83 | Validation Loss   0.03\n",
      "\tEpoch 84 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 84 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 84 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 84 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 84 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 84 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 84 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 84 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 84 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 84 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 84 | Batch 80 | Validation Loss   0.03\n",
      "\tEpoch 84 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 84 | Training Loss   0.03\n",
      "Epoch 84 | Validation Loss   0.03\n",
      "\tEpoch 85 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 85 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 85 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 85 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 85 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 85 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 85 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 85 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 85 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 85 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 85 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 85 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 85 | Training Loss   0.03\n",
      "Epoch 85 | Validation Loss   0.03\n",
      "\tEpoch 86 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 86 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 86 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 86 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 86 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 86 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 86 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 86 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 86 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 86 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 86 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 86 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 86 | Training Loss   0.03\n",
      "Epoch 86 | Validation Loss   0.03\n",
      "\tEpoch 87 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 87 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 87 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 87 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 87 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 87 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 87 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 87 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 87 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 87 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 87 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 87 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 87 | Training Loss   0.03\n",
      "Epoch 87 | Validation Loss   0.03\n",
      "\tEpoch 88 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 88 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 88 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 88 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 88 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 88 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 88 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 88 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 88 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 88 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 88 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 88 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 88 | Training Loss   0.03\n",
      "Epoch 88 | Validation Loss   0.03\n",
      "\tEpoch 89 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 89 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 89 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 89 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 89 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 89 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 89 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 89 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 89 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 89 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 89 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 89 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 89 | Training Loss   0.03\n",
      "Epoch 89 | Validation Loss   0.03\n",
      "\tEpoch 90 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 90 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 90 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 90 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 90 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 90 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 90 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 90 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 90 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 90 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 90 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 90 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 90 | Training Loss   0.03\n",
      "Epoch 90 | Validation Loss   0.03\n",
      "\tEpoch 91 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 91 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 91 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 91 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 91 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 91 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 91 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 91 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 91 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 91 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 91 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 91 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 91 | Training Loss   0.03\n",
      "Epoch 91 | Validation Loss   0.03\n",
      "\tEpoch 92 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 92 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 92 | Batch 80 | Training Loss   0.03\n",
      "\tEpoch 92 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 92 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 92 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 92 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 92 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 92 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 92 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 92 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 92 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 92 | Training Loss   0.03\n",
      "Epoch 92 | Validation Loss   0.03\n",
      "\tEpoch 93 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 93 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 93 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 93 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 93 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 93 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 93 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 93 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 93 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 93 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 93 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 93 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 93 | Training Loss   0.03\n",
      "Epoch 93 | Validation Loss   0.03\n",
      "\tEpoch 94 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 94 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 94 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 94 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 94 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 94 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 94 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 94 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 94 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 94 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 94 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 94 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 94 | Training Loss   0.03\n",
      "Epoch 94 | Validation Loss   0.03\n",
      "\tEpoch 95 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 95 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 95 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 95 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 95 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 95 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 95 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 95 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 95 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 95 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 95 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 95 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 95 | Training Loss   0.03\n",
      "Epoch 95 | Validation Loss   0.03\n",
      "\tEpoch 96 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 96 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 96 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 96 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 96 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 96 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 96 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 96 | Batch 280 | Training Loss   0.03\n",
      "\tEpoch 96 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 96 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 96 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 96 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 96 | Training Loss   0.03\n",
      "Epoch 96 | Validation Loss   0.03\n",
      "\tEpoch 97 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 97 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 97 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 97 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 97 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 97 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 97 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 97 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 97 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 97 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 97 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 97 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 97 | Training Loss   0.03\n",
      "Epoch 97 | Validation Loss   0.03\n",
      "\tEpoch 98 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 98 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 98 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 98 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 98 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 98 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 98 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 98 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 98 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 98 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 98 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 98 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 98 | Training Loss   0.03\n",
      "Epoch 98 | Validation Loss   0.03\n",
      "\tEpoch 99 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 99 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 99 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 99 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 99 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 99 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 99 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 99 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 99 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 99 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 99 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 99 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 99 | Training Loss   0.03\n",
      "Epoch 99 | Validation Loss   0.03\n",
      "\tEpoch 100 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 100 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 100 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 100 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 100 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 100 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 100 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 100 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 100 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 100 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 100 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 100 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 100 | Training Loss   0.03\n",
      "Epoch 100 | Validation Loss   0.03\n",
      "\tEpoch 101 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 101 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 101 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 101 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 101 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 101 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 101 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 101 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 101 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 101 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 101 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 101 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 101 | Training Loss   0.03\n",
      "Epoch 101 | Validation Loss   0.03\n",
      "\tEpoch 102 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 102 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 102 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 102 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 102 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 102 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 102 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 102 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 102 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 102 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 102 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 102 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 102 | Training Loss   0.03\n",
      "Epoch 102 | Validation Loss   0.03\n",
      "\tEpoch 103 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 103 | Batch 40 | Training Loss   0.03\n",
      "\tEpoch 103 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 103 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 103 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 103 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 103 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 103 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 103 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 103 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 103 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 103 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 103 | Training Loss   0.03\n",
      "Epoch 103 | Validation Loss   0.03\n",
      "\tEpoch 104 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 104 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 104 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 104 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 104 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 104 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 104 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 104 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 104 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 104 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 104 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 104 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 104 | Training Loss   0.03\n",
      "Epoch 104 | Validation Loss   0.03\n",
      "\tEpoch 105 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 105 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 105 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 105 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 105 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 105 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 105 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 105 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 105 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 105 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 105 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 105 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 105 | Training Loss   0.03\n",
      "Epoch 105 | Validation Loss   0.03\n",
      "\tEpoch 106 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 106 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 106 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 106 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 106 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 106 | Batch 200 | Training Loss   0.03\n",
      "\tEpoch 106 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 106 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 106 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 106 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 106 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 106 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 106 | Training Loss   0.03\n",
      "Epoch 106 | Validation Loss   0.03\n",
      "\tEpoch 107 | Batch 0 | Training Loss   0.03\n",
      "\tEpoch 107 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 107 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 107 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 107 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 107 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 107 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 107 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 107 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 107 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 107 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 107 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 107 | Training Loss   0.03\n",
      "Epoch 107 | Validation Loss   0.03\n",
      "\tEpoch 108 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 108 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 108 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 108 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 108 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 108 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 108 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 108 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 108 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 108 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 108 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 108 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 108 | Training Loss   0.03\n",
      "Epoch 108 | Validation Loss   0.03\n",
      "\tEpoch 109 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 109 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 109 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 109 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 109 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 109 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 109 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 109 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 109 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 109 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 109 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 109 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 109 | Training Loss   0.03\n",
      "Epoch 109 | Validation Loss   0.03\n",
      "\tEpoch 110 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 110 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 110 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 110 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 110 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 110 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 110 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 110 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 110 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 110 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 110 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 110 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 110 | Training Loss   0.03\n",
      "Epoch 110 | Validation Loss   0.03\n",
      "\tEpoch 111 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 111 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 111 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 111 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 111 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 111 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 111 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 111 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 111 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 111 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 111 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 111 | Batch 120 | Validation Loss   0.03\n",
      "Epoch 111 | Training Loss   0.03\n",
      "Epoch 111 | Validation Loss   0.03\n",
      "\tEpoch 112 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 112 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 112 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 112 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 112 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 112 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 112 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 112 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 112 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 112 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 112 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 112 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 112 | Training Loss   0.03\n",
      "Epoch 112 | Validation Loss   0.03\n",
      "\tEpoch 113 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 113 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 113 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 113 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 113 | Batch 160 | Training Loss   0.03\n",
      "\tEpoch 113 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 113 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 113 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 113 | Batch 0 | Validation Loss   0.03\n",
      "\tEpoch 113 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 113 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 113 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 113 | Training Loss   0.03\n",
      "Epoch 113 | Validation Loss   0.03\n",
      "\tEpoch 114 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 114 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 114 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 114 | Batch 120 | Training Loss   0.03\n",
      "\tEpoch 114 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 114 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 114 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 114 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 114 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 114 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 114 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 114 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 114 | Training Loss   0.03\n",
      "Epoch 114 | Validation Loss   0.03\n",
      "\tEpoch 115 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 115 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 115 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 115 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 115 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 115 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 115 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 115 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 115 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 115 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 115 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 115 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 115 | Training Loss   0.03\n",
      "Epoch 115 | Validation Loss   0.03\n",
      "\tEpoch 116 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 116 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 116 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 116 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 116 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 116 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 116 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 116 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 116 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 116 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 116 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 116 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 116 | Training Loss   0.03\n",
      "Epoch 116 | Validation Loss   0.03\n",
      "\tEpoch 117 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 117 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 117 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 117 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 117 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 117 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 117 | Batch 240 | Training Loss   0.03\n",
      "\tEpoch 117 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 117 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 117 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 117 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 117 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 117 | Training Loss   0.03\n",
      "Epoch 117 | Validation Loss   0.03\n",
      "\tEpoch 118 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 118 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 118 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 118 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 118 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 118 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 118 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 118 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 118 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 118 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 118 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 118 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 118 | Training Loss   0.03\n",
      "Epoch 118 | Validation Loss   0.03\n",
      "\tEpoch 119 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 119 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 119 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 119 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 119 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 119 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 119 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 119 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 119 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 119 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 119 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 119 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 119 | Training Loss   0.03\n",
      "Epoch 119 | Validation Loss   0.03\n",
      "\tEpoch 120 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 120 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 120 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 120 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 120 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 120 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 120 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 120 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 120 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 120 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 120 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 120 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 120 | Training Loss   0.03\n",
      "Epoch 120 | Validation Loss   0.03\n",
      "\tEpoch 121 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 121 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 121 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 121 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 121 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 121 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 121 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 121 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 121 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 121 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 121 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 121 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 121 | Training Loss   0.03\n",
      "Epoch 121 | Validation Loss   0.03\n",
      "\tEpoch 122 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 122 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 122 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 122 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 122 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 122 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 122 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 122 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 122 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 122 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 122 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 122 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 122 | Training Loss   0.03\n",
      "Epoch 122 | Validation Loss   0.03\n",
      "\tEpoch 123 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 123 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 123 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 123 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 123 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 123 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 123 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 123 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 123 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 123 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 123 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 123 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 123 | Training Loss   0.03\n",
      "Epoch 123 | Validation Loss   0.03\n",
      "\tEpoch 124 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 124 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 124 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 124 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 124 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 124 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 124 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 124 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 124 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 124 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 124 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 124 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 124 | Training Loss   0.03\n",
      "Epoch 124 | Validation Loss   0.03\n",
      "\tEpoch 125 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 125 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 125 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 125 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 125 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 125 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 125 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 125 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 125 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 125 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 125 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 125 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 125 | Training Loss   0.03\n",
      "Epoch 125 | Validation Loss   0.03\n",
      "\tEpoch 126 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 126 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 126 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 126 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 126 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 126 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 126 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 126 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 126 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 126 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 126 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 126 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 126 | Training Loss   0.03\n",
      "Epoch 126 | Validation Loss   0.03\n",
      "\tEpoch 127 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 127 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 127 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 127 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 127 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 127 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 127 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 127 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 127 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 127 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 127 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 127 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 127 | Training Loss   0.03\n",
      "Epoch 127 | Validation Loss   0.03\n",
      "\tEpoch 128 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 128 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 128 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 128 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 128 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 128 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 128 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 128 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 128 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 128 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 128 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 128 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 128 | Training Loss   0.03\n",
      "Epoch 128 | Validation Loss   0.03\n",
      "\tEpoch 129 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 129 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 129 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 129 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 129 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 129 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 129 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 129 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 129 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 129 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 129 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 129 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 129 | Training Loss   0.03\n",
      "Epoch 129 | Validation Loss   0.03\n",
      "\tEpoch 130 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 130 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 130 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 130 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 130 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 130 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 130 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 130 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 130 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 130 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 130 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 130 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 130 | Training Loss   0.03\n",
      "Epoch 130 | Validation Loss   0.03\n",
      "\tEpoch 131 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 131 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 131 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 131 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 131 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 131 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 131 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 131 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 131 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 131 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 131 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 131 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 131 | Training Loss   0.03\n",
      "Epoch 131 | Validation Loss   0.03\n",
      "\tEpoch 132 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 132 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 132 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 132 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 132 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 132 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 132 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 132 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 132 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 132 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 132 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 132 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 132 | Training Loss   0.03\n",
      "Epoch 132 | Validation Loss   0.03\n",
      "\tEpoch 133 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 133 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 133 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 133 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 133 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 133 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 133 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 133 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 133 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 133 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 133 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 133 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 133 | Training Loss   0.03\n",
      "Epoch 133 | Validation Loss   0.03\n",
      "\tEpoch 134 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 134 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 134 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 134 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 134 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 134 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 134 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 134 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 134 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 134 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 134 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 134 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 134 | Training Loss   0.03\n",
      "Epoch 134 | Validation Loss   0.03\n",
      "\tEpoch 135 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 135 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 135 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 135 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 135 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 135 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 135 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 135 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 135 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 135 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 135 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 135 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 135 | Training Loss   0.03\n",
      "Epoch 135 | Validation Loss   0.03\n",
      "\tEpoch 136 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 136 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 136 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 136 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 136 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 136 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 136 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 136 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 136 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 136 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 136 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 136 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 136 | Training Loss   0.03\n",
      "Epoch 136 | Validation Loss   0.03\n",
      "\tEpoch 137 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 137 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 137 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 137 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 137 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 137 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 137 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 137 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 137 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 137 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 137 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 137 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 137 | Training Loss   0.03\n",
      "Epoch 137 | Validation Loss   0.03\n",
      "\tEpoch 138 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 138 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 138 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 138 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 138 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 138 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 138 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 138 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 138 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 138 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 138 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 138 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 138 | Training Loss   0.03\n",
      "Epoch 138 | Validation Loss   0.03\n",
      "\tEpoch 139 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 139 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 139 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 139 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 139 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 139 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 139 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 139 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 139 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 139 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 139 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 139 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 139 | Training Loss   0.03\n",
      "Epoch 139 | Validation Loss   0.03\n",
      "\tEpoch 140 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 140 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 140 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 140 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 140 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 140 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 140 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 140 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 140 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 140 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 140 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 140 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 140 | Training Loss   0.03\n",
      "Epoch 140 | Validation Loss   0.03\n",
      "\tEpoch 141 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 141 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 141 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 141 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 141 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 141 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 141 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 141 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 141 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 141 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 141 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 141 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 141 | Training Loss   0.03\n",
      "Epoch 141 | Validation Loss   0.03\n",
      "\tEpoch 142 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 142 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 142 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 142 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 142 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 142 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 142 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 142 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 142 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 142 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 142 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 142 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 142 | Training Loss   0.03\n",
      "Epoch 142 | Validation Loss   0.03\n",
      "\tEpoch 143 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 143 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 143 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 143 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 143 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 143 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 143 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 143 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 143 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 143 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 143 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 143 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 143 | Training Loss   0.03\n",
      "Epoch 143 | Validation Loss   0.03\n",
      "\tEpoch 144 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 144 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 144 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 144 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 144 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 144 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 144 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 144 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 144 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 144 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 144 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 144 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 144 | Training Loss   0.03\n",
      "Epoch 144 | Validation Loss   0.03\n",
      "\tEpoch 145 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 145 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 145 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 145 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 145 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 145 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 145 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 145 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 145 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 145 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 145 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 145 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 145 | Training Loss   0.03\n",
      "Epoch 145 | Validation Loss   0.03\n",
      "\tEpoch 146 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 146 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 146 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 146 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 146 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 146 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 146 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 146 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 146 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 146 | Batch 40 | Validation Loss   0.02\n",
      "\tEpoch 146 | Batch 80 | Validation Loss   0.02\n",
      "\tEpoch 146 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 146 | Training Loss   0.03\n",
      "Epoch 146 | Validation Loss   0.03\n",
      "\tEpoch 147 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 147 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 147 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 147 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 147 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 147 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 147 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 147 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 147 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 147 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 147 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 147 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 147 | Training Loss   0.03\n",
      "Epoch 147 | Validation Loss   0.03\n",
      "\tEpoch 148 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 148 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 148 | Batch 80 | Training Loss   0.02\n",
      "\tEpoch 148 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 148 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 148 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 148 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 148 | Batch 280 | Training Loss   0.02\n",
      "\tEpoch 148 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 148 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 148 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 148 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 148 | Training Loss   0.03\n",
      "Epoch 148 | Validation Loss   0.03\n",
      "\tEpoch 149 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 149 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 149 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 149 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 149 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 149 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 149 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 149 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 149 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 149 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 149 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 149 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 149 | Training Loss   0.03\n",
      "Epoch 149 | Validation Loss   0.03\n",
      "\tEpoch 150 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 150 | Batch 40 | Training Loss   0.02\n",
      "\tEpoch 150 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 150 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 150 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 150 | Batch 200 | Training Loss   0.02\n",
      "\tEpoch 150 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 150 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 150 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 150 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 150 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 150 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 150 | Training Loss   0.03\n",
      "Epoch 150 | Validation Loss   0.03\n",
      "\tEpoch 151 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 151 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 151 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 151 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 151 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 151 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 151 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 151 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 151 | Batch 0 | Validation Loss   0.02\n",
      "\tEpoch 151 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 151 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 151 | Batch 120 | Validation Loss   0.02\n",
      "Epoch 151 | Training Loss   0.03\n",
      "Epoch 151 | Validation Loss   0.03\n",
      "\tEpoch 152 | Batch 0 | Training Loss   0.02\n",
      "\tEpoch 152 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 152 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 152 | Batch 120 | Training Loss   0.02\n",
      "\tEpoch 152 | Batch 160 | Training Loss   0.02\n",
      "\tEpoch 152 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 152 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 152 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 152 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 152 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 152 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 152 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 152 | Training Loss   0.03\n",
      "Epoch 152 | Validation Loss   0.03\n",
      "\tEpoch 153 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 153 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 153 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 153 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 153 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 153 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 153 | Batch 240 | Training Loss   0.02\n",
      "\tEpoch 153 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 153 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 153 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 153 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 153 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 153 | Training Loss   0.03\n",
      "Epoch 153 | Validation Loss   0.03\n",
      "\tEpoch 154 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 154 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 154 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 154 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 154 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 154 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 154 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 154 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 154 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 154 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 154 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 154 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 154 | Training Loss   0.03\n",
      "Epoch 154 | Validation Loss   0.03\n",
      "\tEpoch 155 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 155 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 155 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 155 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 155 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 155 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 155 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 155 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 155 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 155 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 155 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 155 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 155 | Training Loss   0.03\n",
      "Epoch 155 | Validation Loss   0.03\n",
      "\tEpoch 156 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 156 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 156 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 156 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 156 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 156 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 156 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 156 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 156 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 156 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 156 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 156 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 156 | Training Loss   0.03\n",
      "Epoch 156 | Validation Loss   0.03\n",
      "\tEpoch 157 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 157 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 157 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 157 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 157 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 157 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 157 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 157 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 157 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 157 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 157 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 157 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 157 | Training Loss   0.03\n",
      "Epoch 157 | Validation Loss   0.03\n",
      "\tEpoch 158 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 158 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 158 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 158 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 158 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 158 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 158 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 158 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 158 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 158 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 158 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 158 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 158 | Training Loss   0.03\n",
      "Epoch 158 | Validation Loss   0.03\n",
      "\tEpoch 159 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 159 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 159 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 159 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 159 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 159 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 159 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 159 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 159 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 159 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 159 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 159 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 159 | Training Loss   0.03\n",
      "Epoch 159 | Validation Loss   0.03\n",
      "\tEpoch 160 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 160 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 160 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 160 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 160 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 160 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 160 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 160 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 160 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 160 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 160 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 160 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 160 | Training Loss   0.03\n",
      "Epoch 160 | Validation Loss   0.03\n",
      "\tEpoch 161 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 161 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 161 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 161 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 161 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 161 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 161 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 161 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 161 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 161 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 161 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 161 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 161 | Training Loss   0.03\n",
      "Epoch 161 | Validation Loss   0.03\n",
      "\tEpoch 162 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 162 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 162 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 162 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 162 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 162 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 162 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 162 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 162 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 162 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 162 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 162 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 162 | Training Loss   0.03\n",
      "Epoch 162 | Validation Loss   0.03\n",
      "\tEpoch 163 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 163 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 163 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 163 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 163 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 163 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 163 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 163 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 163 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 163 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 163 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 163 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 163 | Training Loss   0.03\n",
      "Epoch 163 | Validation Loss   0.03\n",
      "\tEpoch 164 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 164 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 164 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 164 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 164 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 164 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 164 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 164 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 164 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 164 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 164 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 164 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 164 | Training Loss   0.03\n",
      "Epoch 164 | Validation Loss   0.03\n",
      "\tEpoch 165 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 165 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 165 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 165 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 165 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 165 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 165 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 165 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 165 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 165 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 165 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 165 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 165 | Training Loss   0.03\n",
      "Epoch 165 | Validation Loss   0.03\n",
      "\tEpoch 166 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 166 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 166 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 166 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 166 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 166 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 166 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 166 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 166 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 166 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 166 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 166 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 166 | Training Loss   0.03\n",
      "Epoch 166 | Validation Loss   0.03\n",
      "\tEpoch 167 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 167 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 167 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 167 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 167 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 167 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 167 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 167 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 167 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 167 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 167 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 167 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 167 | Training Loss   0.03\n",
      "Epoch 167 | Validation Loss   0.03\n",
      "\tEpoch 168 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 168 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 168 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 168 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 168 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 168 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 168 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 168 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 168 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 168 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 168 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 168 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 168 | Training Loss   0.03\n",
      "Epoch 168 | Validation Loss   0.03\n",
      "\tEpoch 169 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 169 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 169 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 169 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 169 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 169 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 169 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 169 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 169 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 169 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 169 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 169 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 169 | Training Loss   0.03\n",
      "Epoch 169 | Validation Loss   0.03\n",
      "\tEpoch 170 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 170 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 170 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 170 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 170 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 170 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 170 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 170 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 170 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 170 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 170 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 170 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 170 | Training Loss   0.03\n",
      "Epoch 170 | Validation Loss   0.03\n",
      "\tEpoch 171 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 171 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 171 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 171 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 171 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 171 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 171 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 171 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 171 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 171 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 171 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 171 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 171 | Training Loss   0.03\n",
      "Epoch 171 | Validation Loss   0.03\n",
      "\tEpoch 172 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 172 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 172 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 172 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 172 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 172 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 172 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 172 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 172 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 172 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 172 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 172 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 172 | Training Loss   0.03\n",
      "Epoch 172 | Validation Loss   0.03\n",
      "\tEpoch 173 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 173 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 173 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 173 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 173 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 173 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 173 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 173 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 173 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 173 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 173 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 173 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 173 | Training Loss   0.03\n",
      "Epoch 173 | Validation Loss   0.03\n",
      "\tEpoch 174 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 174 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 174 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 174 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 174 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 174 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 174 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 174 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 174 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 174 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 174 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 174 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 174 | Training Loss   0.03\n",
      "Epoch 174 | Validation Loss   0.02\n",
      "\tEpoch 175 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 175 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 175 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 175 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 175 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 175 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 175 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 175 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 175 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 175 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 175 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 175 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 175 | Training Loss   0.02\n",
      "Epoch 175 | Validation Loss   0.02\n",
      "\tEpoch 176 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 176 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 176 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 176 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 176 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 176 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 176 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 176 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 176 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 176 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 176 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 176 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 176 | Training Loss   0.02\n",
      "Epoch 176 | Validation Loss   0.02\n",
      "\tEpoch 177 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 177 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 177 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 177 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 177 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 177 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 177 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 177 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 177 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 177 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 177 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 177 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 177 | Training Loss   0.02\n",
      "Epoch 177 | Validation Loss   0.02\n",
      "\tEpoch 178 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 178 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 178 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 178 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 178 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 178 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 178 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 178 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 178 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 178 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 178 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 178 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 178 | Training Loss   0.02\n",
      "Epoch 178 | Validation Loss   0.02\n",
      "\tEpoch 179 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 179 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 179 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 179 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 179 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 179 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 179 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 179 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 179 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 179 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 179 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 179 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 179 | Training Loss   0.02\n",
      "Epoch 179 | Validation Loss   0.02\n",
      "\tEpoch 180 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 180 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 180 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 180 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 180 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 180 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 180 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 180 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 180 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 180 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 180 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 180 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 180 | Training Loss   0.02\n",
      "Epoch 180 | Validation Loss   0.02\n",
      "\tEpoch 181 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 181 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 181 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 181 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 181 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 181 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 181 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 181 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 181 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 181 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 181 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 181 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 181 | Training Loss   0.02\n",
      "Epoch 181 | Validation Loss   0.02\n",
      "\tEpoch 182 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 182 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 182 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 182 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 182 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 182 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 182 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 182 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 182 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 182 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 182 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 182 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 182 | Training Loss   0.02\n",
      "Epoch 182 | Validation Loss   0.02\n",
      "\tEpoch 183 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 183 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 183 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 183 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 183 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 183 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 183 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 183 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 183 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 183 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 183 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 183 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 183 | Training Loss   0.02\n",
      "Epoch 183 | Validation Loss   0.02\n",
      "\tEpoch 184 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 184 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 184 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 184 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 184 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 184 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 184 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 184 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 184 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 184 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 184 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 184 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 184 | Training Loss   0.02\n",
      "Epoch 184 | Validation Loss   0.02\n",
      "\tEpoch 185 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 185 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 185 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 185 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 185 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 185 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 185 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 185 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 185 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 185 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 185 | Batch 80 | Validation Loss   0.01\n",
      "\tEpoch 185 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 185 | Training Loss   0.02\n",
      "Epoch 185 | Validation Loss   0.02\n",
      "\tEpoch 186 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 186 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 186 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 186 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 186 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 186 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 186 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 186 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 186 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 186 | Batch 40 | Validation Loss   0.01\n",
      "\tEpoch 186 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 186 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 186 | Training Loss   0.02\n",
      "Epoch 186 | Validation Loss   0.02\n",
      "\tEpoch 187 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 187 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 187 | Batch 80 | Training Loss   0.01\n",
      "\tEpoch 187 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 187 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 187 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 187 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 187 | Batch 280 | Training Loss   0.01\n",
      "\tEpoch 187 | Batch 0 | Validation Loss   0.01\n",
      "\tEpoch 187 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 187 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 187 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 187 | Training Loss   0.02\n",
      "Epoch 187 | Validation Loss   0.02\n",
      "\tEpoch 188 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 188 | Batch 40 | Training Loss   0.01\n",
      "\tEpoch 188 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 188 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 188 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 188 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 188 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 188 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 188 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 188 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 188 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 188 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 188 | Training Loss   0.02\n",
      "Epoch 188 | Validation Loss   0.02\n",
      "\tEpoch 189 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 189 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 189 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 189 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 189 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 189 | Batch 200 | Training Loss   0.01\n",
      "\tEpoch 189 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 189 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 189 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 189 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 189 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 189 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 189 | Training Loss   0.02\n",
      "Epoch 189 | Validation Loss   0.02\n",
      "\tEpoch 190 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 190 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 190 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 190 | Batch 120 | Training Loss   0.01\n",
      "\tEpoch 190 | Batch 160 | Training Loss   0.01\n",
      "\tEpoch 190 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 190 | Batch 240 | Training Loss   0.01\n",
      "\tEpoch 190 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 190 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 190 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 190 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 190 | Batch 120 | Validation Loss   0.01\n",
      "Epoch 190 | Training Loss   0.02\n",
      "Epoch 190 | Validation Loss   0.02\n",
      "\tEpoch 191 | Batch 0 | Training Loss   0.01\n",
      "\tEpoch 191 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 191 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 191 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 191 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 191 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 191 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 191 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 191 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 191 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 191 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 191 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 191 | Training Loss   0.02\n",
      "Epoch 191 | Validation Loss   0.02\n",
      "\tEpoch 192 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 192 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 192 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 192 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 192 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 192 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 192 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 192 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 192 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 192 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 192 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 192 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 192 | Training Loss   0.02\n",
      "Epoch 192 | Validation Loss   0.02\n",
      "\tEpoch 193 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 193 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 193 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 193 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 193 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 193 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 193 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 193 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 193 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 193 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 193 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 193 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 193 | Training Loss   0.02\n",
      "Epoch 193 | Validation Loss   0.02\n",
      "\tEpoch 194 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 194 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 194 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 194 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 194 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 194 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 194 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 194 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 194 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 194 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 194 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 194 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 194 | Training Loss   0.02\n",
      "Epoch 194 | Validation Loss   0.02\n",
      "\tEpoch 195 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 195 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 195 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 195 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 195 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 195 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 195 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 195 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 195 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 195 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 195 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 195 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 195 | Training Loss   0.02\n",
      "Epoch 195 | Validation Loss   0.02\n",
      "\tEpoch 196 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 196 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 196 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 196 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 196 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 196 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 196 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 196 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 196 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 196 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 196 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 196 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 196 | Training Loss   0.02\n",
      "Epoch 196 | Validation Loss   0.02\n",
      "\tEpoch 197 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 197 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 197 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 197 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 197 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 197 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 197 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 197 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 197 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 197 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 197 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 197 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 197 | Training Loss   0.02\n",
      "Epoch 197 | Validation Loss   0.02\n",
      "\tEpoch 198 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 198 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 198 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 198 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 198 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 198 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 198 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 198 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 198 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 198 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 198 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 198 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 198 | Training Loss   0.02\n",
      "Epoch 198 | Validation Loss   0.02\n",
      "\tEpoch 199 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 199 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 199 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 199 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 199 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 199 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 199 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 199 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 199 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 199 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 199 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 199 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 199 | Training Loss   0.02\n",
      "Epoch 199 | Validation Loss   0.02\n",
      "\tEpoch 200 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 200 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 200 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 200 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 200 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 200 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 200 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 200 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 200 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 200 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 200 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 200 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 200 | Training Loss   0.02\n",
      "Epoch 200 | Validation Loss   0.02\n",
      "\tEpoch 201 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 201 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 201 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 201 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 201 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 201 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 201 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 201 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 201 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 201 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 201 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 201 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 201 | Training Loss   0.02\n",
      "Epoch 201 | Validation Loss   0.02\n",
      "\tEpoch 202 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 202 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 202 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 202 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 202 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 202 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 202 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 202 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 202 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 202 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 202 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 202 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 202 | Training Loss   0.02\n",
      "Epoch 202 | Validation Loss   0.02\n",
      "\tEpoch 203 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 203 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 203 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 203 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 203 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 203 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 203 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 203 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 203 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 203 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 203 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 203 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 203 | Training Loss   0.02\n",
      "Epoch 203 | Validation Loss   0.02\n",
      "\tEpoch 204 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 204 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 204 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 204 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 204 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 204 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 204 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 204 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 204 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 204 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 204 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 204 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 204 | Training Loss   0.02\n",
      "Epoch 204 | Validation Loss   0.02\n",
      "\tEpoch 205 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 205 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 205 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 205 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 205 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 205 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 205 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 205 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 205 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 205 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 205 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 205 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 205 | Training Loss   0.02\n",
      "Epoch 205 | Validation Loss   0.02\n",
      "\tEpoch 206 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 206 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 206 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 206 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 206 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 206 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 206 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 206 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 206 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 206 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 206 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 206 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 206 | Training Loss   0.02\n",
      "Epoch 206 | Validation Loss   0.02\n",
      "\tEpoch 207 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 207 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 207 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 207 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 207 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 207 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 207 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 207 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 207 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 207 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 207 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 207 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 207 | Training Loss   0.02\n",
      "Epoch 207 | Validation Loss   0.02\n",
      "\tEpoch 208 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 208 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 208 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 208 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 208 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 208 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 208 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 208 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 208 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 208 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 208 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 208 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 208 | Training Loss   0.02\n",
      "Epoch 208 | Validation Loss   0.02\n",
      "\tEpoch 209 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 209 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 209 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 209 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 209 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 209 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 209 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 209 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 209 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 209 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 209 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 209 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 209 | Training Loss   0.02\n",
      "Epoch 209 | Validation Loss   0.02\n",
      "\tEpoch 210 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 210 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 210 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 210 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 210 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 210 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 210 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 210 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 210 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 210 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 210 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 210 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 210 | Training Loss   0.02\n",
      "Epoch 210 | Validation Loss   0.02\n",
      "\tEpoch 211 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 211 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 211 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 211 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 211 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 211 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 211 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 211 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 211 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 211 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 211 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 211 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 211 | Training Loss   0.02\n",
      "Epoch 211 | Validation Loss   0.02\n",
      "\tEpoch 212 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 212 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 212 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 212 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 212 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 212 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 212 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 212 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 212 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 212 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 212 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 212 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 212 | Training Loss   0.02\n",
      "Epoch 212 | Validation Loss   0.02\n",
      "\tEpoch 213 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 213 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 213 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 213 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 213 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 213 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 213 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 213 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 213 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 213 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 213 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 213 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 213 | Training Loss   0.02\n",
      "Epoch 213 | Validation Loss   0.02\n",
      "\tEpoch 214 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 214 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 214 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 214 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 214 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 214 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 214 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 214 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 214 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 214 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 214 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 214 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 214 | Training Loss   0.02\n",
      "Epoch 214 | Validation Loss   0.02\n",
      "\tEpoch 215 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 215 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 215 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 215 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 215 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 215 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 215 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 215 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 215 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 215 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 215 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 215 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 215 | Training Loss   0.02\n",
      "Epoch 215 | Validation Loss   0.02\n",
      "\tEpoch 216 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 216 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 216 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 216 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 216 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 216 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 216 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 216 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 216 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 216 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 216 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 216 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 216 | Training Loss   0.02\n",
      "Epoch 216 | Validation Loss   0.02\n",
      "\tEpoch 217 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 217 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 217 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 217 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 217 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 217 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 217 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 217 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 217 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 217 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 217 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 217 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 217 | Training Loss   0.02\n",
      "Epoch 217 | Validation Loss   0.02\n",
      "\tEpoch 218 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 218 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 218 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 218 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 218 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 218 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 218 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 218 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 218 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 218 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 218 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 218 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 218 | Training Loss   0.02\n",
      "Epoch 218 | Validation Loss   0.02\n",
      "\tEpoch 219 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 219 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 219 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 219 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 219 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 219 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 219 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 219 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 219 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 219 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 219 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 219 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 219 | Training Loss   0.02\n",
      "Epoch 219 | Validation Loss   0.02\n",
      "\tEpoch 220 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 220 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 220 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 220 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 220 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 220 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 220 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 220 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 220 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 220 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 220 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 220 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 220 | Training Loss   0.02\n",
      "Epoch 220 | Validation Loss   0.02\n",
      "\tEpoch 221 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 221 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 221 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 221 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 221 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 221 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 221 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 221 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 221 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 221 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 221 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 221 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 221 | Training Loss   0.02\n",
      "Epoch 221 | Validation Loss   0.02\n",
      "\tEpoch 222 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 222 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 222 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 222 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 222 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 222 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 222 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 222 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 222 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 222 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 222 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 222 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 222 | Training Loss   0.02\n",
      "Epoch 222 | Validation Loss   0.02\n",
      "\tEpoch 223 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 223 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 223 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 223 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 223 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 223 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 223 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 223 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 223 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 223 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 223 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 223 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 223 | Training Loss   0.02\n",
      "Epoch 223 | Validation Loss   0.02\n",
      "\tEpoch 224 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 224 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 224 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 224 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 224 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 224 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 224 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 224 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 224 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 224 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 224 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 224 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 224 | Training Loss   0.02\n",
      "Epoch 224 | Validation Loss   0.02\n",
      "\tEpoch 225 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 225 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 225 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 225 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 225 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 225 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 225 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 225 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 225 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 225 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 225 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 225 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 225 | Training Loss   0.02\n",
      "Epoch 225 | Validation Loss   0.02\n",
      "\tEpoch 226 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 226 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 226 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 226 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 226 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 226 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 226 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 226 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 226 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 226 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 226 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 226 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 226 | Training Loss   0.02\n",
      "Epoch 226 | Validation Loss   0.02\n",
      "\tEpoch 227 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 227 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 227 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 227 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 227 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 227 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 227 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 227 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 227 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 227 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 227 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 227 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 227 | Training Loss   0.02\n",
      "Epoch 227 | Validation Loss   0.02\n",
      "\tEpoch 228 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 228 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 228 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 228 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 228 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 228 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 228 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 228 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 228 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 228 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 228 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 228 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 228 | Training Loss   0.02\n",
      "Epoch 228 | Validation Loss   0.02\n",
      "\tEpoch 229 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 229 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 229 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 229 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 229 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 229 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 229 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 229 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 229 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 229 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 229 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 229 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 229 | Training Loss   0.02\n",
      "Epoch 229 | Validation Loss   0.02\n",
      "\tEpoch 230 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 230 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 230 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 230 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 230 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 230 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 230 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 230 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 230 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 230 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 230 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 230 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 230 | Training Loss   0.02\n",
      "Epoch 230 | Validation Loss   0.02\n",
      "\tEpoch 231 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 231 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 231 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 231 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 231 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 231 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 231 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 231 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 231 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 231 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 231 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 231 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 231 | Training Loss   0.02\n",
      "Epoch 231 | Validation Loss   0.02\n",
      "\tEpoch 232 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 232 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 232 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 232 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 232 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 232 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 232 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 232 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 232 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 232 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 232 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 232 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 232 | Training Loss   0.02\n",
      "Epoch 232 | Validation Loss   0.02\n",
      "\tEpoch 233 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 233 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 233 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 233 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 233 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 233 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 233 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 233 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 233 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 233 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 233 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 233 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 233 | Training Loss   0.02\n",
      "Epoch 233 | Validation Loss   0.02\n",
      "\tEpoch 234 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 234 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 234 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 234 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 234 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 234 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 234 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 234 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 234 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 234 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 234 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 234 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 234 | Training Loss   0.02\n",
      "Epoch 234 | Validation Loss   0.02\n",
      "\tEpoch 235 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 235 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 235 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 235 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 235 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 235 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 235 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 235 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 235 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 235 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 235 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 235 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 235 | Training Loss   0.02\n",
      "Epoch 235 | Validation Loss   0.02\n",
      "\tEpoch 236 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 236 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 236 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 236 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 236 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 236 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 236 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 236 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 236 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 236 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 236 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 236 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 236 | Training Loss   0.02\n",
      "Epoch 236 | Validation Loss   0.02\n",
      "\tEpoch 237 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 237 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 237 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 237 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 237 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 237 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 237 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 237 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 237 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 237 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 237 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 237 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 237 | Training Loss   0.02\n",
      "Epoch 237 | Validation Loss   0.02\n",
      "\tEpoch 238 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 238 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 238 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 238 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 238 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 238 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 238 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 238 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 238 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 238 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 238 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 238 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 238 | Training Loss   0.02\n",
      "Epoch 238 | Validation Loss   0.02\n",
      "\tEpoch 239 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 239 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 239 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 239 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 239 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 239 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 239 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 239 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 239 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 239 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 239 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 239 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 239 | Training Loss   0.02\n",
      "Epoch 239 | Validation Loss   0.02\n",
      "\tEpoch 240 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 240 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 240 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 240 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 240 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 240 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 240 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 240 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 240 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 240 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 240 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 240 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 240 | Training Loss   0.02\n",
      "Epoch 240 | Validation Loss   0.02\n",
      "\tEpoch 241 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 241 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 241 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 241 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 241 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 241 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 241 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 241 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 241 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 241 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 241 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 241 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 241 | Training Loss   0.02\n",
      "Epoch 241 | Validation Loss   0.02\n",
      "\tEpoch 242 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 242 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 242 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 242 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 242 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 242 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 242 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 242 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 242 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 242 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 242 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 242 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 242 | Training Loss   0.02\n",
      "Epoch 242 | Validation Loss   0.02\n",
      "\tEpoch 243 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 243 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 243 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 243 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 243 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 243 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 243 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 243 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 243 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 243 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 243 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 243 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 243 | Training Loss   0.02\n",
      "Epoch 243 | Validation Loss   0.02\n",
      "\tEpoch 244 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 244 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 244 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 244 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 244 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 244 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 244 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 244 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 244 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 244 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 244 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 244 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 244 | Training Loss   0.02\n",
      "Epoch 244 | Validation Loss   0.02\n",
      "\tEpoch 245 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 245 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 245 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 245 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 245 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 245 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 245 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 245 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 245 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 245 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 245 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 245 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 245 | Training Loss   0.02\n",
      "Epoch 245 | Validation Loss   0.02\n",
      "\tEpoch 246 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 246 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 246 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 246 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 246 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 246 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 246 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 246 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 246 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 246 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 246 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 246 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 246 | Training Loss   0.02\n",
      "Epoch 246 | Validation Loss   0.02\n",
      "\tEpoch 247 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 247 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 247 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 247 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 247 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 247 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 247 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 247 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 247 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 247 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 247 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 247 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 247 | Training Loss   0.02\n",
      "Epoch 247 | Validation Loss   0.02\n",
      "\tEpoch 248 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 248 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 248 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 248 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 248 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 248 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 248 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 248 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 248 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 248 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 248 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 248 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 248 | Training Loss   0.02\n",
      "Epoch 248 | Validation Loss   0.02\n",
      "\tEpoch 249 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 249 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 249 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 249 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 249 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 249 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 249 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 249 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 249 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 249 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 249 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 249 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 249 | Training Loss   0.02\n",
      "Epoch 249 | Validation Loss   0.02\n",
      "\tEpoch 250 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 250 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 250 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 250 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 250 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 250 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 250 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 250 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 250 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 250 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 250 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 250 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 250 | Training Loss   0.02\n",
      "Epoch 250 | Validation Loss   0.02\n",
      "\tEpoch 251 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 251 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 251 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 251 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 251 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 251 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 251 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 251 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 251 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 251 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 251 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 251 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 251 | Training Loss   0.02\n",
      "Epoch 251 | Validation Loss   0.02\n",
      "\tEpoch 252 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 252 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 252 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 252 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 252 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 252 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 252 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 252 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 252 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 252 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 252 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 252 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 252 | Training Loss   0.02\n",
      "Epoch 252 | Validation Loss   0.02\n",
      "\tEpoch 253 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 253 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 253 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 253 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 253 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 253 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 253 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 253 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 253 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 253 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 253 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 253 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 253 | Training Loss   0.02\n",
      "Epoch 253 | Validation Loss   0.02\n",
      "\tEpoch 254 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 254 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 254 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 254 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 254 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 254 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 254 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 254 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 254 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 254 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 254 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 254 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 254 | Training Loss   0.02\n",
      "Epoch 254 | Validation Loss   0.02\n",
      "\tEpoch 255 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 255 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 255 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 255 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 255 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 255 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 255 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 255 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 255 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 255 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 255 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 255 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 255 | Training Loss   0.02\n",
      "Epoch 255 | Validation Loss   0.02\n",
      "\tEpoch 256 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 256 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 256 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 256 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 256 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 256 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 256 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 256 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 256 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 256 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 256 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 256 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 256 | Training Loss   0.02\n",
      "Epoch 256 | Validation Loss   0.02\n",
      "\tEpoch 257 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 257 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 257 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 257 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 257 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 257 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 257 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 257 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 257 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 257 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 257 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 257 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 257 | Training Loss   0.02\n",
      "Epoch 257 | Validation Loss   0.02\n",
      "\tEpoch 258 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 258 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 258 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 258 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 258 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 258 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 258 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 258 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 258 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 258 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 258 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 258 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 258 | Training Loss   0.02\n",
      "Epoch 258 | Validation Loss   0.02\n",
      "\tEpoch 259 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 259 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 259 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 259 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 259 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 259 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 259 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 259 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 259 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 259 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 259 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 259 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 259 | Training Loss   0.02\n",
      "Epoch 259 | Validation Loss   0.02\n",
      "\tEpoch 260 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 260 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 260 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 260 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 260 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 260 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 260 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 260 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 260 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 260 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 260 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 260 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 260 | Training Loss   0.02\n",
      "Epoch 260 | Validation Loss   0.02\n",
      "\tEpoch 261 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 261 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 261 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 261 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 261 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 261 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 261 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 261 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 261 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 261 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 261 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 261 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 261 | Training Loss   0.02\n",
      "Epoch 261 | Validation Loss   0.02\n",
      "\tEpoch 262 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 262 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 262 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 262 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 262 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 262 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 262 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 262 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 262 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 262 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 262 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 262 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 262 | Training Loss   0.02\n",
      "Epoch 262 | Validation Loss   0.02\n",
      "\tEpoch 263 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 263 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 263 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 263 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 263 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 263 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 263 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 263 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 263 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 263 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 263 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 263 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 263 | Training Loss   0.02\n",
      "Epoch 263 | Validation Loss   0.02\n",
      "\tEpoch 264 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 264 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 264 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 264 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 264 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 264 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 264 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 264 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 264 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 264 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 264 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 264 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 264 | Training Loss   0.02\n",
      "Epoch 264 | Validation Loss   0.02\n",
      "\tEpoch 265 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 265 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 265 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 265 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 265 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 265 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 265 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 265 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 265 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 265 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 265 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 265 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 265 | Training Loss   0.02\n",
      "Epoch 265 | Validation Loss   0.02\n",
      "\tEpoch 266 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 266 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 266 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 266 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 266 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 266 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 266 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 266 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 266 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 266 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 266 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 266 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 266 | Training Loss   0.02\n",
      "Epoch 266 | Validation Loss   0.02\n",
      "\tEpoch 267 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 267 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 267 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 267 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 267 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 267 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 267 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 267 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 267 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 267 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 267 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 267 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 267 | Training Loss   0.02\n",
      "Epoch 267 | Validation Loss   0.02\n",
      "\tEpoch 268 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 268 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 268 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 268 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 268 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 268 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 268 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 268 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 268 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 268 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 268 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 268 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 268 | Training Loss   0.02\n",
      "Epoch 268 | Validation Loss   0.02\n",
      "\tEpoch 269 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 269 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 269 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 269 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 269 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 269 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 269 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 269 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 269 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 269 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 269 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 269 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 269 | Training Loss   0.02\n",
      "Epoch 269 | Validation Loss   0.02\n",
      "\tEpoch 270 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 270 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 270 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 270 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 270 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 270 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 270 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 270 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 270 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 270 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 270 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 270 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 270 | Training Loss   0.02\n",
      "Epoch 270 | Validation Loss   0.02\n",
      "\tEpoch 271 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 271 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 271 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 271 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 271 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 271 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 271 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 271 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 271 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 271 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 271 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 271 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 271 | Training Loss   0.02\n",
      "Epoch 271 | Validation Loss   0.02\n",
      "\tEpoch 272 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 272 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 272 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 272 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 272 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 272 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 272 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 272 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 272 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 272 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 272 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 272 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 272 | Training Loss   0.02\n",
      "Epoch 272 | Validation Loss   0.02\n",
      "\tEpoch 273 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 273 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 273 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 273 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 273 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 273 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 273 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 273 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 273 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 273 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 273 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 273 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 273 | Training Loss   0.02\n",
      "Epoch 273 | Validation Loss   0.02\n",
      "\tEpoch 274 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 274 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 274 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 274 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 274 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 274 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 274 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 274 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 274 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 274 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 274 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 274 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 274 | Training Loss   0.02\n",
      "Epoch 274 | Validation Loss   0.02\n",
      "\tEpoch 275 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 275 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 275 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 275 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 275 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 275 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 275 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 275 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 275 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 275 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 275 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 275 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 275 | Training Loss   0.02\n",
      "Epoch 275 | Validation Loss   0.02\n",
      "\tEpoch 276 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 276 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 276 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 276 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 276 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 276 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 276 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 276 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 276 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 276 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 276 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 276 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 276 | Training Loss   0.02\n",
      "Epoch 276 | Validation Loss   0.02\n",
      "\tEpoch 277 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 277 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 277 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 277 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 277 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 277 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 277 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 277 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 277 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 277 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 277 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 277 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 277 | Training Loss   0.02\n",
      "Epoch 277 | Validation Loss   0.02\n",
      "\tEpoch 278 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 278 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 278 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 278 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 278 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 278 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 278 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 278 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 278 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 278 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 278 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 278 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 278 | Training Loss   0.02\n",
      "Epoch 278 | Validation Loss   0.02\n",
      "\tEpoch 279 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 279 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 279 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 279 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 279 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 279 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 279 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 279 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 279 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 279 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 279 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 279 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 279 | Training Loss   0.02\n",
      "Epoch 279 | Validation Loss   0.02\n",
      "\tEpoch 280 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 280 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 280 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 280 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 280 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 280 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 280 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 280 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 280 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 280 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 280 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 280 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 280 | Training Loss   0.02\n",
      "Epoch 280 | Validation Loss   0.02\n",
      "\tEpoch 281 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 281 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 281 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 281 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 281 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 281 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 281 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 281 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 281 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 281 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 281 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 281 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 281 | Training Loss   0.02\n",
      "Epoch 281 | Validation Loss   0.02\n",
      "\tEpoch 282 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 282 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 282 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 282 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 282 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 282 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 282 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 282 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 282 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 282 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 282 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 282 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 282 | Training Loss   0.02\n",
      "Epoch 282 | Validation Loss   0.02\n",
      "\tEpoch 283 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 283 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 283 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 283 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 283 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 283 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 283 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 283 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 283 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 283 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 283 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 283 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 283 | Training Loss   0.02\n",
      "Epoch 283 | Validation Loss   0.02\n",
      "\tEpoch 284 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 284 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 284 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 284 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 284 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 284 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 284 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 284 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 284 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 284 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 284 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 284 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 284 | Training Loss   0.02\n",
      "Epoch 284 | Validation Loss   0.02\n",
      "\tEpoch 285 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 285 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 285 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 285 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 285 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 285 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 285 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 285 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 285 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 285 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 285 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 285 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 285 | Training Loss   0.02\n",
      "Epoch 285 | Validation Loss   0.02\n",
      "\tEpoch 286 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 286 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 286 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 286 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 286 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 286 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 286 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 286 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 286 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 286 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 286 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 286 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 286 | Training Loss   0.02\n",
      "Epoch 286 | Validation Loss   0.02\n",
      "\tEpoch 287 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 287 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 287 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 287 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 287 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 287 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 287 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 287 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 287 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 287 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 287 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 287 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 287 | Training Loss   0.02\n",
      "Epoch 287 | Validation Loss   0.02\n",
      "\tEpoch 288 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 288 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 288 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 288 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 288 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 288 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 288 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 288 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 288 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 288 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 288 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 288 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 288 | Training Loss   0.02\n",
      "Epoch 288 | Validation Loss   0.02\n",
      "\tEpoch 289 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 289 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 289 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 289 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 289 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 289 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 289 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 289 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 289 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 289 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 289 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 289 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 289 | Training Loss   0.02\n",
      "Epoch 289 | Validation Loss   0.02\n",
      "\tEpoch 290 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 290 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 290 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 290 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 290 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 290 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 290 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 290 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 290 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 290 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 290 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 290 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 290 | Training Loss   0.02\n",
      "Epoch 290 | Validation Loss   0.02\n",
      "\tEpoch 291 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 291 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 291 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 291 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 291 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 291 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 291 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 291 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 291 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 291 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 291 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 291 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 291 | Training Loss   0.02\n",
      "Epoch 291 | Validation Loss   0.02\n",
      "\tEpoch 292 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 292 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 292 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 292 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 292 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 292 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 292 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 292 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 292 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 292 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 292 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 292 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 292 | Training Loss   0.02\n",
      "Epoch 292 | Validation Loss   0.02\n",
      "\tEpoch 293 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 293 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 293 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 293 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 293 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 293 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 293 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 293 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 293 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 293 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 293 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 293 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 293 | Training Loss   0.02\n",
      "Epoch 293 | Validation Loss   0.02\n",
      "\tEpoch 294 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 294 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 294 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 294 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 294 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 294 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 294 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 294 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 294 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 294 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 294 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 294 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 294 | Training Loss   0.02\n",
      "Epoch 294 | Validation Loss   0.02\n",
      "\tEpoch 295 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 295 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 295 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 295 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 295 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 295 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 295 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 295 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 295 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 295 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 295 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 295 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 295 | Training Loss   0.02\n",
      "Epoch 295 | Validation Loss   0.02\n",
      "\tEpoch 296 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 296 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 296 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 296 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 296 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 296 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 296 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 296 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 296 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 296 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 296 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 296 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 296 | Training Loss   0.02\n",
      "Epoch 296 | Validation Loss   0.02\n",
      "\tEpoch 297 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 297 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 297 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 297 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 297 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 297 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 297 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 297 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 297 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 297 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 297 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 297 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 297 | Training Loss   0.02\n",
      "Epoch 297 | Validation Loss   0.02\n",
      "\tEpoch 298 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 298 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 298 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 298 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 298 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 298 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 298 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 298 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 298 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 298 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 298 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 298 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 298 | Training Loss   0.02\n",
      "Epoch 298 | Validation Loss   0.02\n",
      "\tEpoch 299 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 299 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 299 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 299 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 299 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 299 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 299 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 299 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 299 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 299 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 299 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 299 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 299 | Training Loss   0.02\n",
      "Epoch 299 | Validation Loss   0.02\n",
      "\tEpoch 300 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 300 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 300 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 300 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 300 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 300 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 300 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 300 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 300 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 300 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 300 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 300 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 300 | Training Loss   0.02\n",
      "Epoch 300 | Validation Loss   0.02\n",
      "\tEpoch 301 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 301 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 301 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 301 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 301 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 301 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 301 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 301 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 301 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 301 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 301 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 301 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 301 | Training Loss   0.02\n",
      "Epoch 301 | Validation Loss   0.02\n",
      "\tEpoch 302 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 302 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 302 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 302 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 302 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 302 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 302 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 302 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 302 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 302 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 302 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 302 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 302 | Training Loss   0.02\n",
      "Epoch 302 | Validation Loss   0.02\n",
      "\tEpoch 303 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 303 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 303 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 303 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 303 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 303 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 303 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 303 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 303 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 303 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 303 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 303 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 303 | Training Loss   0.02\n",
      "Epoch 303 | Validation Loss   0.02\n",
      "\tEpoch 304 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 304 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 304 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 304 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 304 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 304 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 304 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 304 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 304 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 304 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 304 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 304 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 304 | Training Loss   0.02\n",
      "Epoch 304 | Validation Loss   0.02\n",
      "\tEpoch 305 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 305 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 305 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 305 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 305 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 305 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 305 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 305 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 305 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 305 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 305 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 305 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 305 | Training Loss   0.02\n",
      "Epoch 305 | Validation Loss   0.02\n",
      "\tEpoch 306 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 306 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 306 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 306 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 306 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 306 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 306 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 306 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 306 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 306 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 306 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 306 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 306 | Training Loss   0.02\n",
      "Epoch 306 | Validation Loss   0.02\n",
      "\tEpoch 307 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 307 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 307 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 307 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 307 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 307 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 307 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 307 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 307 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 307 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 307 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 307 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 307 | Training Loss   0.02\n",
      "Epoch 307 | Validation Loss   0.02\n",
      "\tEpoch 308 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 308 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 308 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 308 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 308 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 308 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 308 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 308 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 308 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 308 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 308 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 308 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 308 | Training Loss   0.02\n",
      "Epoch 308 | Validation Loss   0.02\n",
      "\tEpoch 309 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 309 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 309 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 309 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 309 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 309 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 309 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 309 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 309 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 309 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 309 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 309 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 309 | Training Loss   0.02\n",
      "Epoch 309 | Validation Loss   0.02\n",
      "\tEpoch 310 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 310 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 310 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 310 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 310 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 310 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 310 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 310 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 310 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 310 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 310 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 310 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 310 | Training Loss   0.02\n",
      "Epoch 310 | Validation Loss   0.02\n",
      "\tEpoch 311 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 311 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 311 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 311 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 311 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 311 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 311 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 311 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 311 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 311 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 311 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 311 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 311 | Training Loss   0.02\n",
      "Epoch 311 | Validation Loss   0.02\n",
      "\tEpoch 312 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 312 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 312 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 312 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 312 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 312 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 312 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 312 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 312 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 312 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 312 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 312 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 312 | Training Loss   0.02\n",
      "Epoch 312 | Validation Loss   0.02\n",
      "\tEpoch 313 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 313 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 313 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 313 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 313 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 313 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 313 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 313 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 313 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 313 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 313 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 313 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 313 | Training Loss   0.01\n",
      "Epoch 313 | Validation Loss   0.01\n",
      "\tEpoch 314 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 314 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 314 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 314 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 314 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 314 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 314 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 314 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 314 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 314 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 314 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 314 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 314 | Training Loss   0.01\n",
      "Epoch 314 | Validation Loss   0.01\n",
      "\tEpoch 315 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 315 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 315 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 315 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 315 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 315 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 315 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 315 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 315 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 315 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 315 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 315 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 315 | Training Loss   0.01\n",
      "Epoch 315 | Validation Loss   0.01\n",
      "\tEpoch 316 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 316 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 316 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 316 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 316 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 316 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 316 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 316 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 316 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 316 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 316 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 316 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 316 | Training Loss   0.01\n",
      "Epoch 316 | Validation Loss   0.01\n",
      "\tEpoch 317 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 317 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 317 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 317 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 317 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 317 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 317 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 317 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 317 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 317 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 317 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 317 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 317 | Training Loss   0.01\n",
      "Epoch 317 | Validation Loss   0.01\n",
      "\tEpoch 318 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 318 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 318 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 318 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 318 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 318 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 318 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 318 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 318 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 318 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 318 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 318 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 318 | Training Loss   0.01\n",
      "Epoch 318 | Validation Loss   0.01\n",
      "\tEpoch 319 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 319 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 319 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 319 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 319 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 319 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 319 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 319 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 319 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 319 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 319 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 319 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 319 | Training Loss   0.01\n",
      "Epoch 319 | Validation Loss   0.01\n",
      "\tEpoch 320 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 320 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 320 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 320 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 320 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 320 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 320 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 320 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 320 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 320 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 320 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 320 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 320 | Training Loss   0.01\n",
      "Epoch 320 | Validation Loss   0.01\n",
      "\tEpoch 321 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 321 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 321 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 321 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 321 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 321 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 321 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 321 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 321 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 321 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 321 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 321 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 321 | Training Loss   0.01\n",
      "Epoch 321 | Validation Loss   0.01\n",
      "\tEpoch 322 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 322 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 322 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 322 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 322 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 322 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 322 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 322 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 322 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 322 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 322 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 322 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 322 | Training Loss   0.01\n",
      "Epoch 322 | Validation Loss   0.01\n",
      "\tEpoch 323 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 323 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 323 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 323 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 323 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 323 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 323 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 323 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 323 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 323 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 323 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 323 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 323 | Training Loss   0.01\n",
      "Epoch 323 | Validation Loss   0.01\n",
      "\tEpoch 324 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 324 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 324 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 324 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 324 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 324 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 324 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 324 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 324 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 324 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 324 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 324 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 324 | Training Loss   0.01\n",
      "Epoch 324 | Validation Loss   0.01\n",
      "\tEpoch 325 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 325 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 325 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 325 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 325 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 325 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 325 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 325 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 325 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 325 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 325 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 325 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 325 | Training Loss   0.01\n",
      "Epoch 325 | Validation Loss   0.01\n",
      "\tEpoch 326 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 326 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 326 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 326 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 326 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 326 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 326 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 326 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 326 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 326 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 326 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 326 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 326 | Training Loss   0.01\n",
      "Epoch 326 | Validation Loss   0.01\n",
      "\tEpoch 327 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 327 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 327 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 327 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 327 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 327 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 327 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 327 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 327 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 327 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 327 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 327 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 327 | Training Loss   0.01\n",
      "Epoch 327 | Validation Loss   0.01\n",
      "\tEpoch 328 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 328 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 328 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 328 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 328 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 328 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 328 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 328 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 328 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 328 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 328 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 328 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 328 | Training Loss   0.01\n",
      "Epoch 328 | Validation Loss   0.01\n",
      "\tEpoch 329 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 329 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 329 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 329 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 329 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 329 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 329 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 329 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 329 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 329 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 329 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 329 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 329 | Training Loss   0.01\n",
      "Epoch 329 | Validation Loss   0.01\n",
      "\tEpoch 330 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 330 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 330 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 330 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 330 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 330 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 330 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 330 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 330 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 330 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 330 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 330 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 330 | Training Loss   0.01\n",
      "Epoch 330 | Validation Loss   0.01\n",
      "\tEpoch 331 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 331 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 331 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 331 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 331 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 331 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 331 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 331 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 331 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 331 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 331 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 331 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 331 | Training Loss   0.01\n",
      "Epoch 331 | Validation Loss   0.01\n",
      "\tEpoch 332 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 332 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 332 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 332 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 332 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 332 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 332 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 332 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 332 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 332 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 332 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 332 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 332 | Training Loss   0.01\n",
      "Epoch 332 | Validation Loss   0.01\n",
      "\tEpoch 333 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 333 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 333 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 333 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 333 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 333 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 333 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 333 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 333 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 333 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 333 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 333 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 333 | Training Loss   0.01\n",
      "Epoch 333 | Validation Loss   0.01\n",
      "\tEpoch 334 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 334 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 334 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 334 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 334 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 334 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 334 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 334 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 334 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 334 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 334 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 334 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 334 | Training Loss   0.01\n",
      "Epoch 334 | Validation Loss   0.01\n",
      "\tEpoch 335 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 335 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 335 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 335 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 335 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 335 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 335 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 335 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 335 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 335 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 335 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 335 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 335 | Training Loss   0.01\n",
      "Epoch 335 | Validation Loss   0.01\n",
      "\tEpoch 336 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 336 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 336 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 336 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 336 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 336 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 336 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 336 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 336 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 336 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 336 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 336 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 336 | Training Loss   0.01\n",
      "Epoch 336 | Validation Loss   0.01\n",
      "\tEpoch 337 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 337 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 337 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 337 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 337 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 337 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 337 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 337 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 337 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 337 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 337 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 337 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 337 | Training Loss   0.01\n",
      "Epoch 337 | Validation Loss   0.01\n",
      "\tEpoch 338 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 338 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 338 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 338 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 338 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 338 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 338 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 338 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 338 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 338 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 338 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 338 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 338 | Training Loss   0.01\n",
      "Epoch 338 | Validation Loss   0.01\n",
      "\tEpoch 339 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 339 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 339 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 339 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 339 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 339 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 339 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 339 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 339 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 339 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 339 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 339 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 339 | Training Loss   0.01\n",
      "Epoch 339 | Validation Loss   0.01\n",
      "\tEpoch 340 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 340 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 340 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 340 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 340 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 340 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 340 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 340 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 340 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 340 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 340 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 340 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 340 | Training Loss   0.01\n",
      "Epoch 340 | Validation Loss   0.01\n",
      "\tEpoch 341 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 341 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 341 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 341 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 341 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 341 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 341 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 341 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 341 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 341 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 341 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 341 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 341 | Training Loss   0.01\n",
      "Epoch 341 | Validation Loss   0.01\n",
      "\tEpoch 342 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 342 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 342 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 342 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 342 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 342 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 342 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 342 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 342 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 342 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 342 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 342 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 342 | Training Loss   0.01\n",
      "Epoch 342 | Validation Loss   0.01\n",
      "\tEpoch 343 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 343 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 343 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 343 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 343 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 343 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 343 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 343 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 343 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 343 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 343 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 343 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 343 | Training Loss   0.01\n",
      "Epoch 343 | Validation Loss   0.01\n",
      "\tEpoch 344 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 344 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 344 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 344 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 344 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 344 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 344 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 344 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 344 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 344 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 344 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 344 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 344 | Training Loss   0.01\n",
      "Epoch 344 | Validation Loss   0.01\n",
      "\tEpoch 345 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 345 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 345 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 345 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 345 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 345 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 345 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 345 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 345 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 345 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 345 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 345 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 345 | Training Loss   0.01\n",
      "Epoch 345 | Validation Loss   0.01\n",
      "\tEpoch 346 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 346 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 346 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 346 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 346 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 346 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 346 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 346 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 346 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 346 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 346 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 346 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 346 | Training Loss   0.01\n",
      "Epoch 346 | Validation Loss   0.01\n",
      "\tEpoch 347 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 347 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 347 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 347 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 347 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 347 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 347 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 347 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 347 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 347 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 347 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 347 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 347 | Training Loss   0.01\n",
      "Epoch 347 | Validation Loss   0.01\n",
      "\tEpoch 348 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 348 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 348 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 348 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 348 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 348 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 348 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 348 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 348 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 348 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 348 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 348 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 348 | Training Loss   0.01\n",
      "Epoch 348 | Validation Loss   0.01\n",
      "\tEpoch 349 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 349 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 349 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 349 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 349 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 349 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 349 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 349 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 349 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 349 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 349 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 349 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 349 | Training Loss   0.01\n",
      "Epoch 349 | Validation Loss   0.01\n",
      "\tEpoch 350 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 350 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 350 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 350 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 350 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 350 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 350 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 350 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 350 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 350 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 350 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 350 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 350 | Training Loss   0.01\n",
      "Epoch 350 | Validation Loss   0.01\n",
      "\tEpoch 351 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 351 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 351 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 351 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 351 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 351 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 351 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 351 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 351 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 351 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 351 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 351 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 351 | Training Loss   0.01\n",
      "Epoch 351 | Validation Loss   0.01\n",
      "\tEpoch 352 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 352 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 352 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 352 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 352 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 352 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 352 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 352 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 352 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 352 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 352 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 352 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 352 | Training Loss   0.01\n",
      "Epoch 352 | Validation Loss   0.01\n",
      "\tEpoch 353 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 353 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 353 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 353 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 353 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 353 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 353 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 353 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 353 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 353 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 353 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 353 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 353 | Training Loss   0.01\n",
      "Epoch 353 | Validation Loss   0.01\n",
      "\tEpoch 354 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 354 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 354 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 354 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 354 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 354 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 354 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 354 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 354 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 354 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 354 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 354 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 354 | Training Loss   0.01\n",
      "Epoch 354 | Validation Loss   0.01\n",
      "\tEpoch 355 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 355 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 355 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 355 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 355 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 355 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 355 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 355 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 355 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 355 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 355 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 355 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 355 | Training Loss   0.01\n",
      "Epoch 355 | Validation Loss   0.01\n",
      "\tEpoch 356 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 356 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 356 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 356 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 356 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 356 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 356 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 356 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 356 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 356 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 356 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 356 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 356 | Training Loss   0.01\n",
      "Epoch 356 | Validation Loss   0.01\n",
      "\tEpoch 357 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 357 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 357 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 357 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 357 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 357 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 357 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 357 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 357 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 357 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 357 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 357 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 357 | Training Loss   0.01\n",
      "Epoch 357 | Validation Loss   0.01\n",
      "\tEpoch 358 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 358 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 358 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 358 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 358 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 358 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 358 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 358 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 358 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 358 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 358 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 358 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 358 | Training Loss   0.01\n",
      "Epoch 358 | Validation Loss   0.01\n",
      "\tEpoch 359 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 359 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 359 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 359 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 359 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 359 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 359 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 359 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 359 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 359 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 359 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 359 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 359 | Training Loss   0.01\n",
      "Epoch 359 | Validation Loss   0.01\n",
      "\tEpoch 360 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 360 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 360 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 360 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 360 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 360 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 360 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 360 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 360 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 360 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 360 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 360 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 360 | Training Loss   0.01\n",
      "Epoch 360 | Validation Loss   0.01\n",
      "\tEpoch 361 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 361 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 361 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 361 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 361 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 361 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 361 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 361 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 361 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 361 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 361 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 361 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 361 | Training Loss   0.01\n",
      "Epoch 361 | Validation Loss   0.01\n",
      "\tEpoch 362 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 362 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 362 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 362 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 362 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 362 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 362 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 362 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 362 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 362 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 362 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 362 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 362 | Training Loss   0.01\n",
      "Epoch 362 | Validation Loss   0.01\n",
      "\tEpoch 363 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 363 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 363 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 363 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 363 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 363 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 363 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 363 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 363 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 363 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 363 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 363 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 363 | Training Loss   0.01\n",
      "Epoch 363 | Validation Loss   0.01\n",
      "\tEpoch 364 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 364 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 364 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 364 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 364 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 364 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 364 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 364 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 364 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 364 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 364 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 364 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 364 | Training Loss   0.01\n",
      "Epoch 364 | Validation Loss   0.01\n",
      "\tEpoch 365 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 365 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 365 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 365 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 365 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 365 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 365 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 365 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 365 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 365 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 365 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 365 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 365 | Training Loss   0.01\n",
      "Epoch 365 | Validation Loss   0.01\n",
      "\tEpoch 366 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 366 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 366 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 366 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 366 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 366 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 366 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 366 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 366 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 366 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 366 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 366 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 366 | Training Loss   0.01\n",
      "Epoch 366 | Validation Loss   0.01\n",
      "\tEpoch 367 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 367 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 367 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 367 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 367 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 367 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 367 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 367 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 367 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 367 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 367 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 367 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 367 | Training Loss   0.01\n",
      "Epoch 367 | Validation Loss   0.01\n",
      "\tEpoch 368 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 368 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 368 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 368 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 368 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 368 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 368 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 368 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 368 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 368 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 368 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 368 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 368 | Training Loss   0.01\n",
      "Epoch 368 | Validation Loss   0.01\n",
      "\tEpoch 369 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 369 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 369 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 369 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 369 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 369 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 369 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 369 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 369 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 369 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 369 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 369 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 369 | Training Loss   0.01\n",
      "Epoch 369 | Validation Loss   0.01\n",
      "\tEpoch 370 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 370 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 370 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 370 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 370 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 370 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 370 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 370 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 370 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 370 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 370 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 370 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 370 | Training Loss   0.01\n",
      "Epoch 370 | Validation Loss   0.01\n",
      "\tEpoch 371 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 371 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 371 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 371 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 371 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 371 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 371 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 371 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 371 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 371 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 371 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 371 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 371 | Training Loss   0.01\n",
      "Epoch 371 | Validation Loss   0.01\n",
      "\tEpoch 372 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 372 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 372 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 372 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 372 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 372 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 372 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 372 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 372 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 372 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 372 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 372 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 372 | Training Loss   0.01\n",
      "Epoch 372 | Validation Loss   0.01\n",
      "\tEpoch 373 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 373 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 373 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 373 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 373 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 373 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 373 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 373 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 373 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 373 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 373 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 373 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 373 | Training Loss   0.01\n",
      "Epoch 373 | Validation Loss   0.01\n",
      "\tEpoch 374 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 374 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 374 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 374 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 374 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 374 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 374 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 374 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 374 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 374 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 374 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 374 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 374 | Training Loss   0.01\n",
      "Epoch 374 | Validation Loss   0.01\n",
      "\tEpoch 375 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 375 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 375 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 375 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 375 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 375 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 375 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 375 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 375 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 375 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 375 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 375 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 375 | Training Loss   0.01\n",
      "Epoch 375 | Validation Loss   0.01\n",
      "\tEpoch 376 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 376 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 376 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 376 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 376 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 376 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 376 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 376 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 376 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 376 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 376 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 376 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 376 | Training Loss   0.01\n",
      "Epoch 376 | Validation Loss   0.01\n",
      "\tEpoch 377 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 377 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 377 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 377 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 377 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 377 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 377 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 377 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 377 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 377 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 377 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 377 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 377 | Training Loss   0.01\n",
      "Epoch 377 | Validation Loss   0.01\n",
      "\tEpoch 378 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 378 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 378 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 378 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 378 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 378 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 378 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 378 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 378 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 378 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 378 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 378 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 378 | Training Loss   0.01\n",
      "Epoch 378 | Validation Loss   0.01\n",
      "\tEpoch 379 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 379 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 379 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 379 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 379 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 379 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 379 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 379 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 379 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 379 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 379 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 379 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 379 | Training Loss   0.01\n",
      "Epoch 379 | Validation Loss   0.01\n",
      "\tEpoch 380 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 380 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 380 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 380 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 380 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 380 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 380 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 380 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 380 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 380 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 380 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 380 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 380 | Training Loss   0.01\n",
      "Epoch 380 | Validation Loss   0.01\n",
      "\tEpoch 381 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 381 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 381 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 381 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 381 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 381 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 381 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 381 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 381 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 381 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 381 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 381 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 381 | Training Loss   0.01\n",
      "Epoch 381 | Validation Loss   0.01\n",
      "\tEpoch 382 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 382 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 382 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 382 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 382 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 382 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 382 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 382 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 382 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 382 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 382 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 382 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 382 | Training Loss   0.01\n",
      "Epoch 382 | Validation Loss   0.01\n",
      "\tEpoch 383 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 383 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 383 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 383 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 383 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 383 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 383 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 383 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 383 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 383 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 383 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 383 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 383 | Training Loss   0.01\n",
      "Epoch 383 | Validation Loss   0.01\n",
      "\tEpoch 384 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 384 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 384 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 384 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 384 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 384 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 384 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 384 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 384 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 384 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 384 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 384 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 384 | Training Loss   0.01\n",
      "Epoch 384 | Validation Loss   0.01\n",
      "\tEpoch 385 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 385 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 385 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 385 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 385 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 385 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 385 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 385 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 385 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 385 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 385 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 385 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 385 | Training Loss   0.01\n",
      "Epoch 385 | Validation Loss   0.01\n",
      "\tEpoch 386 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 386 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 386 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 386 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 386 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 386 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 386 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 386 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 386 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 386 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 386 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 386 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 386 | Training Loss   0.01\n",
      "Epoch 386 | Validation Loss   0.01\n",
      "\tEpoch 387 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 387 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 387 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 387 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 387 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 387 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 387 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 387 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 387 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 387 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 387 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 387 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 387 | Training Loss   0.01\n",
      "Epoch 387 | Validation Loss   0.01\n",
      "\tEpoch 388 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 388 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 388 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 388 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 388 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 388 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 388 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 388 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 388 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 388 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 388 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 388 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 388 | Training Loss   0.01\n",
      "Epoch 388 | Validation Loss   0.01\n",
      "\tEpoch 389 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 389 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 389 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 389 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 389 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 389 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 389 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 389 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 389 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 389 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 389 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 389 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 389 | Training Loss   0.01\n",
      "Epoch 389 | Validation Loss   0.01\n",
      "\tEpoch 390 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 390 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 390 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 390 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 390 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 390 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 390 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 390 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 390 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 390 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 390 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 390 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 390 | Training Loss   0.01\n",
      "Epoch 390 | Validation Loss   0.01\n",
      "\tEpoch 391 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 391 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 391 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 391 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 391 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 391 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 391 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 391 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 391 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 391 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 391 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 391 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 391 | Training Loss   0.01\n",
      "Epoch 391 | Validation Loss   0.01\n",
      "\tEpoch 392 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 392 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 392 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 392 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 392 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 392 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 392 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 392 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 392 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 392 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 392 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 392 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 392 | Training Loss   0.01\n",
      "Epoch 392 | Validation Loss   0.01\n",
      "\tEpoch 393 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 393 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 393 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 393 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 393 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 393 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 393 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 393 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 393 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 393 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 393 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 393 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 393 | Training Loss   0.01\n",
      "Epoch 393 | Validation Loss   0.01\n",
      "\tEpoch 394 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 394 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 394 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 394 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 394 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 394 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 394 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 394 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 394 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 394 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 394 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 394 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 394 | Training Loss   0.01\n",
      "Epoch 394 | Validation Loss   0.01\n",
      "\tEpoch 395 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 395 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 395 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 395 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 395 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 395 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 395 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 395 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 395 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 395 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 395 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 395 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 395 | Training Loss   0.01\n",
      "Epoch 395 | Validation Loss   0.01\n",
      "\tEpoch 396 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 396 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 396 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 396 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 396 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 396 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 396 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 396 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 396 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 396 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 396 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 396 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 396 | Training Loss   0.01\n",
      "Epoch 396 | Validation Loss   0.01\n",
      "\tEpoch 397 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 397 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 397 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 397 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 397 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 397 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 397 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 397 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 397 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 397 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 397 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 397 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 397 | Training Loss   0.01\n",
      "Epoch 397 | Validation Loss   0.01\n",
      "\tEpoch 398 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 398 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 398 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 398 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 398 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 398 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 398 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 398 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 398 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 398 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 398 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 398 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 398 | Training Loss   0.01\n",
      "Epoch 398 | Validation Loss   0.01\n",
      "\tEpoch 399 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 399 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 399 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 399 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 399 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 399 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 399 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 399 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 399 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 399 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 399 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 399 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 399 | Training Loss   0.01\n",
      "Epoch 399 | Validation Loss   0.01\n",
      "\tEpoch 400 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 400 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 400 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 400 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 400 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 400 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 400 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 400 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 400 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 400 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 400 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 400 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 400 | Training Loss   0.01\n",
      "Epoch 400 | Validation Loss   0.01\n",
      "\tEpoch 401 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 401 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 401 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 401 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 401 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 401 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 401 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 401 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 401 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 401 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 401 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 401 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 401 | Training Loss   0.01\n",
      "Epoch 401 | Validation Loss   0.01\n",
      "\tEpoch 402 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 402 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 402 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 402 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 402 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 402 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 402 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 402 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 402 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 402 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 402 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 402 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 402 | Training Loss   0.01\n",
      "Epoch 402 | Validation Loss   0.01\n",
      "\tEpoch 403 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 403 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 403 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 403 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 403 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 403 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 403 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 403 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 403 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 403 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 403 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 403 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 403 | Training Loss   0.01\n",
      "Epoch 403 | Validation Loss   0.01\n",
      "\tEpoch 404 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 404 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 404 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 404 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 404 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 404 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 404 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 404 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 404 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 404 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 404 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 404 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 404 | Training Loss   0.01\n",
      "Epoch 404 | Validation Loss   0.01\n",
      "\tEpoch 405 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 405 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 405 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 405 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 405 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 405 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 405 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 405 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 405 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 405 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 405 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 405 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 405 | Training Loss   0.01\n",
      "Epoch 405 | Validation Loss   0.01\n",
      "\tEpoch 406 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 406 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 406 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 406 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 406 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 406 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 406 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 406 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 406 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 406 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 406 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 406 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 406 | Training Loss   0.01\n",
      "Epoch 406 | Validation Loss   0.01\n",
      "\tEpoch 407 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 407 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 407 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 407 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 407 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 407 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 407 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 407 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 407 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 407 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 407 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 407 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 407 | Training Loss   0.01\n",
      "Epoch 407 | Validation Loss   0.01\n",
      "\tEpoch 408 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 408 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 408 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 408 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 408 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 408 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 408 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 408 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 408 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 408 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 408 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 408 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 408 | Training Loss   0.01\n",
      "Epoch 408 | Validation Loss   0.01\n",
      "\tEpoch 409 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 409 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 409 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 409 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 409 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 409 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 409 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 409 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 409 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 409 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 409 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 409 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 409 | Training Loss   0.01\n",
      "Epoch 409 | Validation Loss   0.01\n",
      "\tEpoch 410 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 410 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 410 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 410 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 410 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 410 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 410 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 410 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 410 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 410 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 410 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 410 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 410 | Training Loss   0.01\n",
      "Epoch 410 | Validation Loss   0.01\n",
      "\tEpoch 411 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 411 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 411 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 411 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 411 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 411 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 411 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 411 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 411 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 411 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 411 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 411 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 411 | Training Loss   0.01\n",
      "Epoch 411 | Validation Loss   0.01\n",
      "\tEpoch 412 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 412 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 412 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 412 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 412 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 412 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 412 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 412 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 412 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 412 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 412 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 412 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 412 | Training Loss   0.01\n",
      "Epoch 412 | Validation Loss   0.01\n",
      "\tEpoch 413 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 413 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 413 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 413 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 413 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 413 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 413 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 413 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 413 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 413 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 413 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 413 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 413 | Training Loss   0.01\n",
      "Epoch 413 | Validation Loss   0.01\n",
      "\tEpoch 414 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 414 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 414 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 414 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 414 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 414 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 414 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 414 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 414 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 414 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 414 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 414 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 414 | Training Loss   0.01\n",
      "Epoch 414 | Validation Loss   0.01\n",
      "\tEpoch 415 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 415 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 415 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 415 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 415 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 415 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 415 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 415 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 415 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 415 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 415 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 415 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 415 | Training Loss   0.01\n",
      "Epoch 415 | Validation Loss   0.01\n",
      "\tEpoch 416 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 416 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 416 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 416 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 416 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 416 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 416 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 416 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 416 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 416 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 416 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 416 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 416 | Training Loss   0.01\n",
      "Epoch 416 | Validation Loss   0.01\n",
      "\tEpoch 417 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 417 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 417 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 417 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 417 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 417 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 417 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 417 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 417 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 417 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 417 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 417 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 417 | Training Loss   0.01\n",
      "Epoch 417 | Validation Loss   0.01\n",
      "\tEpoch 418 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 418 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 418 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 418 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 418 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 418 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 418 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 418 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 418 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 418 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 418 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 418 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 418 | Training Loss   0.01\n",
      "Epoch 418 | Validation Loss   0.01\n",
      "\tEpoch 419 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 419 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 419 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 419 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 419 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 419 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 419 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 419 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 419 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 419 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 419 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 419 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 419 | Training Loss   0.01\n",
      "Epoch 419 | Validation Loss   0.01\n",
      "\tEpoch 420 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 420 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 420 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 420 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 420 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 420 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 420 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 420 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 420 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 420 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 420 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 420 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 420 | Training Loss   0.01\n",
      "Epoch 420 | Validation Loss   0.01\n",
      "\tEpoch 421 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 421 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 421 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 421 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 421 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 421 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 421 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 421 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 421 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 421 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 421 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 421 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 421 | Training Loss   0.01\n",
      "Epoch 421 | Validation Loss   0.01\n",
      "\tEpoch 422 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 422 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 422 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 422 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 422 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 422 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 422 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 422 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 422 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 422 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 422 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 422 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 422 | Training Loss   0.01\n",
      "Epoch 422 | Validation Loss   0.01\n",
      "\tEpoch 423 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 423 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 423 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 423 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 423 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 423 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 423 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 423 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 423 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 423 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 423 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 423 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 423 | Training Loss   0.01\n",
      "Epoch 423 | Validation Loss   0.01\n",
      "\tEpoch 424 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 424 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 424 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 424 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 424 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 424 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 424 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 424 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 424 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 424 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 424 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 424 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 424 | Training Loss   0.01\n",
      "Epoch 424 | Validation Loss   0.01\n",
      "\tEpoch 425 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 425 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 425 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 425 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 425 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 425 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 425 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 425 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 425 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 425 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 425 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 425 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 425 | Training Loss   0.01\n",
      "Epoch 425 | Validation Loss   0.01\n",
      "\tEpoch 426 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 426 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 426 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 426 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 426 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 426 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 426 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 426 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 426 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 426 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 426 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 426 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 426 | Training Loss   0.01\n",
      "Epoch 426 | Validation Loss   0.01\n",
      "\tEpoch 427 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 427 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 427 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 427 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 427 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 427 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 427 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 427 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 427 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 427 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 427 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 427 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 427 | Training Loss   0.01\n",
      "Epoch 427 | Validation Loss   0.01\n",
      "\tEpoch 428 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 428 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 428 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 428 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 428 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 428 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 428 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 428 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 428 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 428 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 428 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 428 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 428 | Training Loss   0.01\n",
      "Epoch 428 | Validation Loss   0.01\n",
      "\tEpoch 429 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 429 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 429 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 429 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 429 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 429 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 429 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 429 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 429 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 429 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 429 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 429 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 429 | Training Loss   0.01\n",
      "Epoch 429 | Validation Loss   0.01\n",
      "\tEpoch 430 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 430 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 430 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 430 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 430 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 430 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 430 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 430 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 430 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 430 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 430 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 430 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 430 | Training Loss   0.01\n",
      "Epoch 430 | Validation Loss   0.01\n",
      "\tEpoch 431 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 431 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 431 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 431 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 431 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 431 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 431 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 431 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 431 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 431 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 431 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 431 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 431 | Training Loss   0.01\n",
      "Epoch 431 | Validation Loss   0.01\n",
      "\tEpoch 432 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 432 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 432 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 432 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 432 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 432 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 432 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 432 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 432 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 432 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 432 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 432 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 432 | Training Loss   0.01\n",
      "Epoch 432 | Validation Loss   0.01\n",
      "\tEpoch 433 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 433 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 433 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 433 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 433 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 433 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 433 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 433 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 433 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 433 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 433 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 433 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 433 | Training Loss   0.01\n",
      "Epoch 433 | Validation Loss   0.01\n",
      "\tEpoch 434 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 434 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 434 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 434 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 434 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 434 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 434 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 434 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 434 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 434 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 434 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 434 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 434 | Training Loss   0.01\n",
      "Epoch 434 | Validation Loss   0.01\n",
      "\tEpoch 435 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 435 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 435 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 435 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 435 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 435 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 435 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 435 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 435 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 435 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 435 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 435 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 435 | Training Loss   0.01\n",
      "Epoch 435 | Validation Loss   0.01\n",
      "\tEpoch 436 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 436 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 436 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 436 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 436 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 436 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 436 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 436 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 436 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 436 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 436 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 436 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 436 | Training Loss   0.01\n",
      "Epoch 436 | Validation Loss   0.01\n",
      "\tEpoch 437 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 437 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 437 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 437 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 437 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 437 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 437 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 437 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 437 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 437 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 437 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 437 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 437 | Training Loss   0.01\n",
      "Epoch 437 | Validation Loss   0.01\n",
      "\tEpoch 438 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 438 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 438 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 438 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 438 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 438 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 438 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 438 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 438 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 438 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 438 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 438 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 438 | Training Loss   0.01\n",
      "Epoch 438 | Validation Loss   0.01\n",
      "\tEpoch 439 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 439 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 439 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 439 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 439 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 439 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 439 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 439 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 439 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 439 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 439 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 439 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 439 | Training Loss   0.01\n",
      "Epoch 439 | Validation Loss   0.01\n",
      "\tEpoch 440 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 440 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 440 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 440 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 440 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 440 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 440 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 440 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 440 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 440 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 440 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 440 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 440 | Training Loss   0.01\n",
      "Epoch 440 | Validation Loss   0.01\n",
      "\tEpoch 441 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 441 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 441 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 441 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 441 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 441 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 441 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 441 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 441 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 441 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 441 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 441 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 441 | Training Loss   0.01\n",
      "Epoch 441 | Validation Loss   0.01\n",
      "\tEpoch 442 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 442 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 442 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 442 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 442 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 442 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 442 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 442 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 442 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 442 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 442 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 442 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 442 | Training Loss   0.01\n",
      "Epoch 442 | Validation Loss   0.01\n",
      "\tEpoch 443 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 443 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 443 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 443 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 443 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 443 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 443 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 443 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 443 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 443 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 443 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 443 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 443 | Training Loss   0.01\n",
      "Epoch 443 | Validation Loss   0.01\n",
      "\tEpoch 444 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 444 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 444 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 444 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 444 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 444 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 444 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 444 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 444 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 444 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 444 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 444 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 444 | Training Loss   0.01\n",
      "Epoch 444 | Validation Loss   0.01\n",
      "\tEpoch 445 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 445 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 445 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 445 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 445 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 445 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 445 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 445 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 445 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 445 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 445 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 445 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 445 | Training Loss   0.01\n",
      "Epoch 445 | Validation Loss   0.01\n",
      "\tEpoch 446 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 446 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 446 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 446 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 446 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 446 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 446 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 446 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 446 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 446 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 446 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 446 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 446 | Training Loss   0.01\n",
      "Epoch 446 | Validation Loss   0.01\n",
      "\tEpoch 447 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 447 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 447 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 447 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 447 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 447 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 447 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 447 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 447 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 447 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 447 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 447 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 447 | Training Loss   0.01\n",
      "Epoch 447 | Validation Loss   0.01\n",
      "\tEpoch 448 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 448 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 448 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 448 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 448 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 448 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 448 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 448 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 448 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 448 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 448 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 448 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 448 | Training Loss   0.01\n",
      "Epoch 448 | Validation Loss   0.01\n",
      "\tEpoch 449 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 449 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 449 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 449 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 449 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 449 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 449 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 449 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 449 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 449 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 449 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 449 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 449 | Training Loss   0.01\n",
      "Epoch 449 | Validation Loss   0.01\n",
      "\tEpoch 450 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 450 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 450 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 450 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 450 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 450 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 450 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 450 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 450 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 450 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 450 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 450 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 450 | Training Loss   0.01\n",
      "Epoch 450 | Validation Loss   0.01\n",
      "\tEpoch 451 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 451 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 451 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 451 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 451 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 451 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 451 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 451 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 451 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 451 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 451 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 451 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 451 | Training Loss   0.01\n",
      "Epoch 451 | Validation Loss   0.01\n",
      "\tEpoch 452 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 452 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 452 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 452 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 452 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 452 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 452 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 452 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 452 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 452 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 452 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 452 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 452 | Training Loss   0.01\n",
      "Epoch 452 | Validation Loss   0.01\n",
      "\tEpoch 453 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 453 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 453 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 453 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 453 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 453 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 453 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 453 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 453 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 453 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 453 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 453 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 453 | Training Loss   0.01\n",
      "Epoch 453 | Validation Loss   0.01\n",
      "\tEpoch 454 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 454 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 454 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 454 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 454 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 454 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 454 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 454 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 454 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 454 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 454 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 454 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 454 | Training Loss   0.01\n",
      "Epoch 454 | Validation Loss   0.01\n",
      "\tEpoch 455 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 455 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 455 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 455 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 455 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 455 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 455 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 455 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 455 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 455 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 455 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 455 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 455 | Training Loss   0.01\n",
      "Epoch 455 | Validation Loss   0.01\n",
      "\tEpoch 456 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 456 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 456 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 456 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 456 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 456 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 456 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 456 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 456 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 456 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 456 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 456 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 456 | Training Loss   0.01\n",
      "Epoch 456 | Validation Loss   0.01\n",
      "\tEpoch 457 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 457 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 457 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 457 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 457 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 457 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 457 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 457 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 457 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 457 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 457 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 457 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 457 | Training Loss   0.01\n",
      "Epoch 457 | Validation Loss   0.01\n",
      "\tEpoch 458 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 458 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 458 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 458 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 458 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 458 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 458 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 458 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 458 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 458 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 458 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 458 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 458 | Training Loss   0.01\n",
      "Epoch 458 | Validation Loss   0.01\n",
      "\tEpoch 459 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 459 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 459 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 459 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 459 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 459 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 459 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 459 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 459 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 459 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 459 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 459 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 459 | Training Loss   0.01\n",
      "Epoch 459 | Validation Loss   0.01\n",
      "\tEpoch 460 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 460 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 460 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 460 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 460 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 460 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 460 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 460 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 460 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 460 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 460 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 460 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 460 | Training Loss   0.01\n",
      "Epoch 460 | Validation Loss   0.01\n",
      "\tEpoch 461 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 461 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 461 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 461 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 461 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 461 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 461 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 461 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 461 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 461 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 461 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 461 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 461 | Training Loss   0.01\n",
      "Epoch 461 | Validation Loss   0.01\n",
      "\tEpoch 462 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 462 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 462 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 462 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 462 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 462 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 462 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 462 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 462 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 462 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 462 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 462 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 462 | Training Loss   0.01\n",
      "Epoch 462 | Validation Loss   0.01\n",
      "\tEpoch 463 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 463 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 463 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 463 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 463 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 463 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 463 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 463 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 463 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 463 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 463 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 463 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 463 | Training Loss   0.01\n",
      "Epoch 463 | Validation Loss   0.01\n",
      "\tEpoch 464 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 464 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 464 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 464 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 464 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 464 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 464 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 464 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 464 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 464 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 464 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 464 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 464 | Training Loss   0.01\n",
      "Epoch 464 | Validation Loss   0.01\n",
      "\tEpoch 465 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 465 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 465 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 465 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 465 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 465 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 465 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 465 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 465 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 465 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 465 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 465 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 465 | Training Loss   0.01\n",
      "Epoch 465 | Validation Loss   0.01\n",
      "\tEpoch 466 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 466 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 466 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 466 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 466 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 466 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 466 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 466 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 466 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 466 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 466 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 466 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 466 | Training Loss   0.01\n",
      "Epoch 466 | Validation Loss   0.01\n",
      "\tEpoch 467 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 467 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 467 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 467 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 467 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 467 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 467 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 467 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 467 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 467 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 467 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 467 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 467 | Training Loss   0.01\n",
      "Epoch 467 | Validation Loss   0.01\n",
      "\tEpoch 468 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 468 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 468 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 468 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 468 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 468 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 468 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 468 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 468 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 468 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 468 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 468 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 468 | Training Loss   0.01\n",
      "Epoch 468 | Validation Loss   0.01\n",
      "\tEpoch 469 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 469 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 469 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 469 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 469 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 469 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 469 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 469 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 469 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 469 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 469 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 469 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 469 | Training Loss   0.01\n",
      "Epoch 469 | Validation Loss   0.01\n",
      "\tEpoch 470 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 470 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 470 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 470 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 470 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 470 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 470 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 470 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 470 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 470 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 470 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 470 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 470 | Training Loss   0.01\n",
      "Epoch 470 | Validation Loss   0.01\n",
      "\tEpoch 471 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 471 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 471 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 471 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 471 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 471 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 471 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 471 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 471 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 471 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 471 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 471 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 471 | Training Loss   0.01\n",
      "Epoch 471 | Validation Loss   0.01\n",
      "\tEpoch 472 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 472 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 472 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 472 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 472 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 472 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 472 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 472 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 472 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 472 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 472 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 472 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 472 | Training Loss   0.01\n",
      "Epoch 472 | Validation Loss   0.01\n",
      "\tEpoch 473 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 473 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 473 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 473 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 473 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 473 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 473 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 473 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 473 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 473 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 473 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 473 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 473 | Training Loss   0.01\n",
      "Epoch 473 | Validation Loss   0.01\n",
      "\tEpoch 474 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 474 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 474 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 474 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 474 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 474 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 474 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 474 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 474 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 474 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 474 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 474 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 474 | Training Loss   0.01\n",
      "Epoch 474 | Validation Loss   0.01\n",
      "\tEpoch 475 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 475 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 475 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 475 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 475 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 475 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 475 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 475 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 475 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 475 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 475 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 475 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 475 | Training Loss   0.01\n",
      "Epoch 475 | Validation Loss   0.01\n",
      "\tEpoch 476 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 476 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 476 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 476 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 476 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 476 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 476 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 476 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 476 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 476 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 476 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 476 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 476 | Training Loss   0.01\n",
      "Epoch 476 | Validation Loss   0.01\n",
      "\tEpoch 477 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 477 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 477 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 477 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 477 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 477 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 477 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 477 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 477 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 477 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 477 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 477 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 477 | Training Loss   0.01\n",
      "Epoch 477 | Validation Loss   0.01\n",
      "\tEpoch 478 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 478 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 478 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 478 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 478 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 478 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 478 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 478 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 478 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 478 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 478 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 478 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 478 | Training Loss   0.01\n",
      "Epoch 478 | Validation Loss   0.01\n",
      "\tEpoch 479 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 479 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 479 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 479 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 479 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 479 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 479 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 479 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 479 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 479 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 479 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 479 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 479 | Training Loss   0.01\n",
      "Epoch 479 | Validation Loss   0.01\n",
      "\tEpoch 480 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 480 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 480 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 480 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 480 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 480 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 480 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 480 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 480 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 480 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 480 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 480 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 480 | Training Loss   0.01\n",
      "Epoch 480 | Validation Loss   0.01\n",
      "\tEpoch 481 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 481 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 481 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 481 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 481 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 481 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 481 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 481 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 481 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 481 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 481 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 481 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 481 | Training Loss   0.01\n",
      "Epoch 481 | Validation Loss   0.01\n",
      "\tEpoch 482 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 482 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 482 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 482 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 482 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 482 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 482 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 482 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 482 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 482 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 482 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 482 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 482 | Training Loss   0.01\n",
      "Epoch 482 | Validation Loss   0.01\n",
      "\tEpoch 483 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 483 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 483 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 483 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 483 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 483 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 483 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 483 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 483 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 483 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 483 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 483 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 483 | Training Loss   0.01\n",
      "Epoch 483 | Validation Loss   0.01\n",
      "\tEpoch 484 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 484 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 484 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 484 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 484 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 484 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 484 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 484 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 484 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 484 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 484 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 484 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 484 | Training Loss   0.01\n",
      "Epoch 484 | Validation Loss   0.01\n",
      "\tEpoch 485 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 485 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 485 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 485 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 485 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 485 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 485 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 485 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 485 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 485 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 485 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 485 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 485 | Training Loss   0.01\n",
      "Epoch 485 | Validation Loss   0.01\n",
      "\tEpoch 486 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 486 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 486 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 486 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 486 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 486 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 486 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 486 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 486 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 486 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 486 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 486 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 486 | Training Loss   0.01\n",
      "Epoch 486 | Validation Loss   0.01\n",
      "\tEpoch 487 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 487 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 487 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 487 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 487 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 487 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 487 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 487 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 487 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 487 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 487 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 487 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 487 | Training Loss   0.01\n",
      "Epoch 487 | Validation Loss   0.01\n",
      "\tEpoch 488 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 488 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 488 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 488 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 488 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 488 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 488 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 488 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 488 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 488 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 488 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 488 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 488 | Training Loss   0.01\n",
      "Epoch 488 | Validation Loss   0.01\n",
      "\tEpoch 489 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 489 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 489 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 489 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 489 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 489 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 489 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 489 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 489 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 489 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 489 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 489 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 489 | Training Loss   0.01\n",
      "Epoch 489 | Validation Loss   0.01\n",
      "\tEpoch 490 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 490 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 490 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 490 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 490 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 490 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 490 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 490 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 490 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 490 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 490 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 490 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 490 | Training Loss   0.01\n",
      "Epoch 490 | Validation Loss   0.01\n",
      "\tEpoch 491 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 491 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 491 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 491 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 491 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 491 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 491 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 491 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 491 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 491 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 491 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 491 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 491 | Training Loss   0.01\n",
      "Epoch 491 | Validation Loss   0.01\n",
      "\tEpoch 492 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 492 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 492 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 492 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 492 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 492 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 492 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 492 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 492 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 492 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 492 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 492 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 492 | Training Loss   0.01\n",
      "Epoch 492 | Validation Loss   0.01\n",
      "\tEpoch 493 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 493 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 493 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 493 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 493 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 493 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 493 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 493 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 493 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 493 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 493 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 493 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 493 | Training Loss   0.01\n",
      "Epoch 493 | Validation Loss   0.01\n",
      "\tEpoch 494 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 494 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 494 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 494 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 494 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 494 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 494 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 494 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 494 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 494 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 494 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 494 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 494 | Training Loss   0.01\n",
      "Epoch 494 | Validation Loss   0.01\n",
      "\tEpoch 495 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 495 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 495 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 495 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 495 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 495 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 495 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 495 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 495 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 495 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 495 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 495 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 495 | Training Loss   0.01\n",
      "Epoch 495 | Validation Loss   0.01\n",
      "\tEpoch 496 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 496 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 496 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 496 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 496 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 496 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 496 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 496 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 496 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 496 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 496 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 496 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 496 | Training Loss   0.01\n",
      "Epoch 496 | Validation Loss   0.01\n",
      "\tEpoch 497 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 497 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 497 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 497 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 497 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 497 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 497 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 497 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 497 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 497 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 497 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 497 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 497 | Training Loss   0.01\n",
      "Epoch 497 | Validation Loss   0.01\n",
      "\tEpoch 498 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 498 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 498 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 498 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 498 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 498 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 498 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 498 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 498 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 498 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 498 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 498 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 498 | Training Loss   0.01\n",
      "Epoch 498 | Validation Loss   0.01\n",
      "\tEpoch 499 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 499 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 499 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 499 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 499 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 499 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 499 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 499 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 499 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 499 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 499 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 499 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 499 | Training Loss   0.01\n",
      "Epoch 499 | Validation Loss   0.01\n",
      "\tEpoch 500 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 500 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 500 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 500 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 500 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 500 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 500 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 500 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 500 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 500 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 500 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 500 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 500 | Training Loss   0.01\n",
      "Epoch 500 | Validation Loss   0.01\n",
      "\tEpoch 501 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 501 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 501 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 501 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 501 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 501 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 501 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 501 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 501 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 501 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 501 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 501 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 501 | Training Loss   0.01\n",
      "Epoch 501 | Validation Loss   0.01\n",
      "\tEpoch 502 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 502 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 502 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 502 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 502 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 502 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 502 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 502 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 502 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 502 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 502 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 502 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 502 | Training Loss   0.01\n",
      "Epoch 502 | Validation Loss   0.01\n",
      "\tEpoch 503 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 503 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 503 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 503 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 503 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 503 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 503 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 503 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 503 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 503 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 503 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 503 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 503 | Training Loss   0.01\n",
      "Epoch 503 | Validation Loss   0.01\n",
      "\tEpoch 504 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 504 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 504 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 504 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 504 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 504 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 504 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 504 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 504 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 504 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 504 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 504 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 504 | Training Loss   0.01\n",
      "Epoch 504 | Validation Loss   0.01\n",
      "\tEpoch 505 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 505 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 505 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 505 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 505 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 505 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 505 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 505 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 505 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 505 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 505 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 505 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 505 | Training Loss   0.01\n",
      "Epoch 505 | Validation Loss   0.01\n",
      "\tEpoch 506 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 506 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 506 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 506 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 506 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 506 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 506 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 506 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 506 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 506 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 506 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 506 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 506 | Training Loss   0.01\n",
      "Epoch 506 | Validation Loss   0.01\n",
      "\tEpoch 507 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 507 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 507 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 507 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 507 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 507 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 507 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 507 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 507 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 507 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 507 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 507 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 507 | Training Loss   0.01\n",
      "Epoch 507 | Validation Loss   0.01\n",
      "\tEpoch 508 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 508 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 508 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 508 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 508 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 508 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 508 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 508 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 508 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 508 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 508 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 508 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 508 | Training Loss   0.01\n",
      "Epoch 508 | Validation Loss   0.01\n",
      "\tEpoch 509 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 509 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 509 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 509 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 509 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 509 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 509 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 509 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 509 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 509 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 509 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 509 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 509 | Training Loss   0.01\n",
      "Epoch 509 | Validation Loss   0.01\n",
      "\tEpoch 510 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 510 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 510 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 510 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 510 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 510 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 510 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 510 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 510 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 510 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 510 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 510 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 510 | Training Loss   0.01\n",
      "Epoch 510 | Validation Loss   0.01\n",
      "\tEpoch 511 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 511 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 511 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 511 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 511 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 511 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 511 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 511 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 511 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 511 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 511 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 511 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 511 | Training Loss   0.01\n",
      "Epoch 511 | Validation Loss   0.01\n",
      "\tEpoch 512 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 512 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 512 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 512 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 512 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 512 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 512 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 512 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 512 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 512 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 512 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 512 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 512 | Training Loss   0.01\n",
      "Epoch 512 | Validation Loss   0.01\n",
      "\tEpoch 513 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 513 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 513 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 513 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 513 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 513 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 513 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 513 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 513 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 513 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 513 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 513 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 513 | Training Loss   0.01\n",
      "Epoch 513 | Validation Loss   0.01\n",
      "\tEpoch 514 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 514 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 514 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 514 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 514 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 514 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 514 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 514 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 514 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 514 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 514 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 514 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 514 | Training Loss   0.01\n",
      "Epoch 514 | Validation Loss   0.01\n",
      "\tEpoch 515 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 515 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 515 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 515 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 515 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 515 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 515 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 515 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 515 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 515 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 515 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 515 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 515 | Training Loss   0.01\n",
      "Epoch 515 | Validation Loss   0.01\n",
      "\tEpoch 516 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 516 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 516 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 516 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 516 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 516 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 516 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 516 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 516 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 516 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 516 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 516 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 516 | Training Loss   0.01\n",
      "Epoch 516 | Validation Loss   0.01\n",
      "\tEpoch 517 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 517 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 517 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 517 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 517 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 517 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 517 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 517 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 517 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 517 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 517 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 517 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 517 | Training Loss   0.01\n",
      "Epoch 517 | Validation Loss   0.01\n",
      "\tEpoch 518 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 518 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 518 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 518 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 518 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 518 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 518 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 518 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 518 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 518 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 518 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 518 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 518 | Training Loss   0.01\n",
      "Epoch 518 | Validation Loss   0.01\n",
      "\tEpoch 519 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 519 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 519 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 519 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 519 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 519 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 519 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 519 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 519 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 519 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 519 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 519 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 519 | Training Loss   0.01\n",
      "Epoch 519 | Validation Loss   0.01\n",
      "\tEpoch 520 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 520 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 520 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 520 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 520 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 520 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 520 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 520 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 520 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 520 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 520 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 520 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 520 | Training Loss   0.01\n",
      "Epoch 520 | Validation Loss   0.01\n",
      "\tEpoch 521 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 521 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 521 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 521 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 521 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 521 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 521 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 521 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 521 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 521 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 521 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 521 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 521 | Training Loss   0.01\n",
      "Epoch 521 | Validation Loss   0.01\n",
      "\tEpoch 522 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 522 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 522 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 522 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 522 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 522 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 522 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 522 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 522 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 522 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 522 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 522 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 522 | Training Loss   0.01\n",
      "Epoch 522 | Validation Loss   0.01\n",
      "\tEpoch 523 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 523 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 523 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 523 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 523 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 523 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 523 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 523 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 523 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 523 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 523 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 523 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 523 | Training Loss   0.01\n",
      "Epoch 523 | Validation Loss   0.01\n",
      "\tEpoch 524 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 524 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 524 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 524 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 524 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 524 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 524 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 524 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 524 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 524 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 524 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 524 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 524 | Training Loss   0.01\n",
      "Epoch 524 | Validation Loss   0.01\n",
      "\tEpoch 525 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 525 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 525 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 525 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 525 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 525 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 525 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 525 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 525 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 525 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 525 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 525 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 525 | Training Loss   0.01\n",
      "Epoch 525 | Validation Loss   0.01\n",
      "\tEpoch 526 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 526 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 526 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 526 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 526 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 526 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 526 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 526 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 526 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 526 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 526 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 526 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 526 | Training Loss   0.01\n",
      "Epoch 526 | Validation Loss   0.01\n",
      "\tEpoch 527 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 527 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 527 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 527 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 527 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 527 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 527 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 527 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 527 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 527 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 527 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 527 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 527 | Training Loss   0.01\n",
      "Epoch 527 | Validation Loss   0.01\n",
      "\tEpoch 528 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 528 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 528 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 528 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 528 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 528 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 528 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 528 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 528 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 528 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 528 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 528 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 528 | Training Loss   0.01\n",
      "Epoch 528 | Validation Loss   0.01\n",
      "\tEpoch 529 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 529 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 529 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 529 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 529 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 529 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 529 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 529 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 529 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 529 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 529 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 529 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 529 | Training Loss   0.01\n",
      "Epoch 529 | Validation Loss   0.01\n",
      "\tEpoch 530 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 530 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 530 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 530 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 530 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 530 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 530 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 530 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 530 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 530 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 530 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 530 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 530 | Training Loss   0.01\n",
      "Epoch 530 | Validation Loss   0.01\n",
      "\tEpoch 531 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 531 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 531 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 531 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 531 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 531 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 531 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 531 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 531 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 531 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 531 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 531 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 531 | Training Loss   0.01\n",
      "Epoch 531 | Validation Loss   0.01\n",
      "\tEpoch 532 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 532 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 532 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 532 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 532 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 532 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 532 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 532 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 532 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 532 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 532 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 532 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 532 | Training Loss   0.01\n",
      "Epoch 532 | Validation Loss   0.01\n",
      "\tEpoch 533 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 533 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 533 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 533 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 533 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 533 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 533 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 533 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 533 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 533 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 533 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 533 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 533 | Training Loss   0.01\n",
      "Epoch 533 | Validation Loss   0.01\n",
      "\tEpoch 534 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 534 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 534 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 534 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 534 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 534 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 534 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 534 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 534 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 534 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 534 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 534 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 534 | Training Loss   0.01\n",
      "Epoch 534 | Validation Loss   0.01\n",
      "\tEpoch 535 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 535 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 535 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 535 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 535 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 535 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 535 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 535 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 535 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 535 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 535 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 535 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 535 | Training Loss   0.01\n",
      "Epoch 535 | Validation Loss   0.01\n",
      "\tEpoch 536 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 536 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 536 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 536 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 536 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 536 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 536 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 536 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 536 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 536 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 536 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 536 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 536 | Training Loss   0.01\n",
      "Epoch 536 | Validation Loss   0.01\n",
      "\tEpoch 537 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 537 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 537 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 537 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 537 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 537 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 537 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 537 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 537 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 537 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 537 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 537 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 537 | Training Loss   0.01\n",
      "Epoch 537 | Validation Loss   0.01\n",
      "\tEpoch 538 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 538 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 538 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 538 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 538 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 538 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 538 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 538 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 538 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 538 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 538 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 538 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 538 | Training Loss   0.01\n",
      "Epoch 538 | Validation Loss   0.01\n",
      "\tEpoch 539 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 539 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 539 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 539 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 539 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 539 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 539 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 539 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 539 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 539 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 539 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 539 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 539 | Training Loss   0.01\n",
      "Epoch 539 | Validation Loss   0.01\n",
      "\tEpoch 540 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 540 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 540 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 540 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 540 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 540 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 540 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 540 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 540 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 540 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 540 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 540 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 540 | Training Loss   0.01\n",
      "Epoch 540 | Validation Loss   0.01\n",
      "\tEpoch 541 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 541 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 541 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 541 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 541 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 541 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 541 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 541 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 541 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 541 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 541 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 541 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 541 | Training Loss   0.01\n",
      "Epoch 541 | Validation Loss   0.01\n",
      "\tEpoch 542 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 542 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 542 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 542 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 542 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 542 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 542 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 542 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 542 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 542 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 542 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 542 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 542 | Training Loss   0.01\n",
      "Epoch 542 | Validation Loss   0.01\n",
      "\tEpoch 543 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 543 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 543 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 543 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 543 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 543 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 543 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 543 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 543 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 543 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 543 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 543 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 543 | Training Loss   0.01\n",
      "Epoch 543 | Validation Loss   0.01\n",
      "\tEpoch 544 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 544 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 544 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 544 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 544 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 544 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 544 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 544 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 544 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 544 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 544 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 544 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 544 | Training Loss   0.01\n",
      "Epoch 544 | Validation Loss   0.01\n",
      "\tEpoch 545 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 545 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 545 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 545 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 545 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 545 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 545 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 545 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 545 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 545 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 545 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 545 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 545 | Training Loss   0.01\n",
      "Epoch 545 | Validation Loss   0.01\n",
      "\tEpoch 546 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 546 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 546 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 546 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 546 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 546 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 546 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 546 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 546 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 546 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 546 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 546 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 546 | Training Loss   0.01\n",
      "Epoch 546 | Validation Loss   0.01\n",
      "\tEpoch 547 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 547 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 547 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 547 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 547 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 547 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 547 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 547 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 547 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 547 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 547 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 547 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 547 | Training Loss   0.01\n",
      "Epoch 547 | Validation Loss   0.01\n",
      "\tEpoch 548 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 548 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 548 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 548 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 548 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 548 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 548 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 548 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 548 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 548 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 548 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 548 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 548 | Training Loss   0.01\n",
      "Epoch 548 | Validation Loss   0.01\n",
      "\tEpoch 549 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 549 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 549 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 549 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 549 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 549 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 549 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 549 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 549 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 549 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 549 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 549 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 549 | Training Loss   0.01\n",
      "Epoch 549 | Validation Loss   0.01\n",
      "\tEpoch 550 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 550 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 550 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 550 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 550 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 550 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 550 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 550 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 550 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 550 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 550 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 550 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 550 | Training Loss   0.01\n",
      "Epoch 550 | Validation Loss   0.01\n",
      "\tEpoch 551 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 551 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 551 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 551 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 551 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 551 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 551 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 551 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 551 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 551 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 551 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 551 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 551 | Training Loss   0.01\n",
      "Epoch 551 | Validation Loss   0.01\n",
      "\tEpoch 552 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 552 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 552 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 552 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 552 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 552 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 552 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 552 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 552 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 552 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 552 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 552 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 552 | Training Loss   0.01\n",
      "Epoch 552 | Validation Loss   0.01\n",
      "\tEpoch 553 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 553 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 553 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 553 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 553 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 553 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 553 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 553 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 553 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 553 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 553 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 553 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 553 | Training Loss   0.01\n",
      "Epoch 553 | Validation Loss   0.01\n",
      "\tEpoch 554 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 554 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 554 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 554 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 554 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 554 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 554 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 554 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 554 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 554 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 554 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 554 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 554 | Training Loss   0.01\n",
      "Epoch 554 | Validation Loss   0.01\n",
      "\tEpoch 555 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 555 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 555 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 555 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 555 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 555 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 555 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 555 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 555 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 555 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 555 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 555 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 555 | Training Loss   0.01\n",
      "Epoch 555 | Validation Loss   0.01\n",
      "\tEpoch 556 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 556 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 556 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 556 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 556 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 556 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 556 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 556 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 556 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 556 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 556 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 556 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 556 | Training Loss   0.01\n",
      "Epoch 556 | Validation Loss   0.01\n",
      "\tEpoch 557 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 557 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 557 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 557 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 557 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 557 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 557 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 557 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 557 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 557 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 557 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 557 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 557 | Training Loss   0.01\n",
      "Epoch 557 | Validation Loss   0.01\n",
      "\tEpoch 558 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 558 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 558 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 558 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 558 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 558 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 558 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 558 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 558 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 558 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 558 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 558 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 558 | Training Loss   0.01\n",
      "Epoch 558 | Validation Loss   0.01\n",
      "\tEpoch 559 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 559 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 559 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 559 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 559 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 559 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 559 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 559 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 559 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 559 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 559 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 559 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 559 | Training Loss   0.01\n",
      "Epoch 559 | Validation Loss   0.01\n",
      "\tEpoch 560 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 560 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 560 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 560 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 560 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 560 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 560 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 560 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 560 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 560 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 560 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 560 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 560 | Training Loss   0.01\n",
      "Epoch 560 | Validation Loss   0.01\n",
      "\tEpoch 561 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 561 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 561 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 561 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 561 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 561 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 561 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 561 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 561 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 561 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 561 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 561 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 561 | Training Loss   0.01\n",
      "Epoch 561 | Validation Loss   0.01\n",
      "\tEpoch 562 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 562 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 562 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 562 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 562 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 562 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 562 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 562 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 562 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 562 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 562 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 562 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 562 | Training Loss   0.01\n",
      "Epoch 562 | Validation Loss   0.01\n",
      "\tEpoch 563 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 563 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 563 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 563 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 563 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 563 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 563 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 563 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 563 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 563 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 563 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 563 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 563 | Training Loss   0.01\n",
      "Epoch 563 | Validation Loss   0.01\n",
      "\tEpoch 564 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 564 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 564 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 564 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 564 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 564 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 564 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 564 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 564 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 564 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 564 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 564 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 564 | Training Loss   0.01\n",
      "Epoch 564 | Validation Loss   0.01\n",
      "\tEpoch 565 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 565 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 565 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 565 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 565 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 565 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 565 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 565 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 565 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 565 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 565 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 565 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 565 | Training Loss   0.01\n",
      "Epoch 565 | Validation Loss   0.01\n",
      "\tEpoch 566 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 566 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 566 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 566 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 566 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 566 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 566 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 566 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 566 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 566 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 566 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 566 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 566 | Training Loss   0.01\n",
      "Epoch 566 | Validation Loss   0.01\n",
      "\tEpoch 567 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 567 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 567 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 567 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 567 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 567 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 567 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 567 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 567 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 567 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 567 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 567 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 567 | Training Loss   0.01\n",
      "Epoch 567 | Validation Loss   0.01\n",
      "\tEpoch 568 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 568 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 568 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 568 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 568 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 568 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 568 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 568 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 568 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 568 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 568 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 568 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 568 | Training Loss   0.01\n",
      "Epoch 568 | Validation Loss   0.01\n",
      "\tEpoch 569 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 569 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 569 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 569 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 569 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 569 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 569 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 569 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 569 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 569 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 569 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 569 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 569 | Training Loss   0.01\n",
      "Epoch 569 | Validation Loss   0.01\n",
      "\tEpoch 570 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 570 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 570 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 570 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 570 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 570 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 570 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 570 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 570 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 570 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 570 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 570 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 570 | Training Loss   0.01\n",
      "Epoch 570 | Validation Loss   0.01\n",
      "\tEpoch 571 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 571 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 571 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 571 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 571 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 571 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 571 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 571 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 571 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 571 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 571 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 571 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 571 | Training Loss   0.01\n",
      "Epoch 571 | Validation Loss   0.01\n",
      "\tEpoch 572 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 572 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 572 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 572 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 572 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 572 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 572 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 572 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 572 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 572 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 572 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 572 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 572 | Training Loss   0.01\n",
      "Epoch 572 | Validation Loss   0.01\n",
      "\tEpoch 573 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 573 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 573 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 573 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 573 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 573 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 573 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 573 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 573 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 573 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 573 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 573 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 573 | Training Loss   0.01\n",
      "Epoch 573 | Validation Loss   0.01\n",
      "\tEpoch 574 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 574 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 574 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 574 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 574 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 574 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 574 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 574 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 574 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 574 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 574 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 574 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 574 | Training Loss   0.01\n",
      "Epoch 574 | Validation Loss   0.01\n",
      "\tEpoch 575 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 575 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 575 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 575 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 575 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 575 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 575 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 575 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 575 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 575 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 575 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 575 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 575 | Training Loss   0.01\n",
      "Epoch 575 | Validation Loss   0.01\n",
      "\tEpoch 576 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 576 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 576 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 576 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 576 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 576 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 576 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 576 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 576 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 576 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 576 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 576 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 576 | Training Loss   0.01\n",
      "Epoch 576 | Validation Loss   0.01\n",
      "\tEpoch 577 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 577 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 577 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 577 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 577 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 577 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 577 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 577 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 577 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 577 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 577 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 577 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 577 | Training Loss   0.01\n",
      "Epoch 577 | Validation Loss   0.01\n",
      "\tEpoch 578 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 578 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 578 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 578 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 578 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 578 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 578 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 578 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 578 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 578 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 578 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 578 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 578 | Training Loss   0.01\n",
      "Epoch 578 | Validation Loss   0.01\n",
      "\tEpoch 579 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 579 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 579 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 579 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 579 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 579 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 579 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 579 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 579 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 579 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 579 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 579 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 579 | Training Loss   0.01\n",
      "Epoch 579 | Validation Loss   0.01\n",
      "\tEpoch 580 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 580 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 580 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 580 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 580 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 580 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 580 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 580 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 580 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 580 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 580 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 580 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 580 | Training Loss   0.01\n",
      "Epoch 580 | Validation Loss   0.01\n",
      "\tEpoch 581 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 581 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 581 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 581 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 581 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 581 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 581 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 581 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 581 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 581 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 581 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 581 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 581 | Training Loss   0.01\n",
      "Epoch 581 | Validation Loss   0.01\n",
      "\tEpoch 582 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 582 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 582 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 582 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 582 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 582 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 582 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 582 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 582 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 582 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 582 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 582 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 582 | Training Loss   0.01\n",
      "Epoch 582 | Validation Loss   0.01\n",
      "\tEpoch 583 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 583 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 583 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 583 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 583 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 583 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 583 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 583 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 583 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 583 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 583 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 583 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 583 | Training Loss   0.01\n",
      "Epoch 583 | Validation Loss   0.01\n",
      "\tEpoch 584 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 584 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 584 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 584 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 584 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 584 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 584 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 584 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 584 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 584 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 584 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 584 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 584 | Training Loss   0.01\n",
      "Epoch 584 | Validation Loss   0.01\n",
      "\tEpoch 585 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 585 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 585 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 585 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 585 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 585 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 585 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 585 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 585 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 585 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 585 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 585 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 585 | Training Loss   0.01\n",
      "Epoch 585 | Validation Loss   0.01\n",
      "\tEpoch 586 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 586 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 586 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 586 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 586 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 586 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 586 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 586 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 586 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 586 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 586 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 586 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 586 | Training Loss   0.01\n",
      "Epoch 586 | Validation Loss   0.01\n",
      "\tEpoch 587 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 587 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 587 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 587 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 587 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 587 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 587 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 587 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 587 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 587 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 587 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 587 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 587 | Training Loss   0.01\n",
      "Epoch 587 | Validation Loss   0.01\n",
      "\tEpoch 588 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 588 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 588 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 588 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 588 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 588 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 588 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 588 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 588 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 588 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 588 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 588 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 588 | Training Loss   0.01\n",
      "Epoch 588 | Validation Loss   0.01\n",
      "\tEpoch 589 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 589 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 589 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 589 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 589 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 589 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 589 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 589 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 589 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 589 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 589 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 589 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 589 | Training Loss   0.01\n",
      "Epoch 589 | Validation Loss   0.01\n",
      "\tEpoch 590 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 590 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 590 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 590 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 590 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 590 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 590 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 590 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 590 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 590 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 590 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 590 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 590 | Training Loss   0.01\n",
      "Epoch 590 | Validation Loss   0.01\n",
      "\tEpoch 591 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 591 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 591 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 591 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 591 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 591 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 591 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 591 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 591 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 591 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 591 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 591 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 591 | Training Loss   0.01\n",
      "Epoch 591 | Validation Loss   0.01\n",
      "\tEpoch 592 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 592 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 592 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 592 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 592 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 592 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 592 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 592 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 592 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 592 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 592 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 592 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 592 | Training Loss   0.01\n",
      "Epoch 592 | Validation Loss   0.01\n",
      "\tEpoch 593 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 593 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 593 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 593 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 593 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 593 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 593 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 593 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 593 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 593 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 593 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 593 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 593 | Training Loss   0.01\n",
      "Epoch 593 | Validation Loss   0.01\n",
      "\tEpoch 594 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 594 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 594 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 594 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 594 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 594 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 594 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 594 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 594 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 594 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 594 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 594 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 594 | Training Loss   0.01\n",
      "Epoch 594 | Validation Loss   0.01\n",
      "\tEpoch 595 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 595 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 595 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 595 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 595 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 595 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 595 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 595 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 595 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 595 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 595 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 595 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 595 | Training Loss   0.01\n",
      "Epoch 595 | Validation Loss   0.01\n",
      "\tEpoch 596 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 596 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 596 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 596 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 596 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 596 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 596 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 596 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 596 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 596 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 596 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 596 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 596 | Training Loss   0.01\n",
      "Epoch 596 | Validation Loss   0.01\n",
      "\tEpoch 597 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 597 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 597 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 597 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 597 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 597 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 597 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 597 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 597 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 597 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 597 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 597 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 597 | Training Loss   0.01\n",
      "Epoch 597 | Validation Loss   0.01\n",
      "\tEpoch 598 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 598 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 598 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 598 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 598 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 598 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 598 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 598 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 598 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 598 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 598 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 598 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 598 | Training Loss   0.01\n",
      "Epoch 598 | Validation Loss   0.01\n",
      "\tEpoch 599 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 599 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 599 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 599 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 599 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 599 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 599 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 599 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 599 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 599 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 599 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 599 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 599 | Training Loss   0.01\n",
      "Epoch 599 | Validation Loss   0.01\n",
      "\tEpoch 600 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 600 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 600 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 600 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 600 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 600 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 600 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 600 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 600 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 600 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 600 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 600 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 600 | Training Loss   0.01\n",
      "Epoch 600 | Validation Loss   0.01\n",
      "\tEpoch 601 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 601 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 601 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 601 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 601 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 601 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 601 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 601 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 601 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 601 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 601 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 601 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 601 | Training Loss   0.01\n",
      "Epoch 601 | Validation Loss   0.01\n",
      "\tEpoch 602 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 602 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 602 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 602 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 602 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 602 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 602 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 602 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 602 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 602 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 602 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 602 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 602 | Training Loss   0.01\n",
      "Epoch 602 | Validation Loss   0.01\n",
      "\tEpoch 603 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 603 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 603 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 603 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 603 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 603 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 603 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 603 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 603 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 603 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 603 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 603 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 603 | Training Loss   0.01\n",
      "Epoch 603 | Validation Loss   0.01\n",
      "\tEpoch 604 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 604 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 604 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 604 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 604 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 604 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 604 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 604 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 604 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 604 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 604 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 604 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 604 | Training Loss   0.01\n",
      "Epoch 604 | Validation Loss   0.01\n",
      "\tEpoch 605 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 605 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 605 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 605 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 605 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 605 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 605 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 605 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 605 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 605 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 605 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 605 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 605 | Training Loss   0.01\n",
      "Epoch 605 | Validation Loss   0.01\n",
      "\tEpoch 606 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 606 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 606 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 606 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 606 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 606 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 606 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 606 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 606 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 606 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 606 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 606 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 606 | Training Loss   0.01\n",
      "Epoch 606 | Validation Loss   0.01\n",
      "\tEpoch 607 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 607 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 607 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 607 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 607 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 607 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 607 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 607 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 607 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 607 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 607 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 607 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 607 | Training Loss   0.01\n",
      "Epoch 607 | Validation Loss   0.01\n",
      "\tEpoch 608 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 608 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 608 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 608 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 608 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 608 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 608 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 608 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 608 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 608 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 608 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 608 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 608 | Training Loss   0.01\n",
      "Epoch 608 | Validation Loss   0.01\n",
      "\tEpoch 609 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 609 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 609 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 609 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 609 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 609 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 609 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 609 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 609 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 609 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 609 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 609 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 609 | Training Loss   0.01\n",
      "Epoch 609 | Validation Loss   0.01\n",
      "\tEpoch 610 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 610 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 610 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 610 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 610 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 610 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 610 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 610 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 610 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 610 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 610 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 610 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 610 | Training Loss   0.01\n",
      "Epoch 610 | Validation Loss   0.01\n",
      "\tEpoch 611 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 611 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 611 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 611 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 611 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 611 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 611 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 611 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 611 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 611 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 611 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 611 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 611 | Training Loss   0.01\n",
      "Epoch 611 | Validation Loss   0.01\n",
      "\tEpoch 612 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 612 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 612 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 612 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 612 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 612 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 612 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 612 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 612 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 612 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 612 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 612 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 612 | Training Loss   0.01\n",
      "Epoch 612 | Validation Loss   0.01\n",
      "\tEpoch 613 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 613 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 613 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 613 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 613 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 613 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 613 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 613 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 613 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 613 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 613 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 613 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 613 | Training Loss   0.01\n",
      "Epoch 613 | Validation Loss   0.01\n",
      "\tEpoch 614 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 614 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 614 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 614 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 614 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 614 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 614 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 614 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 614 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 614 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 614 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 614 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 614 | Training Loss   0.01\n",
      "Epoch 614 | Validation Loss   0.01\n",
      "\tEpoch 615 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 615 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 615 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 615 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 615 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 615 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 615 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 615 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 615 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 615 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 615 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 615 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 615 | Training Loss   0.01\n",
      "Epoch 615 | Validation Loss   0.01\n",
      "\tEpoch 616 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 616 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 616 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 616 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 616 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 616 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 616 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 616 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 616 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 616 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 616 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 616 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 616 | Training Loss   0.01\n",
      "Epoch 616 | Validation Loss   0.01\n",
      "\tEpoch 617 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 617 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 617 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 617 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 617 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 617 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 617 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 617 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 617 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 617 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 617 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 617 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 617 | Training Loss   0.01\n",
      "Epoch 617 | Validation Loss   0.01\n",
      "\tEpoch 618 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 618 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 618 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 618 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 618 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 618 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 618 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 618 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 618 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 618 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 618 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 618 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 618 | Training Loss   0.01\n",
      "Epoch 618 | Validation Loss   0.01\n",
      "\tEpoch 619 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 619 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 619 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 619 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 619 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 619 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 619 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 619 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 619 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 619 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 619 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 619 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 619 | Training Loss   0.01\n",
      "Epoch 619 | Validation Loss   0.01\n",
      "\tEpoch 620 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 620 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 620 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 620 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 620 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 620 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 620 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 620 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 620 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 620 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 620 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 620 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 620 | Training Loss   0.01\n",
      "Epoch 620 | Validation Loss   0.01\n",
      "\tEpoch 621 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 621 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 621 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 621 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 621 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 621 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 621 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 621 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 621 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 621 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 621 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 621 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 621 | Training Loss   0.01\n",
      "Epoch 621 | Validation Loss   0.01\n",
      "\tEpoch 622 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 622 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 622 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 622 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 622 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 622 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 622 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 622 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 622 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 622 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 622 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 622 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 622 | Training Loss   0.01\n",
      "Epoch 622 | Validation Loss   0.01\n",
      "\tEpoch 623 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 623 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 623 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 623 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 623 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 623 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 623 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 623 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 623 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 623 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 623 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 623 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 623 | Training Loss   0.01\n",
      "Epoch 623 | Validation Loss   0.01\n",
      "\tEpoch 624 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 624 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 624 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 624 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 624 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 624 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 624 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 624 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 624 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 624 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 624 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 624 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 624 | Training Loss   0.01\n",
      "Epoch 624 | Validation Loss   0.01\n",
      "\tEpoch 625 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 625 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 625 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 625 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 625 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 625 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 625 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 625 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 625 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 625 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 625 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 625 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 625 | Training Loss   0.01\n",
      "Epoch 625 | Validation Loss   0.01\n",
      "\tEpoch 626 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 626 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 626 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 626 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 626 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 626 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 626 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 626 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 626 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 626 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 626 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 626 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 626 | Training Loss   0.01\n",
      "Epoch 626 | Validation Loss   0.01\n",
      "\tEpoch 627 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 627 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 627 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 627 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 627 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 627 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 627 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 627 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 627 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 627 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 627 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 627 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 627 | Training Loss   0.01\n",
      "Epoch 627 | Validation Loss   0.01\n",
      "\tEpoch 628 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 628 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 628 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 628 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 628 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 628 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 628 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 628 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 628 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 628 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 628 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 628 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 628 | Training Loss   0.01\n",
      "Epoch 628 | Validation Loss   0.01\n",
      "\tEpoch 629 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 629 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 629 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 629 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 629 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 629 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 629 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 629 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 629 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 629 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 629 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 629 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 629 | Training Loss   0.01\n",
      "Epoch 629 | Validation Loss   0.01\n",
      "\tEpoch 630 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 630 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 630 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 630 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 630 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 630 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 630 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 630 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 630 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 630 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 630 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 630 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 630 | Training Loss   0.01\n",
      "Epoch 630 | Validation Loss   0.01\n",
      "\tEpoch 631 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 631 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 631 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 631 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 631 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 631 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 631 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 631 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 631 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 631 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 631 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 631 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 631 | Training Loss   0.01\n",
      "Epoch 631 | Validation Loss   0.01\n",
      "\tEpoch 632 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 632 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 632 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 632 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 632 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 632 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 632 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 632 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 632 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 632 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 632 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 632 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 632 | Training Loss   0.01\n",
      "Epoch 632 | Validation Loss   0.01\n",
      "\tEpoch 633 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 633 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 633 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 633 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 633 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 633 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 633 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 633 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 633 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 633 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 633 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 633 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 633 | Training Loss   0.01\n",
      "Epoch 633 | Validation Loss   0.01\n",
      "\tEpoch 634 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 634 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 634 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 634 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 634 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 634 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 634 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 634 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 634 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 634 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 634 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 634 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 634 | Training Loss   0.01\n",
      "Epoch 634 | Validation Loss   0.01\n",
      "\tEpoch 635 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 635 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 635 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 635 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 635 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 635 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 635 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 635 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 635 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 635 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 635 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 635 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 635 | Training Loss   0.01\n",
      "Epoch 635 | Validation Loss   0.01\n",
      "\tEpoch 636 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 636 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 636 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 636 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 636 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 636 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 636 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 636 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 636 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 636 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 636 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 636 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 636 | Training Loss   0.01\n",
      "Epoch 636 | Validation Loss   0.01\n",
      "\tEpoch 637 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 637 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 637 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 637 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 637 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 637 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 637 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 637 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 637 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 637 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 637 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 637 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 637 | Training Loss   0.01\n",
      "Epoch 637 | Validation Loss   0.01\n",
      "\tEpoch 638 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 638 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 638 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 638 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 638 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 638 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 638 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 638 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 638 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 638 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 638 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 638 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 638 | Training Loss   0.01\n",
      "Epoch 638 | Validation Loss   0.01\n",
      "\tEpoch 639 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 639 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 639 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 639 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 639 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 639 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 639 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 639 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 639 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 639 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 639 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 639 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 639 | Training Loss   0.01\n",
      "Epoch 639 | Validation Loss   0.01\n",
      "\tEpoch 640 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 640 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 640 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 640 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 640 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 640 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 640 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 640 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 640 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 640 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 640 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 640 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 640 | Training Loss   0.01\n",
      "Epoch 640 | Validation Loss   0.01\n",
      "\tEpoch 641 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 641 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 641 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 641 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 641 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 641 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 641 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 641 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 641 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 641 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 641 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 641 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 641 | Training Loss   0.01\n",
      "Epoch 641 | Validation Loss   0.01\n",
      "\tEpoch 642 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 642 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 642 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 642 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 642 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 642 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 642 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 642 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 642 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 642 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 642 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 642 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 642 | Training Loss   0.01\n",
      "Epoch 642 | Validation Loss   0.01\n",
      "\tEpoch 643 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 643 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 643 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 643 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 643 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 643 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 643 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 643 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 643 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 643 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 643 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 643 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 643 | Training Loss   0.01\n",
      "Epoch 643 | Validation Loss   0.01\n",
      "\tEpoch 644 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 644 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 644 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 644 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 644 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 644 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 644 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 644 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 644 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 644 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 644 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 644 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 644 | Training Loss   0.01\n",
      "Epoch 644 | Validation Loss   0.01\n",
      "\tEpoch 645 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 645 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 645 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 645 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 645 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 645 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 645 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 645 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 645 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 645 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 645 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 645 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 645 | Training Loss   0.01\n",
      "Epoch 645 | Validation Loss   0.01\n",
      "\tEpoch 646 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 646 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 646 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 646 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 646 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 646 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 646 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 646 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 646 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 646 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 646 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 646 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 646 | Training Loss   0.01\n",
      "Epoch 646 | Validation Loss   0.01\n",
      "\tEpoch 647 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 647 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 647 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 647 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 647 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 647 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 647 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 647 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 647 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 647 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 647 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 647 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 647 | Training Loss   0.01\n",
      "Epoch 647 | Validation Loss   0.01\n",
      "\tEpoch 648 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 648 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 648 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 648 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 648 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 648 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 648 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 648 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 648 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 648 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 648 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 648 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 648 | Training Loss   0.01\n",
      "Epoch 648 | Validation Loss   0.01\n",
      "\tEpoch 649 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 649 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 649 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 649 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 649 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 649 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 649 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 649 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 649 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 649 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 649 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 649 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 649 | Training Loss   0.01\n",
      "Epoch 649 | Validation Loss   0.01\n",
      "\tEpoch 650 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 650 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 650 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 650 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 650 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 650 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 650 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 650 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 650 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 650 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 650 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 650 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 650 | Training Loss   0.01\n",
      "Epoch 650 | Validation Loss   0.01\n",
      "\tEpoch 651 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 651 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 651 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 651 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 651 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 651 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 651 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 651 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 651 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 651 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 651 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 651 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 651 | Training Loss   0.01\n",
      "Epoch 651 | Validation Loss   0.01\n",
      "\tEpoch 652 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 652 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 652 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 652 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 652 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 652 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 652 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 652 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 652 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 652 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 652 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 652 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 652 | Training Loss   0.01\n",
      "Epoch 652 | Validation Loss   0.01\n",
      "\tEpoch 653 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 653 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 653 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 653 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 653 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 653 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 653 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 653 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 653 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 653 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 653 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 653 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 653 | Training Loss   0.01\n",
      "Epoch 653 | Validation Loss   0.01\n",
      "\tEpoch 654 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 654 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 654 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 654 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 654 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 654 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 654 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 654 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 654 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 654 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 654 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 654 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 654 | Training Loss   0.01\n",
      "Epoch 654 | Validation Loss   0.01\n",
      "\tEpoch 655 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 655 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 655 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 655 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 655 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 655 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 655 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 655 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 655 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 655 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 655 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 655 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 655 | Training Loss   0.01\n",
      "Epoch 655 | Validation Loss   0.01\n",
      "\tEpoch 656 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 656 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 656 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 656 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 656 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 656 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 656 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 656 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 656 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 656 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 656 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 656 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 656 | Training Loss   0.01\n",
      "Epoch 656 | Validation Loss   0.01\n",
      "\tEpoch 657 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 657 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 657 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 657 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 657 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 657 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 657 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 657 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 657 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 657 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 657 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 657 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 657 | Training Loss   0.01\n",
      "Epoch 657 | Validation Loss   0.01\n",
      "\tEpoch 658 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 658 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 658 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 658 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 658 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 658 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 658 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 658 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 658 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 658 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 658 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 658 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 658 | Training Loss   0.01\n",
      "Epoch 658 | Validation Loss   0.01\n",
      "\tEpoch 659 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 659 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 659 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 659 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 659 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 659 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 659 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 659 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 659 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 659 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 659 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 659 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 659 | Training Loss   0.01\n",
      "Epoch 659 | Validation Loss   0.01\n",
      "\tEpoch 660 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 660 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 660 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 660 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 660 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 660 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 660 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 660 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 660 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 660 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 660 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 660 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 660 | Training Loss   0.01\n",
      "Epoch 660 | Validation Loss   0.01\n",
      "\tEpoch 661 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 661 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 661 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 661 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 661 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 661 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 661 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 661 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 661 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 661 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 661 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 661 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 661 | Training Loss   0.01\n",
      "Epoch 661 | Validation Loss   0.01\n",
      "\tEpoch 662 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 662 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 662 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 662 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 662 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 662 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 662 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 662 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 662 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 662 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 662 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 662 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 662 | Training Loss   0.01\n",
      "Epoch 662 | Validation Loss   0.01\n",
      "\tEpoch 663 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 663 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 663 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 663 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 663 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 663 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 663 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 663 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 663 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 663 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 663 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 663 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 663 | Training Loss   0.01\n",
      "Epoch 663 | Validation Loss   0.01\n",
      "\tEpoch 664 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 664 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 664 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 664 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 664 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 664 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 664 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 664 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 664 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 664 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 664 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 664 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 664 | Training Loss   0.01\n",
      "Epoch 664 | Validation Loss   0.01\n",
      "\tEpoch 665 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 665 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 665 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 665 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 665 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 665 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 665 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 665 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 665 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 665 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 665 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 665 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 665 | Training Loss   0.01\n",
      "Epoch 665 | Validation Loss   0.01\n",
      "\tEpoch 666 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 666 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 666 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 666 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 666 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 666 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 666 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 666 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 666 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 666 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 666 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 666 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 666 | Training Loss   0.01\n",
      "Epoch 666 | Validation Loss   0.01\n",
      "\tEpoch 667 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 667 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 667 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 667 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 667 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 667 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 667 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 667 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 667 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 667 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 667 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 667 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 667 | Training Loss   0.01\n",
      "Epoch 667 | Validation Loss   0.01\n",
      "\tEpoch 668 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 668 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 668 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 668 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 668 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 668 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 668 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 668 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 668 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 668 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 668 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 668 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 668 | Training Loss   0.01\n",
      "Epoch 668 | Validation Loss   0.01\n",
      "\tEpoch 669 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 669 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 669 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 669 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 669 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 669 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 669 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 669 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 669 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 669 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 669 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 669 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 669 | Training Loss   0.01\n",
      "Epoch 669 | Validation Loss   0.01\n",
      "\tEpoch 670 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 670 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 670 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 670 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 670 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 670 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 670 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 670 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 670 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 670 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 670 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 670 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 670 | Training Loss   0.01\n",
      "Epoch 670 | Validation Loss   0.01\n",
      "\tEpoch 671 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 671 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 671 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 671 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 671 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 671 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 671 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 671 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 671 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 671 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 671 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 671 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 671 | Training Loss   0.01\n",
      "Epoch 671 | Validation Loss   0.01\n",
      "\tEpoch 672 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 672 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 672 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 672 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 672 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 672 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 672 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 672 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 672 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 672 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 672 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 672 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 672 | Training Loss   0.01\n",
      "Epoch 672 | Validation Loss   0.01\n",
      "\tEpoch 673 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 673 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 673 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 673 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 673 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 673 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 673 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 673 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 673 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 673 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 673 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 673 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 673 | Training Loss   0.01\n",
      "Epoch 673 | Validation Loss   0.01\n",
      "\tEpoch 674 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 674 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 674 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 674 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 674 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 674 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 674 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 674 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 674 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 674 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 674 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 674 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 674 | Training Loss   0.01\n",
      "Epoch 674 | Validation Loss   0.01\n",
      "\tEpoch 675 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 675 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 675 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 675 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 675 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 675 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 675 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 675 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 675 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 675 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 675 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 675 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 675 | Training Loss   0.01\n",
      "Epoch 675 | Validation Loss   0.01\n",
      "\tEpoch 676 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 676 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 676 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 676 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 676 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 676 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 676 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 676 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 676 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 676 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 676 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 676 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 676 | Training Loss   0.01\n",
      "Epoch 676 | Validation Loss   0.01\n",
      "\tEpoch 677 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 677 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 677 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 677 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 677 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 677 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 677 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 677 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 677 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 677 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 677 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 677 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 677 | Training Loss   0.01\n",
      "Epoch 677 | Validation Loss   0.01\n",
      "\tEpoch 678 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 678 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 678 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 678 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 678 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 678 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 678 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 678 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 678 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 678 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 678 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 678 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 678 | Training Loss   0.01\n",
      "Epoch 678 | Validation Loss   0.01\n",
      "\tEpoch 679 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 679 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 679 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 679 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 679 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 679 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 679 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 679 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 679 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 679 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 679 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 679 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 679 | Training Loss   0.01\n",
      "Epoch 679 | Validation Loss   0.01\n",
      "\tEpoch 680 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 680 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 680 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 680 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 680 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 680 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 680 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 680 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 680 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 680 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 680 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 680 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 680 | Training Loss   0.01\n",
      "Epoch 680 | Validation Loss   0.01\n",
      "\tEpoch 681 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 681 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 681 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 681 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 681 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 681 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 681 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 681 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 681 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 681 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 681 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 681 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 681 | Training Loss   0.01\n",
      "Epoch 681 | Validation Loss   0.01\n",
      "\tEpoch 682 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 682 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 682 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 682 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 682 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 682 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 682 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 682 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 682 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 682 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 682 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 682 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 682 | Training Loss   0.01\n",
      "Epoch 682 | Validation Loss   0.01\n",
      "\tEpoch 683 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 683 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 683 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 683 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 683 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 683 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 683 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 683 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 683 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 683 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 683 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 683 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 683 | Training Loss   0.01\n",
      "Epoch 683 | Validation Loss   0.01\n",
      "\tEpoch 684 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 684 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 684 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 684 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 684 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 684 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 684 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 684 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 684 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 684 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 684 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 684 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 684 | Training Loss   0.01\n",
      "Epoch 684 | Validation Loss   0.01\n",
      "\tEpoch 685 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 685 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 685 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 685 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 685 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 685 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 685 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 685 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 685 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 685 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 685 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 685 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 685 | Training Loss   0.01\n",
      "Epoch 685 | Validation Loss   0.01\n",
      "\tEpoch 686 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 686 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 686 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 686 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 686 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 686 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 686 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 686 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 686 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 686 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 686 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 686 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 686 | Training Loss   0.01\n",
      "Epoch 686 | Validation Loss   0.01\n",
      "\tEpoch 687 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 687 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 687 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 687 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 687 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 687 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 687 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 687 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 687 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 687 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 687 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 687 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 687 | Training Loss   0.01\n",
      "Epoch 687 | Validation Loss   0.01\n",
      "\tEpoch 688 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 688 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 688 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 688 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 688 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 688 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 688 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 688 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 688 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 688 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 688 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 688 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 688 | Training Loss   0.01\n",
      "Epoch 688 | Validation Loss   0.01\n",
      "\tEpoch 689 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 689 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 689 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 689 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 689 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 689 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 689 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 689 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 689 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 689 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 689 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 689 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 689 | Training Loss   0.01\n",
      "Epoch 689 | Validation Loss   0.01\n",
      "\tEpoch 690 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 690 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 690 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 690 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 690 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 690 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 690 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 690 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 690 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 690 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 690 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 690 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 690 | Training Loss   0.01\n",
      "Epoch 690 | Validation Loss   0.01\n",
      "\tEpoch 691 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 691 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 691 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 691 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 691 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 691 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 691 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 691 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 691 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 691 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 691 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 691 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 691 | Training Loss   0.01\n",
      "Epoch 691 | Validation Loss   0.01\n",
      "\tEpoch 692 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 692 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 692 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 692 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 692 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 692 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 692 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 692 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 692 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 692 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 692 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 692 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 692 | Training Loss   0.01\n",
      "Epoch 692 | Validation Loss   0.01\n",
      "\tEpoch 693 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 693 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 693 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 693 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 693 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 693 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 693 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 693 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 693 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 693 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 693 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 693 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 693 | Training Loss   0.01\n",
      "Epoch 693 | Validation Loss   0.01\n",
      "\tEpoch 694 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 694 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 694 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 694 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 694 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 694 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 694 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 694 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 694 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 694 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 694 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 694 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 694 | Training Loss   0.01\n",
      "Epoch 694 | Validation Loss   0.01\n",
      "\tEpoch 695 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 695 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 695 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 695 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 695 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 695 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 695 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 695 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 695 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 695 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 695 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 695 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 695 | Training Loss   0.01\n",
      "Epoch 695 | Validation Loss   0.01\n",
      "\tEpoch 696 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 696 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 696 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 696 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 696 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 696 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 696 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 696 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 696 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 696 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 696 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 696 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 696 | Training Loss   0.01\n",
      "Epoch 696 | Validation Loss   0.01\n",
      "\tEpoch 697 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 697 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 697 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 697 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 697 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 697 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 697 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 697 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 697 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 697 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 697 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 697 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 697 | Training Loss   0.01\n",
      "Epoch 697 | Validation Loss   0.01\n",
      "\tEpoch 698 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 698 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 698 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 698 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 698 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 698 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 698 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 698 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 698 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 698 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 698 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 698 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 698 | Training Loss   0.01\n",
      "Epoch 698 | Validation Loss   0.01\n",
      "\tEpoch 699 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 699 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 699 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 699 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 699 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 699 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 699 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 699 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 699 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 699 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 699 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 699 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 699 | Training Loss   0.01\n",
      "Epoch 699 | Validation Loss   0.01\n",
      "\tEpoch 700 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 700 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 700 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 700 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 700 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 700 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 700 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 700 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 700 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 700 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 700 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 700 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 700 | Training Loss   0.01\n",
      "Epoch 700 | Validation Loss   0.01\n",
      "\tEpoch 701 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 701 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 701 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 701 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 701 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 701 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 701 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 701 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 701 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 701 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 701 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 701 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 701 | Training Loss   0.01\n",
      "Epoch 701 | Validation Loss   0.01\n",
      "\tEpoch 702 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 702 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 702 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 702 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 702 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 702 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 702 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 702 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 702 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 702 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 702 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 702 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 702 | Training Loss   0.01\n",
      "Epoch 702 | Validation Loss   0.01\n",
      "\tEpoch 703 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 703 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 703 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 703 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 703 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 703 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 703 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 703 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 703 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 703 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 703 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 703 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 703 | Training Loss   0.01\n",
      "Epoch 703 | Validation Loss   0.01\n",
      "\tEpoch 704 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 704 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 704 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 704 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 704 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 704 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 704 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 704 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 704 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 704 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 704 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 704 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 704 | Training Loss   0.01\n",
      "Epoch 704 | Validation Loss   0.01\n",
      "\tEpoch 705 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 705 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 705 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 705 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 705 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 705 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 705 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 705 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 705 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 705 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 705 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 705 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 705 | Training Loss   0.01\n",
      "Epoch 705 | Validation Loss   0.01\n",
      "\tEpoch 706 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 706 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 706 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 706 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 706 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 706 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 706 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 706 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 706 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 706 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 706 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 706 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 706 | Training Loss   0.01\n",
      "Epoch 706 | Validation Loss   0.01\n",
      "\tEpoch 707 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 707 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 707 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 707 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 707 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 707 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 707 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 707 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 707 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 707 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 707 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 707 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 707 | Training Loss   0.01\n",
      "Epoch 707 | Validation Loss   0.01\n",
      "\tEpoch 708 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 708 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 708 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 708 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 708 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 708 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 708 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 708 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 708 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 708 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 708 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 708 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 708 | Training Loss   0.01\n",
      "Epoch 708 | Validation Loss   0.01\n",
      "\tEpoch 709 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 709 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 709 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 709 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 709 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 709 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 709 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 709 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 709 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 709 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 709 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 709 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 709 | Training Loss   0.01\n",
      "Epoch 709 | Validation Loss   0.01\n",
      "\tEpoch 710 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 710 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 710 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 710 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 710 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 710 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 710 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 710 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 710 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 710 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 710 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 710 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 710 | Training Loss   0.01\n",
      "Epoch 710 | Validation Loss   0.01\n",
      "\tEpoch 711 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 711 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 711 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 711 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 711 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 711 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 711 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 711 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 711 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 711 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 711 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 711 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 711 | Training Loss   0.01\n",
      "Epoch 711 | Validation Loss   0.01\n",
      "\tEpoch 712 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 712 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 712 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 712 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 712 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 712 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 712 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 712 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 712 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 712 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 712 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 712 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 712 | Training Loss   0.01\n",
      "Epoch 712 | Validation Loss   0.01\n",
      "\tEpoch 713 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 713 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 713 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 713 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 713 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 713 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 713 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 713 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 713 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 713 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 713 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 713 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 713 | Training Loss   0.01\n",
      "Epoch 713 | Validation Loss   0.01\n",
      "\tEpoch 714 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 714 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 714 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 714 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 714 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 714 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 714 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 714 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 714 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 714 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 714 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 714 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 714 | Training Loss   0.01\n",
      "Epoch 714 | Validation Loss   0.01\n",
      "\tEpoch 715 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 715 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 715 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 715 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 715 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 715 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 715 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 715 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 715 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 715 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 715 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 715 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 715 | Training Loss   0.01\n",
      "Epoch 715 | Validation Loss   0.01\n",
      "\tEpoch 716 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 716 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 716 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 716 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 716 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 716 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 716 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 716 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 716 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 716 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 716 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 716 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 716 | Training Loss   0.01\n",
      "Epoch 716 | Validation Loss   0.01\n",
      "\tEpoch 717 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 717 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 717 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 717 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 717 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 717 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 717 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 717 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 717 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 717 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 717 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 717 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 717 | Training Loss   0.01\n",
      "Epoch 717 | Validation Loss   0.01\n",
      "\tEpoch 718 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 718 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 718 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 718 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 718 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 718 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 718 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 718 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 718 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 718 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 718 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 718 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 718 | Training Loss   0.01\n",
      "Epoch 718 | Validation Loss   0.01\n",
      "\tEpoch 719 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 719 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 719 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 719 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 719 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 719 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 719 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 719 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 719 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 719 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 719 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 719 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 719 | Training Loss   0.01\n",
      "Epoch 719 | Validation Loss   0.01\n",
      "\tEpoch 720 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 720 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 720 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 720 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 720 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 720 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 720 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 720 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 720 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 720 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 720 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 720 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 720 | Training Loss   0.01\n",
      "Epoch 720 | Validation Loss   0.01\n",
      "\tEpoch 721 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 721 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 721 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 721 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 721 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 721 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 721 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 721 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 721 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 721 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 721 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 721 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 721 | Training Loss   0.01\n",
      "Epoch 721 | Validation Loss   0.01\n",
      "\tEpoch 722 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 722 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 722 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 722 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 722 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 722 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 722 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 722 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 722 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 722 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 722 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 722 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 722 | Training Loss   0.01\n",
      "Epoch 722 | Validation Loss   0.01\n",
      "\tEpoch 723 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 723 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 723 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 723 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 723 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 723 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 723 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 723 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 723 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 723 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 723 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 723 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 723 | Training Loss   0.01\n",
      "Epoch 723 | Validation Loss   0.01\n",
      "\tEpoch 724 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 724 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 724 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 724 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 724 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 724 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 724 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 724 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 724 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 724 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 724 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 724 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 724 | Training Loss   0.01\n",
      "Epoch 724 | Validation Loss   0.01\n",
      "\tEpoch 725 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 725 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 725 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 725 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 725 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 725 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 725 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 725 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 725 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 725 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 725 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 725 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 725 | Training Loss   0.01\n",
      "Epoch 725 | Validation Loss   0.01\n",
      "\tEpoch 726 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 726 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 726 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 726 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 726 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 726 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 726 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 726 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 726 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 726 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 726 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 726 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 726 | Training Loss   0.01\n",
      "Epoch 726 | Validation Loss   0.01\n",
      "\tEpoch 727 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 727 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 727 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 727 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 727 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 727 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 727 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 727 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 727 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 727 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 727 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 727 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 727 | Training Loss   0.01\n",
      "Epoch 727 | Validation Loss   0.01\n",
      "\tEpoch 728 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 728 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 728 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 728 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 728 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 728 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 728 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 728 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 728 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 728 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 728 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 728 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 728 | Training Loss   0.01\n",
      "Epoch 728 | Validation Loss   0.01\n",
      "\tEpoch 729 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 729 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 729 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 729 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 729 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 729 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 729 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 729 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 729 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 729 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 729 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 729 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 729 | Training Loss   0.01\n",
      "Epoch 729 | Validation Loss   0.01\n",
      "\tEpoch 730 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 730 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 730 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 730 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 730 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 730 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 730 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 730 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 730 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 730 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 730 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 730 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 730 | Training Loss   0.01\n",
      "Epoch 730 | Validation Loss   0.01\n",
      "\tEpoch 731 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 731 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 731 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 731 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 731 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 731 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 731 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 731 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 731 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 731 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 731 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 731 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 731 | Training Loss   0.01\n",
      "Epoch 731 | Validation Loss   0.01\n",
      "\tEpoch 732 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 732 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 732 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 732 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 732 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 732 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 732 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 732 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 732 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 732 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 732 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 732 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 732 | Training Loss   0.01\n",
      "Epoch 732 | Validation Loss   0.01\n",
      "\tEpoch 733 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 733 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 733 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 733 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 733 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 733 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 733 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 733 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 733 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 733 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 733 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 733 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 733 | Training Loss   0.01\n",
      "Epoch 733 | Validation Loss   0.01\n",
      "\tEpoch 734 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 734 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 734 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 734 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 734 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 734 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 734 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 734 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 734 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 734 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 734 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 734 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 734 | Training Loss   0.01\n",
      "Epoch 734 | Validation Loss   0.01\n",
      "\tEpoch 735 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 735 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 735 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 735 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 735 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 735 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 735 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 735 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 735 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 735 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 735 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 735 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 735 | Training Loss   0.01\n",
      "Epoch 735 | Validation Loss   0.01\n",
      "\tEpoch 736 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 736 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 736 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 736 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 736 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 736 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 736 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 736 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 736 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 736 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 736 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 736 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 736 | Training Loss   0.01\n",
      "Epoch 736 | Validation Loss   0.01\n",
      "\tEpoch 737 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 737 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 737 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 737 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 737 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 737 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 737 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 737 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 737 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 737 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 737 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 737 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 737 | Training Loss   0.01\n",
      "Epoch 737 | Validation Loss   0.01\n",
      "\tEpoch 738 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 738 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 738 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 738 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 738 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 738 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 738 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 738 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 738 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 738 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 738 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 738 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 738 | Training Loss   0.01\n",
      "Epoch 738 | Validation Loss   0.01\n",
      "\tEpoch 739 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 739 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 739 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 739 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 739 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 739 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 739 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 739 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 739 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 739 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 739 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 739 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 739 | Training Loss   0.01\n",
      "Epoch 739 | Validation Loss   0.01\n",
      "\tEpoch 740 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 740 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 740 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 740 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 740 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 740 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 740 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 740 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 740 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 740 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 740 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 740 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 740 | Training Loss   0.01\n",
      "Epoch 740 | Validation Loss   0.01\n",
      "\tEpoch 741 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 741 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 741 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 741 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 741 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 741 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 741 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 741 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 741 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 741 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 741 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 741 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 741 | Training Loss   0.01\n",
      "Epoch 741 | Validation Loss   0.01\n",
      "\tEpoch 742 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 742 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 742 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 742 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 742 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 742 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 742 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 742 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 742 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 742 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 742 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 742 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 742 | Training Loss   0.01\n",
      "Epoch 742 | Validation Loss   0.01\n",
      "\tEpoch 743 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 743 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 743 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 743 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 743 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 743 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 743 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 743 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 743 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 743 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 743 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 743 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 743 | Training Loss   0.01\n",
      "Epoch 743 | Validation Loss   0.01\n",
      "\tEpoch 744 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 744 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 744 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 744 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 744 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 744 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 744 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 744 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 744 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 744 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 744 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 744 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 744 | Training Loss   0.01\n",
      "Epoch 744 | Validation Loss   0.01\n",
      "\tEpoch 745 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 745 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 745 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 745 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 745 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 745 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 745 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 745 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 745 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 745 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 745 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 745 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 745 | Training Loss   0.01\n",
      "Epoch 745 | Validation Loss   0.01\n",
      "\tEpoch 746 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 746 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 746 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 746 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 746 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 746 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 746 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 746 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 746 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 746 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 746 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 746 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 746 | Training Loss   0.01\n",
      "Epoch 746 | Validation Loss   0.01\n",
      "\tEpoch 747 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 747 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 747 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 747 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 747 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 747 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 747 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 747 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 747 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 747 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 747 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 747 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 747 | Training Loss   0.01\n",
      "Epoch 747 | Validation Loss   0.01\n",
      "\tEpoch 748 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 748 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 748 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 748 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 748 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 748 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 748 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 748 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 748 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 748 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 748 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 748 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 748 | Training Loss   0.01\n",
      "Epoch 748 | Validation Loss   0.01\n",
      "\tEpoch 749 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 749 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 749 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 749 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 749 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 749 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 749 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 749 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 749 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 749 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 749 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 749 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 749 | Training Loss   0.01\n",
      "Epoch 749 | Validation Loss   0.01\n",
      "\tEpoch 750 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 750 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 750 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 750 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 750 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 750 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 750 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 750 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 750 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 750 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 750 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 750 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 750 | Training Loss   0.01\n",
      "Epoch 750 | Validation Loss   0.01\n",
      "\tEpoch 751 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 751 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 751 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 751 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 751 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 751 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 751 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 751 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 751 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 751 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 751 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 751 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 751 | Training Loss   0.01\n",
      "Epoch 751 | Validation Loss   0.01\n",
      "\tEpoch 752 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 752 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 752 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 752 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 752 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 752 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 752 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 752 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 752 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 752 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 752 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 752 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 752 | Training Loss   0.01\n",
      "Epoch 752 | Validation Loss   0.01\n",
      "\tEpoch 753 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 753 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 753 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 753 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 753 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 753 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 753 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 753 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 753 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 753 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 753 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 753 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 753 | Training Loss   0.01\n",
      "Epoch 753 | Validation Loss   0.01\n",
      "\tEpoch 754 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 754 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 754 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 754 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 754 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 754 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 754 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 754 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 754 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 754 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 754 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 754 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 754 | Training Loss   0.01\n",
      "Epoch 754 | Validation Loss   0.01\n",
      "\tEpoch 755 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 755 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 755 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 755 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 755 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 755 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 755 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 755 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 755 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 755 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 755 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 755 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 755 | Training Loss   0.01\n",
      "Epoch 755 | Validation Loss   0.01\n",
      "\tEpoch 756 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 756 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 756 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 756 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 756 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 756 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 756 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 756 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 756 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 756 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 756 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 756 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 756 | Training Loss   0.01\n",
      "Epoch 756 | Validation Loss   0.01\n",
      "\tEpoch 757 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 757 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 757 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 757 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 757 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 757 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 757 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 757 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 757 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 757 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 757 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 757 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 757 | Training Loss   0.01\n",
      "Epoch 757 | Validation Loss   0.01\n",
      "\tEpoch 758 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 758 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 758 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 758 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 758 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 758 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 758 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 758 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 758 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 758 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 758 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 758 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 758 | Training Loss   0.01\n",
      "Epoch 758 | Validation Loss   0.01\n",
      "\tEpoch 759 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 759 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 759 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 759 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 759 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 759 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 759 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 759 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 759 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 759 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 759 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 759 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 759 | Training Loss   0.01\n",
      "Epoch 759 | Validation Loss   0.01\n",
      "\tEpoch 760 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 760 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 760 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 760 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 760 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 760 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 760 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 760 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 760 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 760 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 760 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 760 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 760 | Training Loss   0.01\n",
      "Epoch 760 | Validation Loss   0.01\n",
      "\tEpoch 761 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 761 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 761 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 761 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 761 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 761 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 761 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 761 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 761 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 761 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 761 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 761 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 761 | Training Loss   0.01\n",
      "Epoch 761 | Validation Loss   0.01\n",
      "\tEpoch 762 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 762 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 762 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 762 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 762 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 762 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 762 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 762 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 762 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 762 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 762 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 762 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 762 | Training Loss   0.01\n",
      "Epoch 762 | Validation Loss   0.01\n",
      "\tEpoch 763 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 763 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 763 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 763 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 763 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 763 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 763 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 763 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 763 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 763 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 763 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 763 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 763 | Training Loss   0.01\n",
      "Epoch 763 | Validation Loss   0.01\n",
      "\tEpoch 764 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 764 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 764 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 764 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 764 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 764 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 764 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 764 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 764 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 764 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 764 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 764 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 764 | Training Loss   0.01\n",
      "Epoch 764 | Validation Loss   0.01\n",
      "\tEpoch 765 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 765 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 765 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 765 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 765 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 765 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 765 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 765 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 765 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 765 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 765 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 765 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 765 | Training Loss   0.01\n",
      "Epoch 765 | Validation Loss   0.01\n",
      "\tEpoch 766 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 766 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 766 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 766 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 766 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 766 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 766 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 766 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 766 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 766 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 766 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 766 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 766 | Training Loss   0.01\n",
      "Epoch 766 | Validation Loss   0.01\n",
      "\tEpoch 767 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 767 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 767 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 767 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 767 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 767 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 767 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 767 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 767 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 767 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 767 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 767 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 767 | Training Loss   0.01\n",
      "Epoch 767 | Validation Loss   0.01\n",
      "\tEpoch 768 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 768 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 768 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 768 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 768 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 768 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 768 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 768 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 768 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 768 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 768 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 768 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 768 | Training Loss   0.01\n",
      "Epoch 768 | Validation Loss   0.01\n",
      "\tEpoch 769 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 769 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 769 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 769 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 769 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 769 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 769 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 769 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 769 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 769 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 769 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 769 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 769 | Training Loss   0.01\n",
      "Epoch 769 | Validation Loss   0.01\n",
      "\tEpoch 770 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 770 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 770 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 770 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 770 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 770 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 770 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 770 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 770 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 770 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 770 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 770 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 770 | Training Loss   0.01\n",
      "Epoch 770 | Validation Loss   0.01\n",
      "\tEpoch 771 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 771 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 771 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 771 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 771 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 771 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 771 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 771 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 771 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 771 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 771 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 771 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 771 | Training Loss   0.01\n",
      "Epoch 771 | Validation Loss   0.01\n",
      "\tEpoch 772 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 772 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 772 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 772 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 772 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 772 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 772 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 772 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 772 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 772 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 772 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 772 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 772 | Training Loss   0.01\n",
      "Epoch 772 | Validation Loss   0.01\n",
      "\tEpoch 773 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 773 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 773 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 773 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 773 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 773 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 773 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 773 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 773 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 773 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 773 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 773 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 773 | Training Loss   0.01\n",
      "Epoch 773 | Validation Loss   0.01\n",
      "\tEpoch 774 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 774 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 774 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 774 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 774 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 774 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 774 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 774 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 774 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 774 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 774 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 774 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 774 | Training Loss   0.01\n",
      "Epoch 774 | Validation Loss   0.01\n",
      "\tEpoch 775 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 775 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 775 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 775 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 775 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 775 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 775 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 775 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 775 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 775 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 775 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 775 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 775 | Training Loss   0.01\n",
      "Epoch 775 | Validation Loss   0.01\n",
      "\tEpoch 776 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 776 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 776 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 776 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 776 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 776 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 776 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 776 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 776 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 776 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 776 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 776 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 776 | Training Loss   0.01\n",
      "Epoch 776 | Validation Loss   0.01\n",
      "\tEpoch 777 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 777 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 777 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 777 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 777 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 777 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 777 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 777 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 777 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 777 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 777 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 777 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 777 | Training Loss   0.01\n",
      "Epoch 777 | Validation Loss   0.01\n",
      "\tEpoch 778 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 778 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 778 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 778 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 778 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 778 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 778 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 778 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 778 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 778 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 778 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 778 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 778 | Training Loss   0.01\n",
      "Epoch 778 | Validation Loss   0.01\n",
      "\tEpoch 779 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 779 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 779 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 779 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 779 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 779 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 779 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 779 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 779 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 779 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 779 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 779 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 779 | Training Loss   0.01\n",
      "Epoch 779 | Validation Loss   0.01\n",
      "\tEpoch 780 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 780 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 780 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 780 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 780 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 780 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 780 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 780 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 780 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 780 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 780 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 780 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 780 | Training Loss   0.01\n",
      "Epoch 780 | Validation Loss   0.01\n",
      "\tEpoch 781 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 781 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 781 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 781 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 781 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 781 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 781 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 781 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 781 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 781 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 781 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 781 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 781 | Training Loss   0.01\n",
      "Epoch 781 | Validation Loss   0.01\n",
      "\tEpoch 782 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 782 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 782 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 782 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 782 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 782 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 782 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 782 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 782 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 782 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 782 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 782 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 782 | Training Loss   0.01\n",
      "Epoch 782 | Validation Loss   0.01\n",
      "\tEpoch 783 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 783 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 783 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 783 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 783 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 783 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 783 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 783 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 783 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 783 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 783 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 783 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 783 | Training Loss   0.01\n",
      "Epoch 783 | Validation Loss   0.01\n",
      "\tEpoch 784 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 784 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 784 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 784 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 784 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 784 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 784 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 784 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 784 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 784 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 784 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 784 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 784 | Training Loss   0.01\n",
      "Epoch 784 | Validation Loss   0.01\n",
      "\tEpoch 785 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 785 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 785 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 785 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 785 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 785 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 785 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 785 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 785 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 785 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 785 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 785 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 785 | Training Loss   0.01\n",
      "Epoch 785 | Validation Loss   0.01\n",
      "\tEpoch 786 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 786 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 786 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 786 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 786 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 786 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 786 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 786 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 786 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 786 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 786 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 786 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 786 | Training Loss   0.01\n",
      "Epoch 786 | Validation Loss   0.01\n",
      "\tEpoch 787 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 787 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 787 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 787 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 787 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 787 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 787 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 787 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 787 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 787 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 787 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 787 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 787 | Training Loss   0.01\n",
      "Epoch 787 | Validation Loss   0.01\n",
      "\tEpoch 788 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 788 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 788 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 788 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 788 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 788 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 788 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 788 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 788 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 788 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 788 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 788 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 788 | Training Loss   0.01\n",
      "Epoch 788 | Validation Loss   0.01\n",
      "\tEpoch 789 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 789 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 789 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 789 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 789 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 789 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 789 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 789 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 789 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 789 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 789 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 789 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 789 | Training Loss   0.01\n",
      "Epoch 789 | Validation Loss   0.01\n",
      "\tEpoch 790 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 790 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 790 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 790 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 790 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 790 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 790 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 790 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 790 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 790 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 790 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 790 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 790 | Training Loss   0.01\n",
      "Epoch 790 | Validation Loss   0.01\n",
      "\tEpoch 791 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 791 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 791 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 791 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 791 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 791 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 791 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 791 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 791 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 791 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 791 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 791 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 791 | Training Loss   0.01\n",
      "Epoch 791 | Validation Loss   0.01\n",
      "\tEpoch 792 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 792 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 792 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 792 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 792 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 792 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 792 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 792 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 792 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 792 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 792 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 792 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 792 | Training Loss   0.01\n",
      "Epoch 792 | Validation Loss   0.01\n",
      "\tEpoch 793 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 793 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 793 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 793 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 793 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 793 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 793 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 793 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 793 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 793 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 793 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 793 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 793 | Training Loss   0.01\n",
      "Epoch 793 | Validation Loss   0.01\n",
      "\tEpoch 794 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 794 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 794 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 794 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 794 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 794 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 794 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 794 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 794 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 794 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 794 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 794 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 794 | Training Loss   0.01\n",
      "Epoch 794 | Validation Loss   0.01\n",
      "\tEpoch 795 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 795 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 795 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 795 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 795 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 795 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 795 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 795 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 795 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 795 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 795 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 795 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 795 | Training Loss   0.01\n",
      "Epoch 795 | Validation Loss   0.01\n",
      "\tEpoch 796 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 796 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 796 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 796 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 796 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 796 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 796 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 796 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 796 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 796 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 796 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 796 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 796 | Training Loss   0.01\n",
      "Epoch 796 | Validation Loss   0.01\n",
      "\tEpoch 797 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 797 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 797 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 797 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 797 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 797 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 797 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 797 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 797 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 797 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 797 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 797 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 797 | Training Loss   0.01\n",
      "Epoch 797 | Validation Loss   0.01\n",
      "\tEpoch 798 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 798 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 798 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 798 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 798 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 798 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 798 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 798 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 798 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 798 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 798 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 798 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 798 | Training Loss   0.01\n",
      "Epoch 798 | Validation Loss   0.01\n",
      "\tEpoch 799 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 799 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 799 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 799 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 799 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 799 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 799 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 799 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 799 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 799 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 799 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 799 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 799 | Training Loss   0.01\n",
      "Epoch 799 | Validation Loss   0.01\n",
      "\tEpoch 800 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 800 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 800 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 800 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 800 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 800 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 800 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 800 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 800 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 800 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 800 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 800 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 800 | Training Loss   0.01\n",
      "Epoch 800 | Validation Loss   0.01\n",
      "\tEpoch 801 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 801 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 801 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 801 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 801 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 801 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 801 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 801 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 801 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 801 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 801 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 801 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 801 | Training Loss   0.01\n",
      "Epoch 801 | Validation Loss   0.01\n",
      "\tEpoch 802 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 802 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 802 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 802 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 802 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 802 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 802 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 802 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 802 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 802 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 802 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 802 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 802 | Training Loss   0.01\n",
      "Epoch 802 | Validation Loss   0.01\n",
      "\tEpoch 803 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 803 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 803 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 803 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 803 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 803 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 803 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 803 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 803 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 803 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 803 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 803 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 803 | Training Loss   0.01\n",
      "Epoch 803 | Validation Loss   0.01\n",
      "\tEpoch 804 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 804 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 804 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 804 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 804 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 804 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 804 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 804 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 804 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 804 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 804 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 804 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 804 | Training Loss   0.01\n",
      "Epoch 804 | Validation Loss   0.01\n",
      "\tEpoch 805 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 805 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 805 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 805 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 805 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 805 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 805 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 805 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 805 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 805 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 805 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 805 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 805 | Training Loss   0.01\n",
      "Epoch 805 | Validation Loss   0.01\n",
      "\tEpoch 806 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 806 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 806 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 806 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 806 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 806 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 806 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 806 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 806 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 806 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 806 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 806 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 806 | Training Loss   0.01\n",
      "Epoch 806 | Validation Loss   0.01\n",
      "\tEpoch 807 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 807 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 807 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 807 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 807 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 807 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 807 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 807 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 807 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 807 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 807 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 807 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 807 | Training Loss   0.01\n",
      "Epoch 807 | Validation Loss   0.01\n",
      "\tEpoch 808 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 808 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 808 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 808 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 808 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 808 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 808 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 808 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 808 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 808 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 808 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 808 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 808 | Training Loss   0.01\n",
      "Epoch 808 | Validation Loss   0.01\n",
      "\tEpoch 809 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 809 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 809 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 809 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 809 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 809 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 809 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 809 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 809 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 809 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 809 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 809 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 809 | Training Loss   0.01\n",
      "Epoch 809 | Validation Loss   0.01\n",
      "\tEpoch 810 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 810 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 810 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 810 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 810 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 810 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 810 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 810 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 810 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 810 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 810 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 810 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 810 | Training Loss   0.01\n",
      "Epoch 810 | Validation Loss   0.01\n",
      "\tEpoch 811 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 811 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 811 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 811 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 811 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 811 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 811 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 811 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 811 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 811 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 811 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 811 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 811 | Training Loss   0.01\n",
      "Epoch 811 | Validation Loss   0.01\n",
      "\tEpoch 812 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 812 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 812 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 812 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 812 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 812 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 812 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 812 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 812 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 812 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 812 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 812 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 812 | Training Loss   0.01\n",
      "Epoch 812 | Validation Loss   0.01\n",
      "\tEpoch 813 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 813 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 813 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 813 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 813 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 813 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 813 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 813 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 813 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 813 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 813 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 813 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 813 | Training Loss   0.01\n",
      "Epoch 813 | Validation Loss   0.01\n",
      "\tEpoch 814 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 814 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 814 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 814 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 814 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 814 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 814 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 814 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 814 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 814 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 814 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 814 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 814 | Training Loss   0.01\n",
      "Epoch 814 | Validation Loss   0.01\n",
      "\tEpoch 815 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 815 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 815 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 815 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 815 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 815 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 815 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 815 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 815 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 815 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 815 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 815 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 815 | Training Loss   0.01\n",
      "Epoch 815 | Validation Loss   0.01\n",
      "\tEpoch 816 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 816 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 816 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 816 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 816 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 816 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 816 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 816 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 816 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 816 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 816 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 816 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 816 | Training Loss   0.01\n",
      "Epoch 816 | Validation Loss   0.01\n",
      "\tEpoch 817 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 817 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 817 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 817 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 817 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 817 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 817 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 817 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 817 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 817 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 817 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 817 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 817 | Training Loss   0.01\n",
      "Epoch 817 | Validation Loss   0.01\n",
      "\tEpoch 818 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 818 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 818 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 818 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 818 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 818 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 818 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 818 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 818 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 818 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 818 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 818 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 818 | Training Loss   0.01\n",
      "Epoch 818 | Validation Loss   0.01\n",
      "\tEpoch 819 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 819 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 819 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 819 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 819 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 819 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 819 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 819 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 819 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 819 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 819 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 819 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 819 | Training Loss   0.01\n",
      "Epoch 819 | Validation Loss   0.01\n",
      "\tEpoch 820 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 820 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 820 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 820 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 820 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 820 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 820 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 820 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 820 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 820 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 820 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 820 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 820 | Training Loss   0.01\n",
      "Epoch 820 | Validation Loss   0.01\n",
      "\tEpoch 821 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 821 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 821 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 821 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 821 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 821 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 821 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 821 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 821 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 821 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 821 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 821 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 821 | Training Loss   0.01\n",
      "Epoch 821 | Validation Loss   0.01\n",
      "\tEpoch 822 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 822 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 822 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 822 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 822 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 822 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 822 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 822 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 822 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 822 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 822 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 822 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 822 | Training Loss   0.01\n",
      "Epoch 822 | Validation Loss   0.01\n",
      "\tEpoch 823 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 823 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 823 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 823 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 823 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 823 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 823 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 823 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 823 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 823 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 823 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 823 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 823 | Training Loss   0.01\n",
      "Epoch 823 | Validation Loss   0.01\n",
      "\tEpoch 824 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 824 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 824 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 824 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 824 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 824 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 824 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 824 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 824 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 824 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 824 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 824 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 824 | Training Loss   0.01\n",
      "Epoch 824 | Validation Loss   0.01\n",
      "\tEpoch 825 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 825 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 825 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 825 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 825 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 825 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 825 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 825 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 825 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 825 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 825 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 825 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 825 | Training Loss   0.01\n",
      "Epoch 825 | Validation Loss   0.01\n",
      "\tEpoch 826 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 826 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 826 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 826 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 826 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 826 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 826 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 826 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 826 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 826 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 826 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 826 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 826 | Training Loss   0.01\n",
      "Epoch 826 | Validation Loss   0.01\n",
      "\tEpoch 827 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 827 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 827 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 827 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 827 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 827 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 827 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 827 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 827 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 827 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 827 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 827 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 827 | Training Loss   0.01\n",
      "Epoch 827 | Validation Loss   0.01\n",
      "\tEpoch 828 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 828 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 828 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 828 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 828 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 828 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 828 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 828 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 828 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 828 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 828 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 828 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 828 | Training Loss   0.01\n",
      "Epoch 828 | Validation Loss   0.01\n",
      "\tEpoch 829 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 829 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 829 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 829 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 829 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 829 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 829 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 829 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 829 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 829 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 829 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 829 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 829 | Training Loss   0.01\n",
      "Epoch 829 | Validation Loss   0.01\n",
      "\tEpoch 830 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 830 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 830 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 830 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 830 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 830 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 830 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 830 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 830 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 830 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 830 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 830 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 830 | Training Loss   0.01\n",
      "Epoch 830 | Validation Loss   0.01\n",
      "\tEpoch 831 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 831 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 831 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 831 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 831 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 831 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 831 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 831 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 831 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 831 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 831 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 831 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 831 | Training Loss   0.01\n",
      "Epoch 831 | Validation Loss   0.01\n",
      "\tEpoch 832 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 832 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 832 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 832 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 832 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 832 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 832 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 832 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 832 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 832 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 832 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 832 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 832 | Training Loss   0.01\n",
      "Epoch 832 | Validation Loss   0.01\n",
      "\tEpoch 833 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 833 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 833 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 833 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 833 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 833 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 833 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 833 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 833 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 833 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 833 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 833 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 833 | Training Loss   0.01\n",
      "Epoch 833 | Validation Loss   0.01\n",
      "\tEpoch 834 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 834 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 834 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 834 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 834 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 834 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 834 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 834 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 834 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 834 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 834 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 834 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 834 | Training Loss   0.01\n",
      "Epoch 834 | Validation Loss   0.01\n",
      "\tEpoch 835 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 835 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 835 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 835 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 835 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 835 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 835 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 835 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 835 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 835 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 835 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 835 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 835 | Training Loss   0.01\n",
      "Epoch 835 | Validation Loss   0.01\n",
      "\tEpoch 836 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 836 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 836 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 836 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 836 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 836 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 836 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 836 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 836 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 836 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 836 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 836 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 836 | Training Loss   0.01\n",
      "Epoch 836 | Validation Loss   0.01\n",
      "\tEpoch 837 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 837 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 837 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 837 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 837 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 837 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 837 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 837 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 837 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 837 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 837 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 837 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 837 | Training Loss   0.01\n",
      "Epoch 837 | Validation Loss   0.01\n",
      "\tEpoch 838 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 838 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 838 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 838 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 838 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 838 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 838 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 838 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 838 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 838 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 838 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 838 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 838 | Training Loss   0.01\n",
      "Epoch 838 | Validation Loss   0.01\n",
      "\tEpoch 839 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 839 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 839 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 839 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 839 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 839 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 839 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 839 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 839 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 839 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 839 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 839 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 839 | Training Loss   0.01\n",
      "Epoch 839 | Validation Loss   0.01\n",
      "\tEpoch 840 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 840 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 840 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 840 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 840 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 840 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 840 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 840 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 840 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 840 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 840 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 840 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 840 | Training Loss   0.01\n",
      "Epoch 840 | Validation Loss   0.01\n",
      "\tEpoch 841 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 841 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 841 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 841 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 841 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 841 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 841 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 841 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 841 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 841 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 841 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 841 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 841 | Training Loss   0.01\n",
      "Epoch 841 | Validation Loss   0.01\n",
      "\tEpoch 842 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 842 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 842 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 842 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 842 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 842 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 842 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 842 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 842 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 842 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 842 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 842 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 842 | Training Loss   0.01\n",
      "Epoch 842 | Validation Loss   0.01\n",
      "\tEpoch 843 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 843 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 843 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 843 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 843 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 843 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 843 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 843 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 843 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 843 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 843 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 843 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 843 | Training Loss   0.01\n",
      "Epoch 843 | Validation Loss   0.01\n",
      "\tEpoch 844 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 844 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 844 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 844 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 844 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 844 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 844 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 844 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 844 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 844 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 844 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 844 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 844 | Training Loss   0.01\n",
      "Epoch 844 | Validation Loss   0.01\n",
      "\tEpoch 845 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 845 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 845 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 845 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 845 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 845 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 845 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 845 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 845 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 845 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 845 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 845 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 845 | Training Loss   0.01\n",
      "Epoch 845 | Validation Loss   0.01\n",
      "\tEpoch 846 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 846 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 846 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 846 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 846 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 846 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 846 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 846 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 846 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 846 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 846 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 846 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 846 | Training Loss   0.01\n",
      "Epoch 846 | Validation Loss   0.01\n",
      "\tEpoch 847 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 847 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 847 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 847 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 847 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 847 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 847 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 847 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 847 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 847 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 847 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 847 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 847 | Training Loss   0.01\n",
      "Epoch 847 | Validation Loss   0.01\n",
      "\tEpoch 848 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 848 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 848 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 848 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 848 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 848 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 848 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 848 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 848 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 848 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 848 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 848 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 848 | Training Loss   0.01\n",
      "Epoch 848 | Validation Loss   0.01\n",
      "\tEpoch 849 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 849 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 849 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 849 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 849 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 849 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 849 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 849 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 849 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 849 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 849 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 849 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 849 | Training Loss   0.01\n",
      "Epoch 849 | Validation Loss   0.01\n",
      "\tEpoch 850 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 850 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 850 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 850 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 850 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 850 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 850 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 850 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 850 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 850 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 850 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 850 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 850 | Training Loss   0.01\n",
      "Epoch 850 | Validation Loss   0.01\n",
      "\tEpoch 851 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 851 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 851 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 851 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 851 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 851 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 851 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 851 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 851 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 851 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 851 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 851 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 851 | Training Loss   0.01\n",
      "Epoch 851 | Validation Loss   0.01\n",
      "\tEpoch 852 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 852 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 852 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 852 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 852 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 852 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 852 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 852 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 852 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 852 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 852 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 852 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 852 | Training Loss   0.01\n",
      "Epoch 852 | Validation Loss   0.01\n",
      "\tEpoch 853 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 853 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 853 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 853 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 853 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 853 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 853 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 853 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 853 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 853 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 853 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 853 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 853 | Training Loss   0.01\n",
      "Epoch 853 | Validation Loss   0.01\n",
      "\tEpoch 854 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 854 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 854 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 854 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 854 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 854 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 854 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 854 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 854 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 854 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 854 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 854 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 854 | Training Loss   0.01\n",
      "Epoch 854 | Validation Loss   0.01\n",
      "\tEpoch 855 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 855 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 855 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 855 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 855 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 855 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 855 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 855 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 855 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 855 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 855 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 855 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 855 | Training Loss   0.01\n",
      "Epoch 855 | Validation Loss   0.01\n",
      "\tEpoch 856 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 856 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 856 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 856 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 856 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 856 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 856 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 856 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 856 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 856 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 856 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 856 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 856 | Training Loss   0.01\n",
      "Epoch 856 | Validation Loss   0.01\n",
      "\tEpoch 857 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 857 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 857 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 857 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 857 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 857 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 857 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 857 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 857 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 857 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 857 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 857 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 857 | Training Loss   0.01\n",
      "Epoch 857 | Validation Loss   0.01\n",
      "\tEpoch 858 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 858 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 858 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 858 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 858 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 858 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 858 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 858 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 858 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 858 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 858 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 858 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 858 | Training Loss   0.01\n",
      "Epoch 858 | Validation Loss   0.01\n",
      "\tEpoch 859 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 859 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 859 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 859 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 859 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 859 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 859 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 859 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 859 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 859 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 859 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 859 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 859 | Training Loss   0.01\n",
      "Epoch 859 | Validation Loss   0.01\n",
      "\tEpoch 860 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 860 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 860 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 860 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 860 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 860 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 860 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 860 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 860 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 860 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 860 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 860 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 860 | Training Loss   0.01\n",
      "Epoch 860 | Validation Loss   0.01\n",
      "\tEpoch 861 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 861 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 861 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 861 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 861 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 861 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 861 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 861 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 861 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 861 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 861 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 861 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 861 | Training Loss   0.01\n",
      "Epoch 861 | Validation Loss   0.01\n",
      "\tEpoch 862 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 862 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 862 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 862 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 862 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 862 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 862 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 862 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 862 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 862 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 862 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 862 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 862 | Training Loss   0.01\n",
      "Epoch 862 | Validation Loss   0.01\n",
      "\tEpoch 863 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 863 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 863 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 863 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 863 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 863 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 863 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 863 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 863 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 863 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 863 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 863 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 863 | Training Loss   0.01\n",
      "Epoch 863 | Validation Loss   0.01\n",
      "\tEpoch 864 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 864 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 864 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 864 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 864 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 864 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 864 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 864 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 864 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 864 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 864 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 864 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 864 | Training Loss   0.01\n",
      "Epoch 864 | Validation Loss   0.01\n",
      "\tEpoch 865 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 865 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 865 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 865 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 865 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 865 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 865 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 865 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 865 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 865 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 865 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 865 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 865 | Training Loss   0.01\n",
      "Epoch 865 | Validation Loss   0.01\n",
      "\tEpoch 866 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 866 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 866 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 866 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 866 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 866 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 866 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 866 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 866 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 866 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 866 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 866 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 866 | Training Loss   0.01\n",
      "Epoch 866 | Validation Loss   0.01\n",
      "\tEpoch 867 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 867 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 867 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 867 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 867 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 867 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 867 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 867 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 867 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 867 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 867 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 867 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 867 | Training Loss   0.01\n",
      "Epoch 867 | Validation Loss   0.01\n",
      "\tEpoch 868 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 868 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 868 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 868 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 868 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 868 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 868 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 868 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 868 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 868 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 868 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 868 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 868 | Training Loss   0.01\n",
      "Epoch 868 | Validation Loss   0.01\n",
      "\tEpoch 869 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 869 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 869 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 869 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 869 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 869 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 869 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 869 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 869 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 869 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 869 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 869 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 869 | Training Loss   0.01\n",
      "Epoch 869 | Validation Loss   0.01\n",
      "\tEpoch 870 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 870 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 870 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 870 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 870 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 870 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 870 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 870 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 870 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 870 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 870 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 870 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 870 | Training Loss   0.01\n",
      "Epoch 870 | Validation Loss   0.01\n",
      "\tEpoch 871 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 871 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 871 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 871 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 871 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 871 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 871 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 871 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 871 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 871 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 871 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 871 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 871 | Training Loss   0.01\n",
      "Epoch 871 | Validation Loss   0.01\n",
      "\tEpoch 872 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 872 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 872 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 872 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 872 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 872 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 872 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 872 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 872 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 872 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 872 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 872 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 872 | Training Loss   0.01\n",
      "Epoch 872 | Validation Loss   0.01\n",
      "\tEpoch 873 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 873 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 873 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 873 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 873 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 873 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 873 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 873 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 873 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 873 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 873 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 873 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 873 | Training Loss   0.01\n",
      "Epoch 873 | Validation Loss   0.01\n",
      "\tEpoch 874 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 874 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 874 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 874 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 874 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 874 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 874 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 874 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 874 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 874 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 874 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 874 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 874 | Training Loss   0.01\n",
      "Epoch 874 | Validation Loss   0.01\n",
      "\tEpoch 875 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 875 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 875 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 875 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 875 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 875 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 875 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 875 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 875 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 875 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 875 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 875 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 875 | Training Loss   0.01\n",
      "Epoch 875 | Validation Loss   0.01\n",
      "\tEpoch 876 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 876 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 876 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 876 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 876 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 876 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 876 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 876 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 876 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 876 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 876 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 876 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 876 | Training Loss   0.01\n",
      "Epoch 876 | Validation Loss   0.01\n",
      "\tEpoch 877 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 877 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 877 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 877 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 877 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 877 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 877 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 877 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 877 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 877 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 877 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 877 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 877 | Training Loss   0.01\n",
      "Epoch 877 | Validation Loss   0.01\n",
      "\tEpoch 878 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 878 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 878 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 878 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 878 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 878 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 878 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 878 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 878 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 878 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 878 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 878 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 878 | Training Loss   0.01\n",
      "Epoch 878 | Validation Loss   0.01\n",
      "\tEpoch 879 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 879 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 879 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 879 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 879 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 879 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 879 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 879 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 879 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 879 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 879 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 879 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 879 | Training Loss   0.01\n",
      "Epoch 879 | Validation Loss   0.01\n",
      "\tEpoch 880 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 880 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 880 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 880 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 880 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 880 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 880 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 880 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 880 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 880 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 880 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 880 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 880 | Training Loss   0.01\n",
      "Epoch 880 | Validation Loss   0.01\n",
      "\tEpoch 881 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 881 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 881 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 881 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 881 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 881 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 881 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 881 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 881 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 881 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 881 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 881 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 881 | Training Loss   0.01\n",
      "Epoch 881 | Validation Loss   0.01\n",
      "\tEpoch 882 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 882 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 882 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 882 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 882 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 882 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 882 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 882 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 882 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 882 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 882 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 882 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 882 | Training Loss   0.01\n",
      "Epoch 882 | Validation Loss   0.01\n",
      "\tEpoch 883 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 883 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 883 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 883 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 883 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 883 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 883 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 883 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 883 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 883 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 883 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 883 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 883 | Training Loss   0.01\n",
      "Epoch 883 | Validation Loss   0.01\n",
      "\tEpoch 884 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 884 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 884 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 884 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 884 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 884 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 884 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 884 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 884 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 884 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 884 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 884 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 884 | Training Loss   0.01\n",
      "Epoch 884 | Validation Loss   0.01\n",
      "\tEpoch 885 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 885 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 885 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 885 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 885 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 885 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 885 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 885 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 885 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 885 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 885 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 885 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 885 | Training Loss   0.01\n",
      "Epoch 885 | Validation Loss   0.01\n",
      "\tEpoch 886 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 886 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 886 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 886 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 886 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 886 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 886 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 886 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 886 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 886 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 886 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 886 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 886 | Training Loss   0.01\n",
      "Epoch 886 | Validation Loss   0.01\n",
      "\tEpoch 887 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 887 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 887 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 887 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 887 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 887 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 887 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 887 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 887 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 887 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 887 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 887 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 887 | Training Loss   0.01\n",
      "Epoch 887 | Validation Loss   0.01\n",
      "\tEpoch 888 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 888 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 888 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 888 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 888 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 888 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 888 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 888 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 888 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 888 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 888 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 888 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 888 | Training Loss   0.01\n",
      "Epoch 888 | Validation Loss   0.01\n",
      "\tEpoch 889 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 889 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 889 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 889 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 889 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 889 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 889 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 889 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 889 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 889 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 889 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 889 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 889 | Training Loss   0.01\n",
      "Epoch 889 | Validation Loss   0.01\n",
      "\tEpoch 890 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 890 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 890 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 890 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 890 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 890 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 890 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 890 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 890 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 890 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 890 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 890 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 890 | Training Loss   0.01\n",
      "Epoch 890 | Validation Loss   0.01\n",
      "\tEpoch 891 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 891 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 891 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 891 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 891 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 891 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 891 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 891 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 891 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 891 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 891 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 891 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 891 | Training Loss   0.01\n",
      "Epoch 891 | Validation Loss   0.01\n",
      "\tEpoch 892 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 892 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 892 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 892 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 892 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 892 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 892 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 892 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 892 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 892 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 892 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 892 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 892 | Training Loss   0.01\n",
      "Epoch 892 | Validation Loss   0.01\n",
      "\tEpoch 893 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 893 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 893 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 893 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 893 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 893 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 893 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 893 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 893 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 893 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 893 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 893 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 893 | Training Loss   0.01\n",
      "Epoch 893 | Validation Loss   0.01\n",
      "\tEpoch 894 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 894 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 894 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 894 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 894 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 894 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 894 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 894 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 894 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 894 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 894 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 894 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 894 | Training Loss   0.01\n",
      "Epoch 894 | Validation Loss   0.01\n",
      "\tEpoch 895 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 895 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 895 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 895 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 895 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 895 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 895 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 895 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 895 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 895 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 895 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 895 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 895 | Training Loss   0.01\n",
      "Epoch 895 | Validation Loss   0.01\n",
      "\tEpoch 896 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 896 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 896 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 896 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 896 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 896 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 896 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 896 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 896 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 896 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 896 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 896 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 896 | Training Loss   0.01\n",
      "Epoch 896 | Validation Loss   0.01\n",
      "\tEpoch 897 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 897 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 897 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 897 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 897 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 897 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 897 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 897 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 897 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 897 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 897 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 897 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 897 | Training Loss   0.01\n",
      "Epoch 897 | Validation Loss   0.01\n",
      "\tEpoch 898 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 898 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 898 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 898 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 898 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 898 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 898 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 898 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 898 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 898 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 898 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 898 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 898 | Training Loss   0.01\n",
      "Epoch 898 | Validation Loss   0.01\n",
      "\tEpoch 899 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 899 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 899 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 899 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 899 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 899 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 899 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 899 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 899 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 899 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 899 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 899 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 899 | Training Loss   0.01\n",
      "Epoch 899 | Validation Loss   0.01\n",
      "\tEpoch 900 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 900 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 900 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 900 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 900 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 900 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 900 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 900 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 900 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 900 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 900 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 900 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 900 | Training Loss   0.01\n",
      "Epoch 900 | Validation Loss   0.01\n",
      "\tEpoch 901 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 901 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 901 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 901 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 901 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 901 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 901 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 901 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 901 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 901 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 901 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 901 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 901 | Training Loss   0.01\n",
      "Epoch 901 | Validation Loss   0.01\n",
      "\tEpoch 902 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 902 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 902 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 902 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 902 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 902 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 902 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 902 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 902 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 902 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 902 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 902 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 902 | Training Loss   0.01\n",
      "Epoch 902 | Validation Loss   0.01\n",
      "\tEpoch 903 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 903 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 903 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 903 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 903 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 903 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 903 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 903 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 903 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 903 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 903 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 903 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 903 | Training Loss   0.01\n",
      "Epoch 903 | Validation Loss   0.01\n",
      "\tEpoch 904 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 904 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 904 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 904 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 904 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 904 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 904 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 904 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 904 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 904 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 904 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 904 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 904 | Training Loss   0.01\n",
      "Epoch 904 | Validation Loss   0.01\n",
      "\tEpoch 905 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 905 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 905 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 905 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 905 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 905 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 905 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 905 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 905 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 905 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 905 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 905 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 905 | Training Loss   0.01\n",
      "Epoch 905 | Validation Loss   0.01\n",
      "\tEpoch 906 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 906 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 906 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 906 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 906 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 906 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 906 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 906 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 906 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 906 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 906 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 906 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 906 | Training Loss   0.01\n",
      "Epoch 906 | Validation Loss   0.01\n",
      "\tEpoch 907 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 907 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 907 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 907 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 907 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 907 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 907 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 907 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 907 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 907 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 907 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 907 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 907 | Training Loss   0.01\n",
      "Epoch 907 | Validation Loss   0.01\n",
      "\tEpoch 908 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 908 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 908 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 908 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 908 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 908 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 908 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 908 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 908 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 908 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 908 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 908 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 908 | Training Loss   0.01\n",
      "Epoch 908 | Validation Loss   0.01\n",
      "\tEpoch 909 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 909 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 909 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 909 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 909 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 909 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 909 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 909 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 909 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 909 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 909 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 909 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 909 | Training Loss   0.01\n",
      "Epoch 909 | Validation Loss   0.01\n",
      "\tEpoch 910 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 910 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 910 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 910 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 910 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 910 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 910 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 910 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 910 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 910 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 910 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 910 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 910 | Training Loss   0.01\n",
      "Epoch 910 | Validation Loss   0.01\n",
      "\tEpoch 911 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 911 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 911 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 911 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 911 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 911 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 911 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 911 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 911 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 911 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 911 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 911 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 911 | Training Loss   0.01\n",
      "Epoch 911 | Validation Loss   0.01\n",
      "\tEpoch 912 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 912 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 912 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 912 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 912 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 912 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 912 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 912 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 912 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 912 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 912 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 912 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 912 | Training Loss   0.01\n",
      "Epoch 912 | Validation Loss   0.01\n",
      "\tEpoch 913 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 913 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 913 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 913 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 913 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 913 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 913 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 913 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 913 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 913 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 913 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 913 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 913 | Training Loss   0.01\n",
      "Epoch 913 | Validation Loss   0.01\n",
      "\tEpoch 914 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 914 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 914 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 914 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 914 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 914 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 914 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 914 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 914 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 914 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 914 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 914 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 914 | Training Loss   0.01\n",
      "Epoch 914 | Validation Loss   0.01\n",
      "\tEpoch 915 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 915 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 915 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 915 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 915 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 915 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 915 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 915 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 915 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 915 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 915 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 915 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 915 | Training Loss   0.01\n",
      "Epoch 915 | Validation Loss   0.01\n",
      "\tEpoch 916 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 916 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 916 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 916 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 916 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 916 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 916 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 916 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 916 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 916 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 916 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 916 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 916 | Training Loss   0.01\n",
      "Epoch 916 | Validation Loss   0.01\n",
      "\tEpoch 917 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 917 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 917 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 917 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 917 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 917 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 917 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 917 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 917 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 917 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 917 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 917 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 917 | Training Loss   0.01\n",
      "Epoch 917 | Validation Loss   0.01\n",
      "\tEpoch 918 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 918 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 918 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 918 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 918 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 918 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 918 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 918 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 918 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 918 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 918 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 918 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 918 | Training Loss   0.01\n",
      "Epoch 918 | Validation Loss   0.01\n",
      "\tEpoch 919 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 919 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 919 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 919 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 919 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 919 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 919 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 919 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 919 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 919 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 919 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 919 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 919 | Training Loss   0.01\n",
      "Epoch 919 | Validation Loss   0.01\n",
      "\tEpoch 920 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 920 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 920 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 920 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 920 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 920 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 920 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 920 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 920 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 920 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 920 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 920 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 920 | Training Loss   0.01\n",
      "Epoch 920 | Validation Loss   0.01\n",
      "\tEpoch 921 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 921 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 921 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 921 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 921 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 921 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 921 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 921 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 921 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 921 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 921 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 921 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 921 | Training Loss   0.01\n",
      "Epoch 921 | Validation Loss   0.01\n",
      "\tEpoch 922 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 922 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 922 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 922 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 922 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 922 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 922 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 922 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 922 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 922 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 922 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 922 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 922 | Training Loss   0.01\n",
      "Epoch 922 | Validation Loss   0.01\n",
      "\tEpoch 923 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 923 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 923 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 923 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 923 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 923 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 923 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 923 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 923 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 923 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 923 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 923 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 923 | Training Loss   0.01\n",
      "Epoch 923 | Validation Loss   0.01\n",
      "\tEpoch 924 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 924 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 924 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 924 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 924 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 924 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 924 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 924 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 924 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 924 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 924 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 924 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 924 | Training Loss   0.01\n",
      "Epoch 924 | Validation Loss   0.01\n",
      "\tEpoch 925 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 925 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 925 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 925 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 925 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 925 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 925 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 925 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 925 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 925 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 925 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 925 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 925 | Training Loss   0.01\n",
      "Epoch 925 | Validation Loss   0.01\n",
      "\tEpoch 926 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 926 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 926 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 926 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 926 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 926 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 926 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 926 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 926 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 926 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 926 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 926 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 926 | Training Loss   0.01\n",
      "Epoch 926 | Validation Loss   0.01\n",
      "\tEpoch 927 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 927 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 927 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 927 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 927 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 927 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 927 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 927 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 927 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 927 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 927 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 927 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 927 | Training Loss   0.01\n",
      "Epoch 927 | Validation Loss   0.01\n",
      "\tEpoch 928 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 928 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 928 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 928 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 928 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 928 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 928 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 928 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 928 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 928 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 928 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 928 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 928 | Training Loss   0.01\n",
      "Epoch 928 | Validation Loss   0.01\n",
      "\tEpoch 929 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 929 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 929 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 929 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 929 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 929 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 929 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 929 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 929 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 929 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 929 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 929 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 929 | Training Loss   0.01\n",
      "Epoch 929 | Validation Loss   0.01\n",
      "\tEpoch 930 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 930 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 930 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 930 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 930 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 930 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 930 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 930 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 930 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 930 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 930 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 930 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 930 | Training Loss   0.01\n",
      "Epoch 930 | Validation Loss   0.01\n",
      "\tEpoch 931 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 931 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 931 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 931 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 931 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 931 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 931 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 931 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 931 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 931 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 931 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 931 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 931 | Training Loss   0.01\n",
      "Epoch 931 | Validation Loss   0.01\n",
      "\tEpoch 932 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 932 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 932 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 932 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 932 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 932 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 932 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 932 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 932 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 932 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 932 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 932 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 932 | Training Loss   0.01\n",
      "Epoch 932 | Validation Loss   0.01\n",
      "\tEpoch 933 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 933 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 933 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 933 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 933 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 933 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 933 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 933 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 933 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 933 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 933 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 933 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 933 | Training Loss   0.01\n",
      "Epoch 933 | Validation Loss   0.01\n",
      "\tEpoch 934 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 934 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 934 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 934 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 934 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 934 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 934 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 934 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 934 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 934 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 934 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 934 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 934 | Training Loss   0.01\n",
      "Epoch 934 | Validation Loss   0.01\n",
      "\tEpoch 935 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 935 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 935 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 935 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 935 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 935 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 935 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 935 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 935 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 935 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 935 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 935 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 935 | Training Loss   0.01\n",
      "Epoch 935 | Validation Loss   0.01\n",
      "\tEpoch 936 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 936 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 936 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 936 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 936 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 936 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 936 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 936 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 936 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 936 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 936 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 936 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 936 | Training Loss   0.01\n",
      "Epoch 936 | Validation Loss   0.01\n",
      "\tEpoch 937 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 937 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 937 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 937 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 937 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 937 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 937 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 937 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 937 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 937 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 937 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 937 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 937 | Training Loss   0.01\n",
      "Epoch 937 | Validation Loss   0.01\n",
      "\tEpoch 938 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 938 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 938 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 938 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 938 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 938 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 938 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 938 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 938 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 938 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 938 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 938 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 938 | Training Loss   0.01\n",
      "Epoch 938 | Validation Loss   0.01\n",
      "\tEpoch 939 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 939 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 939 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 939 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 939 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 939 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 939 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 939 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 939 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 939 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 939 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 939 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 939 | Training Loss   0.01\n",
      "Epoch 939 | Validation Loss   0.01\n",
      "\tEpoch 940 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 940 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 940 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 940 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 940 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 940 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 940 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 940 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 940 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 940 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 940 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 940 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 940 | Training Loss   0.01\n",
      "Epoch 940 | Validation Loss   0.01\n",
      "\tEpoch 941 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 941 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 941 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 941 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 941 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 941 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 941 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 941 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 941 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 941 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 941 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 941 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 941 | Training Loss   0.01\n",
      "Epoch 941 | Validation Loss   0.01\n",
      "\tEpoch 942 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 942 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 942 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 942 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 942 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 942 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 942 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 942 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 942 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 942 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 942 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 942 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 942 | Training Loss   0.01\n",
      "Epoch 942 | Validation Loss   0.01\n",
      "\tEpoch 943 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 943 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 943 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 943 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 943 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 943 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 943 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 943 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 943 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 943 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 943 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 943 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 943 | Training Loss   0.01\n",
      "Epoch 943 | Validation Loss   0.01\n",
      "\tEpoch 944 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 944 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 944 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 944 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 944 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 944 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 944 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 944 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 944 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 944 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 944 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 944 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 944 | Training Loss   0.01\n",
      "Epoch 944 | Validation Loss   0.01\n",
      "\tEpoch 945 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 945 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 945 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 945 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 945 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 945 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 945 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 945 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 945 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 945 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 945 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 945 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 945 | Training Loss   0.01\n",
      "Epoch 945 | Validation Loss   0.01\n",
      "\tEpoch 946 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 946 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 946 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 946 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 946 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 946 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 946 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 946 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 946 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 946 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 946 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 946 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 946 | Training Loss   0.01\n",
      "Epoch 946 | Validation Loss   0.01\n",
      "\tEpoch 947 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 947 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 947 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 947 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 947 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 947 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 947 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 947 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 947 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 947 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 947 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 947 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 947 | Training Loss   0.01\n",
      "Epoch 947 | Validation Loss   0.01\n",
      "\tEpoch 948 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 948 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 948 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 948 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 948 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 948 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 948 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 948 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 948 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 948 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 948 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 948 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 948 | Training Loss   0.01\n",
      "Epoch 948 | Validation Loss   0.01\n",
      "\tEpoch 949 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 949 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 949 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 949 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 949 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 949 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 949 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 949 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 949 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 949 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 949 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 949 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 949 | Training Loss   0.01\n",
      "Epoch 949 | Validation Loss   0.01\n",
      "\tEpoch 950 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 950 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 950 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 950 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 950 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 950 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 950 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 950 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 950 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 950 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 950 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 950 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 950 | Training Loss   0.01\n",
      "Epoch 950 | Validation Loss   0.01\n",
      "\tEpoch 951 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 951 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 951 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 951 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 951 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 951 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 951 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 951 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 951 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 951 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 951 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 951 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 951 | Training Loss   0.01\n",
      "Epoch 951 | Validation Loss   0.01\n",
      "\tEpoch 952 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 952 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 952 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 952 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 952 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 952 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 952 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 952 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 952 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 952 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 952 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 952 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 952 | Training Loss   0.01\n",
      "Epoch 952 | Validation Loss   0.01\n",
      "\tEpoch 953 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 953 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 953 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 953 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 953 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 953 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 953 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 953 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 953 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 953 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 953 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 953 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 953 | Training Loss   0.01\n",
      "Epoch 953 | Validation Loss   0.01\n",
      "\tEpoch 954 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 954 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 954 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 954 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 954 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 954 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 954 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 954 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 954 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 954 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 954 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 954 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 954 | Training Loss   0.01\n",
      "Epoch 954 | Validation Loss   0.01\n",
      "\tEpoch 955 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 955 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 955 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 955 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 955 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 955 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 955 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 955 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 955 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 955 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 955 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 955 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 955 | Training Loss   0.01\n",
      "Epoch 955 | Validation Loss   0.01\n",
      "\tEpoch 956 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 956 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 956 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 956 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 956 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 956 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 956 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 956 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 956 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 956 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 956 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 956 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 956 | Training Loss   0.01\n",
      "Epoch 956 | Validation Loss   0.01\n",
      "\tEpoch 957 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 957 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 957 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 957 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 957 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 957 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 957 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 957 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 957 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 957 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 957 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 957 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 957 | Training Loss   0.01\n",
      "Epoch 957 | Validation Loss   0.01\n",
      "\tEpoch 958 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 958 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 958 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 958 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 958 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 958 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 958 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 958 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 958 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 958 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 958 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 958 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 958 | Training Loss   0.01\n",
      "Epoch 958 | Validation Loss   0.01\n",
      "\tEpoch 959 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 959 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 959 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 959 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 959 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 959 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 959 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 959 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 959 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 959 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 959 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 959 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 959 | Training Loss   0.01\n",
      "Epoch 959 | Validation Loss   0.01\n",
      "\tEpoch 960 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 960 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 960 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 960 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 960 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 960 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 960 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 960 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 960 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 960 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 960 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 960 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 960 | Training Loss   0.01\n",
      "Epoch 960 | Validation Loss   0.01\n",
      "\tEpoch 961 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 961 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 961 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 961 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 961 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 961 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 961 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 961 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 961 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 961 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 961 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 961 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 961 | Training Loss   0.01\n",
      "Epoch 961 | Validation Loss   0.01\n",
      "\tEpoch 962 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 962 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 962 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 962 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 962 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 962 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 962 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 962 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 962 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 962 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 962 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 962 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 962 | Training Loss   0.01\n",
      "Epoch 962 | Validation Loss   0.01\n",
      "\tEpoch 963 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 963 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 963 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 963 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 963 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 963 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 963 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 963 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 963 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 963 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 963 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 963 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 963 | Training Loss   0.01\n",
      "Epoch 963 | Validation Loss   0.01\n",
      "\tEpoch 964 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 964 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 964 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 964 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 964 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 964 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 964 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 964 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 964 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 964 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 964 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 964 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 964 | Training Loss   0.01\n",
      "Epoch 964 | Validation Loss   0.01\n",
      "\tEpoch 965 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 965 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 965 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 965 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 965 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 965 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 965 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 965 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 965 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 965 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 965 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 965 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 965 | Training Loss   0.01\n",
      "Epoch 965 | Validation Loss   0.01\n",
      "\tEpoch 966 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 966 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 966 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 966 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 966 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 966 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 966 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 966 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 966 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 966 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 966 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 966 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 966 | Training Loss   0.01\n",
      "Epoch 966 | Validation Loss   0.01\n",
      "\tEpoch 967 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 967 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 967 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 967 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 967 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 967 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 967 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 967 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 967 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 967 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 967 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 967 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 967 | Training Loss   0.01\n",
      "Epoch 967 | Validation Loss   0.01\n",
      "\tEpoch 968 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 968 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 968 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 968 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 968 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 968 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 968 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 968 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 968 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 968 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 968 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 968 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 968 | Training Loss   0.01\n",
      "Epoch 968 | Validation Loss   0.01\n",
      "\tEpoch 969 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 969 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 969 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 969 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 969 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 969 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 969 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 969 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 969 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 969 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 969 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 969 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 969 | Training Loss   0.01\n",
      "Epoch 969 | Validation Loss   0.01\n",
      "\tEpoch 970 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 970 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 970 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 970 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 970 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 970 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 970 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 970 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 970 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 970 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 970 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 970 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 970 | Training Loss   0.01\n",
      "Epoch 970 | Validation Loss   0.01\n",
      "\tEpoch 971 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 971 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 971 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 971 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 971 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 971 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 971 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 971 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 971 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 971 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 971 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 971 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 971 | Training Loss   0.01\n",
      "Epoch 971 | Validation Loss   0.01\n",
      "\tEpoch 972 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 972 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 972 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 972 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 972 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 972 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 972 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 972 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 972 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 972 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 972 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 972 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 972 | Training Loss   0.01\n",
      "Epoch 972 | Validation Loss   0.01\n",
      "\tEpoch 973 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 973 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 973 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 973 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 973 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 973 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 973 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 973 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 973 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 973 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 973 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 973 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 973 | Training Loss   0.01\n",
      "Epoch 973 | Validation Loss   0.01\n",
      "\tEpoch 974 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 974 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 974 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 974 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 974 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 974 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 974 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 974 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 974 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 974 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 974 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 974 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 974 | Training Loss   0.01\n",
      "Epoch 974 | Validation Loss   0.01\n",
      "\tEpoch 975 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 975 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 975 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 975 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 975 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 975 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 975 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 975 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 975 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 975 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 975 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 975 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 975 | Training Loss   0.01\n",
      "Epoch 975 | Validation Loss   0.01\n",
      "\tEpoch 976 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 976 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 976 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 976 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 976 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 976 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 976 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 976 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 976 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 976 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 976 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 976 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 976 | Training Loss   0.01\n",
      "Epoch 976 | Validation Loss   0.01\n",
      "\tEpoch 977 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 977 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 977 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 977 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 977 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 977 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 977 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 977 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 977 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 977 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 977 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 977 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 977 | Training Loss   0.01\n",
      "Epoch 977 | Validation Loss   0.01\n",
      "\tEpoch 978 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 978 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 978 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 978 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 978 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 978 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 978 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 978 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 978 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 978 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 978 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 978 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 978 | Training Loss   0.01\n",
      "Epoch 978 | Validation Loss   0.01\n",
      "\tEpoch 979 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 979 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 979 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 979 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 979 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 979 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 979 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 979 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 979 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 979 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 979 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 979 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 979 | Training Loss   0.01\n",
      "Epoch 979 | Validation Loss   0.01\n",
      "\tEpoch 980 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 980 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 980 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 980 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 980 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 980 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 980 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 980 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 980 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 980 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 980 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 980 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 980 | Training Loss   0.01\n",
      "Epoch 980 | Validation Loss   0.01\n",
      "\tEpoch 981 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 981 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 981 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 981 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 981 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 981 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 981 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 981 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 981 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 981 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 981 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 981 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 981 | Training Loss   0.01\n",
      "Epoch 981 | Validation Loss   0.01\n",
      "\tEpoch 982 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 982 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 982 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 982 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 982 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 982 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 982 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 982 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 982 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 982 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 982 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 982 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 982 | Training Loss   0.01\n",
      "Epoch 982 | Validation Loss   0.01\n",
      "\tEpoch 983 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 983 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 983 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 983 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 983 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 983 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 983 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 983 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 983 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 983 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 983 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 983 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 983 | Training Loss   0.01\n",
      "Epoch 983 | Validation Loss   0.01\n",
      "\tEpoch 984 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 984 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 984 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 984 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 984 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 984 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 984 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 984 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 984 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 984 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 984 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 984 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 984 | Training Loss   0.01\n",
      "Epoch 984 | Validation Loss   0.01\n",
      "\tEpoch 985 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 985 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 985 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 985 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 985 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 985 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 985 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 985 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 985 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 985 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 985 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 985 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 985 | Training Loss   0.01\n",
      "Epoch 985 | Validation Loss   0.01\n",
      "\tEpoch 986 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 986 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 986 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 986 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 986 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 986 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 986 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 986 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 986 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 986 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 986 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 986 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 986 | Training Loss   0.01\n",
      "Epoch 986 | Validation Loss   0.01\n",
      "\tEpoch 987 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 987 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 987 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 987 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 987 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 987 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 987 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 987 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 987 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 987 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 987 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 987 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 987 | Training Loss   0.01\n",
      "Epoch 987 | Validation Loss   0.01\n",
      "\tEpoch 988 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 988 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 988 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 988 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 988 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 988 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 988 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 988 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 988 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 988 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 988 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 988 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 988 | Training Loss   0.01\n",
      "Epoch 988 | Validation Loss   0.01\n",
      "\tEpoch 989 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 989 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 989 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 989 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 989 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 989 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 989 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 989 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 989 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 989 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 989 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 989 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 989 | Training Loss   0.01\n",
      "Epoch 989 | Validation Loss   0.01\n",
      "\tEpoch 990 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 990 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 990 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 990 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 990 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 990 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 990 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 990 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 990 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 990 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 990 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 990 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 990 | Training Loss   0.01\n",
      "Epoch 990 | Validation Loss   0.01\n",
      "\tEpoch 991 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 991 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 991 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 991 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 991 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 991 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 991 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 991 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 991 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 991 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 991 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 991 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 991 | Training Loss   0.01\n",
      "Epoch 991 | Validation Loss   0.01\n",
      "\tEpoch 992 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 992 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 992 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 992 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 992 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 992 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 992 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 992 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 992 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 992 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 992 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 992 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 992 | Training Loss   0.01\n",
      "Epoch 992 | Validation Loss   0.01\n",
      "\tEpoch 993 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 993 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 993 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 993 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 993 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 993 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 993 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 993 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 993 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 993 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 993 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 993 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 993 | Training Loss   0.01\n",
      "Epoch 993 | Validation Loss   0.01\n",
      "\tEpoch 994 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 994 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 994 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 994 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 994 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 994 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 994 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 994 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 994 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 994 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 994 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 994 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 994 | Training Loss   0.01\n",
      "Epoch 994 | Validation Loss   0.01\n",
      "\tEpoch 995 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 995 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 995 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 995 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 995 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 995 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 995 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 995 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 995 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 995 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 995 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 995 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 995 | Training Loss   0.01\n",
      "Epoch 995 | Validation Loss   0.01\n",
      "\tEpoch 996 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 996 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 996 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 996 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 996 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 996 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 996 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 996 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 996 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 996 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 996 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 996 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 996 | Training Loss   0.01\n",
      "Epoch 996 | Validation Loss   0.01\n",
      "\tEpoch 997 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 997 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 997 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 997 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 997 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 997 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 997 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 997 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 997 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 997 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 997 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 997 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 997 | Training Loss   0.01\n",
      "Epoch 997 | Validation Loss   0.01\n",
      "\tEpoch 998 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 998 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 998 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 998 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 998 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 998 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 998 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 998 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 998 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 998 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 998 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 998 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 998 | Training Loss   0.01\n",
      "Epoch 998 | Validation Loss   0.01\n",
      "\tEpoch 999 | Batch 0 | Training Loss   0.00\n",
      "\tEpoch 999 | Batch 40 | Training Loss   0.00\n",
      "\tEpoch 999 | Batch 80 | Training Loss   0.00\n",
      "\tEpoch 999 | Batch 120 | Training Loss   0.00\n",
      "\tEpoch 999 | Batch 160 | Training Loss   0.00\n",
      "\tEpoch 999 | Batch 200 | Training Loss   0.00\n",
      "\tEpoch 999 | Batch 240 | Training Loss   0.00\n",
      "\tEpoch 999 | Batch 280 | Training Loss   0.00\n",
      "\tEpoch 999 | Batch 0 | Validation Loss   0.00\n",
      "\tEpoch 999 | Batch 40 | Validation Loss   0.00\n",
      "\tEpoch 999 | Batch 80 | Validation Loss   0.00\n",
      "\tEpoch 999 | Batch 120 | Validation Loss   0.00\n",
      "Epoch 999 | Training Loss   0.01\n",
      "Epoch 999 | Validation Loss   0.01\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "epochs = 1000\n",
    "n_batches_training = training_dataset[\"source\"].T.shape[0] // batch_size\n",
    "n_batches_testing = testing_dataset[\"source\"].T.shape[0] // batch_size\n",
    "losses = []\n",
    "val_loss = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for i in range(n_batches_training):\n",
    "        optimizer.zero_grad()\n",
    "        x = training_dataset[\"source\"][:,i*batch_size:(i+1)*batch_size].T\n",
    "        y = training_dataset[\"target\"][i*batch_size:(i+1)*batch_size]\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        x = x.to(device)\n",
    "        y = torch.unsqueeze(y, -1)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = torch.mean((output - y)**2)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if i % 40 == 0:\n",
    "            print('\\tEpoch %d | Batch %d | Training Loss %6.2f' % (epoch, i, loss.item()))\n",
    "    \n",
    "    for i in range(n_batches_testing):\n",
    "        x = testing_dataset[\"source\"][:,i*batch_size:(i+1)*batch_size].T\n",
    "        y = testing_dataset[\"target\"][i*batch_size:(i+1)*batch_size]\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        x = x.to(device)\n",
    "        y = torch.unsqueeze(y, -1)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = torch.mean((output - y)**2)\n",
    "\n",
    "        val_loss += [loss.item()]\n",
    "        # target_outputs += list(output.T[0].cpu().detach().numpy())\n",
    "        # target_truth += list(y.cpu().detach().numpy())\n",
    "\n",
    "        if i % 40 == 0:\n",
    "            print('\\tEpoch %d | Batch %d | Validation Loss %6.2f' % (epoch, i, loss.item()))\n",
    "    print('Epoch %d | Training Loss %6.2f' % (epoch, sum(losses)/len(losses)))\n",
    "    print('Epoch %d | Validation Loss %6.2f' % (epoch, sum(val_loss)/len(val_loss)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0, epochs, len(losses)), losses, label=\"Training\")\n",
    "plt.plot(np.linspace(0, epochs, len(val_loss)), val_loss, label=\"Validation\")\n",
    "plt.ylabel(\"MSE log-loss\", fontsize=20)\n",
    "plt.xlabel(\"Epoch\", fontsize=20)\n",
    "plt.legend(loc=\"upper right\", fontsize=15)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"./loss_curve.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad = testing_dataset[\"source\"][0]\n",
    "dens = testing_dataset[\"source\"][1]\n",
    "Babs = testing_dataset[\"source\"][2]\n",
    "encr = testing_dataset[\"source\"][3]\n",
    "slope = testing_dataset[\"target\"]\n",
    "predicted_slope = model(torch.tensor(testing_dataset[\"source\"].T, dtype=torch.float32).to(device)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rad, predicted_slope, 'g.', alpha=0.02)\n",
    "plt.plot(rad, slope, 'm.', alpha=0.02)\n",
    "# plt.plot(dens, predicted_slope, 'g.', alpha=0.02)\n",
    "# plt.plot(dens, slope, 'm.', alpha=0.02)\n",
    "# plt.plot(Babs, predicted_slope, 'g.', alpha=0.02)\n",
    "# plt.plot(Babs, slope, 'm.', alpha=0.02)\n",
    "# plt.plot(encr, predicted_slope, 'g.', alpha=0.02)\n",
    "# plt.plot(encr, slope, 'm.', alpha=0.02)\n",
    "\n",
    "# plt.plot(1000, 1000,'b.', label=\"Prediction\")\n",
    "# # plt.plot([0,1], [0,1], color='red', linestyle='--', label=\"Reference\")\n",
    "# plt.axhline(0, color='red', linestyle='--', label=\"Perfect\")\n",
    "# # plt.plot(slope.T[::100], predicted_slope.T[0][::100], 'b.', alpha=0.1)\n",
    "# plt.plot(slope.T[::100], (predicted_slope.T[0]-slope.T)[::100], 'b.', alpha=0.1)\n",
    "# plt.ylabel(\"Residual\", fontsize=20)\n",
    "# # plt.ylabel(\"Predicted Slope\", fontsize=20)\n",
    "# plt.xlabel(\"True Slope\", fontsize=20)\n",
    "# plt.xlim(0, 1)\n",
    "# # plt.ylim(0, 1)\n",
    "# plt.ylim(-0.15, 0.15)\n",
    "# plt.legend(loc=\"upper left\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"./slope_residuals.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01533026, -0.09317164,  0.07764612,  0.24760722,  0.09719799,\n",
       "       -0.08726634, -0.20231137, -0.10136826, -0.10566126, -0.08033785,\n",
       "        0.34365845, -0.07342204, -0.11508676, -0.09615466, -0.05647072,\n",
       "       -0.11734276,  0.05778848, -0.0825475 ,  0.01539035,  0.51936185,\n",
       "       -0.10064353,  0.10819273, -0.08588037, -0.09309423,  0.04075627,\n",
       "        0.37899572, -0.08480714, -0.08337086, -0.08085114,  0.09346624,\n",
       "        0.02569263, -0.09115702, -0.16507754, -0.09313771, -0.08634068,\n",
       "        0.43492132, -0.10510363, -0.10099135, -0.17101964,  0.06249185,\n",
       "       -0.08993234, -0.12945822,  0.2939474 , -0.09150913, -0.09056275,\n",
       "       -0.17915995, -0.08830021, -0.07952209, -0.08997546,  0.03045143,\n",
       "       -0.11357652, -0.09561132, -0.1109589 ,  0.2376792 , -0.09033671,\n",
       "       -0.09221609, -0.10251323, -0.08939242, -0.09989181, -0.09847704,\n",
       "        0.47242534, -0.09087139, -0.08551657, -0.09006871,  0.04583211,\n",
       "       -0.0877146 , -0.09046257,  0.37774056,  0.07428886,  0.40453732,\n",
       "       -0.09258315, -0.08492516,  0.08836223, -0.08845671, -0.08182232,\n",
       "       -0.08585556, -0.1782313 , -0.08460574, -0.08303902, -0.08574955,\n",
       "        0.03456591, -0.09333867, -0.0799536 , -0.00758332, -0.1036764 ,\n",
       "       -0.09157239, -0.08907741,  0.26139665, -0.09348217, -0.1745151 ,\n",
       "       -0.17470397, -0.10621564, -0.09618564, -0.07235095,  0.19811882,\n",
       "        0.5465295 ,  0.49767464,  0.36274505, -0.08430465, -0.08451906,\n",
       "       -0.0928476 ,  0.35061282, -0.19895156, -0.0842451 , -0.18290639,\n",
       "       -0.11840853, -0.09982981, -0.03573152, -0.06878084, -0.08453973,\n",
       "        0.33299792, -0.09694128, -0.15797216,  0.42181122, -0.08468707,\n",
       "       -0.09026144, -0.08426528, -0.04346755, -0.08237015,  0.23605175,\n",
       "       -0.12785016, -0.03793995, -0.09151199, -0.08959052,  0.00639194,\n",
       "        0.2447763 , -0.08493924,  0.14332466, -0.12931284,  0.43122655,\n",
       "        0.0916184 , -0.08352533,  0.5148757 , -0.08443286,  0.10620709,\n",
       "        0.48209274, -0.1161643 , -0.08825698, -0.09922068, -0.09673445,\n",
       "       -0.12876879, -0.09070778,  0.05591647, -0.09896709,  0.5921478 ,\n",
       "       -0.1074497 , -0.08664304,  0.06161509,  0.01532206, -0.09428662,\n",
       "       -0.08416314, -0.10371137, -0.11077192,  0.43292278, -0.07974294,\n",
       "        0.03052358, -0.12918352,  0.5106956 ,  0.09680887,  0.03366195,\n",
       "        0.315623  , -0.07798226, -0.08536124,  0.5295248 , -0.09553505,\n",
       "       -0.10841205, -0.10059606, -0.08434264,  0.10704063, -0.09334518,\n",
       "        0.62170607, -0.08724552, -0.10356794,  0.03629477, -0.09227687,\n",
       "       -0.09072667, -0.01362786,  0.47692335, -0.0907943 , -0.08977613,\n",
       "       -0.08646868, -0.0610016 , -0.09063973, -0.16460265, -0.09014378,\n",
       "       -0.08646239, -0.08438163,  0.03130566, -0.06200635, -0.10230309,\n",
       "        0.2682867 , -0.08311142, -0.08748865, -0.17539774,  0.4889698 ,\n",
       "       -0.14467987, -0.17619632,  0.60741526, -0.08419806, -0.0981835 ,\n",
       "       -0.08506843,  0.13326396,  0.59238136, -0.19743118, -0.09049751,\n",
       "       -0.09862819,  0.3128453 ,  0.34460658,  0.46127212,  0.46405494,\n",
       "       -0.08319014, -0.17045942, -0.10259713, -0.08945033, -0.08946425,\n",
       "       -0.07341997,  0.24329929,  0.0325083 , -0.08352852, -0.09136543,\n",
       "       -0.0955448 ,  0.3850404 , -0.09354243,  0.15384267,  0.08465804,\n",
       "       -0.08916916, -0.08838379, -0.09035973,  0.48861045, -0.11476545,\n",
       "       -0.08712226,  0.28977334, -0.05968519,  0.4912985 ,  0.23448114,\n",
       "       -0.08833402, -0.11931803,  0.19900258,  0.19784768, -0.09452139,\n",
       "        0.15233026, -0.08666895, -0.09282343, -0.08068603, -0.10048273,\n",
       "       -0.0909934 ,  0.14424072, -0.08571304,  0.34410357, -0.08922425,\n",
       "       -0.09206112, -0.06682944,  0.48616165, -0.09080786, -0.17174898,\n",
       "       -0.08893269, -0.1599979 , -0.07406701, -0.09768808,  0.03363438,\n",
       "        0.02236618,  0.22020672], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_slope.T[0]-slope.T[0])[::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(val_loss, 100)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddpm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
